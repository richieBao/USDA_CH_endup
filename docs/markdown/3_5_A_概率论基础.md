> Created on Sun Apr 30 11:56:23 2023 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.5-A 推理学习：概率论基础

概率论和图论是概率图的基础，图论的基础可以查看*复杂网络*部分，本章主要汇集概率论的基础知识点，并利用Python相关库介入计算。以《概率论与数理统计》<sup>[1,2]</sup>为主要参考书目；以[datascience](https://github.com/data-8/datascience)<sup>①</sup>、[SymPy](https://docs.sympy.org/latest/index.html)<sup>②</sup>为主要计算工具；结合加州大学伯克利分校（University of California（UC）, Berkeley）[数据科学的概率课程（Probability for Data Science）在线教材](http://prob140.org/textbook/content/README.html)<sup>[3]</sup>整理书写。

## 3.5.1 随机事件与概率

* 随机试验

**概率论**是一门研究**随机现象**（事先无法预知会出现哪个结果）统计规律性的数学学科。随机现象在一次试验中呈现不确定性的结果，而在大量重复试验中结果将呈现某种规律性，称为**统计规律性**。为研究随机现象的统计规律性，对客观事物进行观察的过程为**随机试验（试验）**。随机试验的特点有：

（1）在相同条件下试验可以重复进行；

（2）每次试验的结果不止一种，但是试验之前必须明确所有可能的结果；

（3）每次试验将会出现什么样的结果事先无法预知。

* 样本空间

随机试验一切可能结果组成的集合称为**样本空间**，记为$\Omega=\{\omega\}$，其中$\omega$表示试验的每一个可能结果，又称为**样本点**，即样本空间为全体样本点的集合。样本空间中的元素可以是数（例如，投掷一枚均匀骰子的样本空间为$\Omega=\{1,2, \cdots, 6\}$），也可以不是数（例如，抛掷一枚硬币的样本空间为$ \Omega=\{H, T\}$）；可以为有限个，也可以为无限个（例如，污染气体浓度（单位，ppm）的样本空间$\Omega=\{c: c \geqslant 0\}$）。

* 随机事件

通过随机试验研究随机现象时，每次试验都只能出现$\Omega$中的某一个结果（样本点）$\omega$。各个可能结果$\omega$是否在一次试验中出现是随机的。在随机试验中，常关注某些结果是否出现，例如空气质量指数（Air quality index，AQI）是否超出了评定空气质量为优的阈值，掷出点数是否为奇数（可描述为$A=\{1,3,5\}$，为$\Omega=\{1,2, \cdots, 6\}$的一个子集）等。这些在一次试验中可能出现和可能不出现的一类结果称为**随机事件（事件）**，常用大写字母$A, B, C, \cdots$等表示。从集合的角度，随机事件为样本空间部分样本点组成的集合。在事件的定义中，有如下概念：

（1）任意随机事件$A$是样本空间$\Omega$的一个子集；

（2）当试验结果$\omega$属于该子集时，就说事件$A$发生了；否则，不属于该子集，事件$A$没有发生；

（3）仅含一个样本点的随机事件称为**基本事件**；

（4）样本空间$\Omega$也是自己的一个子集，也称为一个事件。因为$\Omega$包含所有可能的试验结果，所以$\Omega$在每次试验中一定发生，又称为**必然事件**；

（5）空集$Ø$也是样本空间$\Omega$的一个子集，所以也称为一个事件。因为$Ø$中不包含任何元素，所以$Ø$在每次试验中一定不发生，又称为**不可能事件**。

* 关系运算

因为随机事件为样本空间部分样本点组成的集合，因此同集合，给定一个随机试验，$\Omega$是它的样本空间，$A, B, C, \cdots$都为$\Omega$的子集，随机事件有如下关系和运算：

（1） 如果$A \subset B$（或$B \supset A$），则称事件$A$包含在$B$中（或称$B$包含$A$）。从概率论角度来说，事件$A$发生必然导致事件$B$发生；

（2）如果$A \subset B$，$B \subset A$同时成立，则称事件$A$与$B$相等，记为$A=B$。从概率论角度来说，事件$A$发生必然导致事件$B$发生；同样，事件$B$发生必然导致事件$A$发生，即$A$和$B$为同一事件；

（3）如果$A$和$B$没有相同的样本点，则称事件$A$和$B$互不相容（或称为互斥），从概率论角度来说，事件$A$和事件$B$不可能同时发生；

（4）事件$A$与$B$的并，记为$A \cup B$，表示由事件$A$与$B$中所有样本点组成的新事件，从概率论角度，事件$A$与$B$中至少有一个可能结果发生；

（5）事件$A$与$B$的交，记为$A \cap B$（或$AB$），表示由事件$A$和$B$中公共的样本点组成的事件，从概率论角度，事件$A$与$B$同时发生；

（6）事件$A$与$B$的差，记为$A - B$，表示由在事件$A$中且不在事件$B$中的样本点组成的新事件，从概率论角度，事件$A$发生，且事件$B$不发生；

（7）事件$A$的对立事件（或称为逆事件、余事件），记为$ \overline{A} $，表示由$\Omega$中且不在事件$A$中的的所有样本点组成的新事件，即$ \overline{A} = \Omega -A$，从概率论角度，事件$A$不发生。

<img src="./imgs/3_5_a/3_5_a_01.jpg" height='auto' width=700 title="caDesign"> 

从随机事件的关系和运算可以得出：

（1）对立事件一定是互不相容的事件，即$A \cap  \overline{A} =Ø$，但互不相容事件不一定是对立事件；

（2）根据差事件和对立事件的定义，事件$A$与$B$的差还可以表示成$A-B=A \overline{B} $；

（3）必然事件$\Omega$与不可能事件$Ø$互为对立事件，即$ \overline{ \Omega } =Ø,  \overline{Ø} = \Omega $。

事件的运算性质，满足如下定律：

（1）交换律，$A \cup B=B \cup A, A \cap B=B \cap A $；

（2）结合律，$ (A \cup B) \cup C=A \cup(B \cup C),(A B) C=A(B C)$；

（3）分配律，$(A \cup B) \cap C=A C \cup B C,(A \cap B) \cup C=(A \cup C) \cap(B \cup C)$;

（4）对偶律，$\overline{A \cup B}=\bar{A} \cap \bar{B}, \overline{A \cap B}=\bar{A} \cup \bar{B}$。

* 概率定义

在$n$次试验中，如果事件$A$出现了$n_A$次，则称比值$\frac{n_{A} }{n} $为这$n$次试验中事件$A$出现的频率，记为$f_n(A)=\frac{n_A}{n}$，$n_{A} $称为事件$A$发生的**频数**。**概率的统计定义**为：随着试验次数$n$的增大，频率值逐步“稳定”到一个实数，这个实数称为事件$A$发生的概率。**概率的公理化定义**为：设任一随机试验$E$，$\Omega$为相应的样本空间，若对任意事件$A$，有唯一实数$P(A)$与之对应，且满足下面条件，则数$P(A)$称为事件$A$的概率：

（1）**非负性公理**，对于任意事件$A$，总有$P(A) \geq 0$ ;

（2） **规范性公理**，$P( \Omega )=1$；

（3）**可列可加性公理**，若$ A_1, A_2, \cdots, A_n$为两两互不相容的事件，则有$P\left(\bigcup_{i=1}^{\infty} A_i\right)=\sum_{i=1}^{\infty} P\left(A_i\right)$。

由概率的3条公理，得到概率的一些重要基本性质如下：

（1）$ P(Ø)=0$；

（2）有限可加性。设$ A_1, A_2, \cdots, A_n$为两两互不相容的事件，$P\left(\bigcup_{i=1}^{n} A_i\right)=\sum_{i=1}^{n} P\left(A_i\right)$;

（3）对任意事件$A$，有$P( \overline{A} )=1-P(A)$；

（4）若事件$A \subset B$，则$P(B-A)=P(B)-P(A)$；

（5）减法公式。设$A,B$为任意事件，则$P(A-B)=P(A)-P(AB)$；

（6）加法公式。设$A,B$为任意事件，则$P(A \cup B)=P(A)+P(B)-P(AB)$。

* 等可能概型

最简单的一种随机现象是样本空间中的每个基本事件发生的可能性相等，称之为**等可能概型**。例如抛掷一枚均匀的硬币或一颗均匀的骰子等。研究这一类随机现象的数学模型称之为**古典概型**。当样本空间是某个区域（可以是一维区间、二维平面或三维空间），例如搭乘地铁的等待时间、蒲丰投针问题等，称之为**几何概型**。

对于古典概型有，（1）随机试验的样本空间只有有限个样本点，可记作$\Omega=\left\{\omega_1, \omega_2, \cdots, \omega_n\right\}$；（2）每个基本事件发生的可能性相等，即$\left.P\left(\{ \omega_1\right\}\right)=\cdots=P\left(\left\{\omega_n\right\}\right)=\frac{1}{n}$。若事件$A$中含有$n_A$个样本点，则事件$A$的概率为：$P(A)= \frac{n_A}{n} $，式中，$n_A$为事件$A$中所含样本点的个数，$n$为$\Omega$中所有样本点的个数。例如，抛掷两枚均匀的骰子，观察出现的点数，设事件$A$表示“两个骰子的点数一样”，则$\Omega$中由两个骰子可能出现的所有不同结果组成有$\Omega =\{(1,1),(1,2), \ldots ,(1,6),(2,1), \ldots ,(6,6)\}$，共包含36个样本点，而$A=\{(1,1),(2,2), \ldots ,(6,6)\}$，共6个样本点，因而$P(A)= \frac{6}{36}= \frac{1}{6}  $。

几何概型是古典概型的推广，保留每个样本点发生的等可能性，但去掉了$\Omega$中包含有限个样本点的限制，即允许试验可能结果有无穷不可列个。对几何概型有，（1）随机试验的样本空间$\Omega$是某个区域（可以是一维区间、二维平面或三维空间）；（2）每个样本点发生的可能性相等，则事件$A$的概率为：$ P(A)=\frac{m(A)}{m(\Omega)}$，式中，$m(   \bullet    )$在一维情形下表示长度，在二维情形下表示面积，在三维情形下表示体积。求几何概型的关键在于图形正确的描述样本空间$\Omega$和所求事件$A$，然后计算出相关图形的度量（一般为长度、面积或体积）。

* 条件概率

**条件概率**是指在某随机事件$A$发生的条件下，另一随机事件$B$发生的概率，记为$P(B  \mid  A)$，它与$P(B)$是不同的两类概率。例如，假设抛掷一枚均匀的骰子，已知掷出的点数是偶数，求点数超过3的概率。因为该试验的样本空间是$ \Omega =\{1,2,3,4,5 ,6\}$，随机事件$A=\{2,4,6\}$，随机事件$B=\{4,5,6\}$，在已知条件事件$A$发生前提下观察满足事件$B$的样本点有$\{4,6\}$2个，因此在已知事件$A$发生条件下，事件$B$发生的概率为$P(B \mid A)= \frac{2}{3} $，并可易知$P(B \mid A)= \frac{P(AB)}{P(A)} $。

定义 1：设$E$是随机试验，$\Omega$是样本空间，$A,B$是随机试验$E$上的两个随机事件且$P(A)>0$，称$P(B \mid A)= \frac{P(AB)}{P(A)} $为在事件$A$发生条件下事件$B$发生的概率，称为**条件概率**，记作$P(B \mid A)$。

可以验证，条件概率同样满足概率公理化定义的三条基本性质，设$P(B)>0$，有（必须在同一条件下进行）：

（1）**非负性公理**，对于任意事件$A$，总有$P(A \mid B) \geq 0$；

（2）**规范性公理**，$P( \Omega  \mid B) =1$;

（3）**可列可加性公理**，若$ A_1, A_2, \cdots$为两两互不相容的事件，则有$P\left(\bigcup_{i=1}^{\infty} A_i \mid B \right)=\sum_{i=1}^{\infty} P\left(A_i \mid B \right)$。

定理 1（概率的乘法公式）：设$A,B$为随机试验$E$上的两个事件，且$P(A)>0$，则有$P(AB)=P(A)P(B \mid A)$；同理，若$P(B)>0$，有$P(AB)=P(B)P(A \mid B)$。将其推广到多个事件的情况，设$A,B,C$为任意的3个事件，且$P(AB)>0$，有$P(ABC)=P(A)P(B \mid A)P(C \mid AB)$。更一般的表述为，设$ A_1, A_2, \cdots, A_n$为一事件组，且$P\left(A_1 A_2 \cdots A_{n-1}\right)>0$，则$P\left(A_1 A_2 \cdots A_n\right)=P\left(A_1\right) P\left(A_2 \mid A_1\right) P\left(A_3 \mid A_1 A_2\right) \cdots P\left(A_n \mid A_1 A_2 \cdots A_{n-1}\right)$。

* 事件的相互独立性

一般来说，设$A,B$为试验$E$的两个事件，且$P(A)>0$，则事件$A$的发生对事件$B$发生的概率是有影响的，这时条件概率$P(B \mid A) \neq P(B)$。但是，如果有$P(B \mid  A) = P(B)$，则可以推导出$P(A B)=P(A) P(B \mid A)=P(A) P(B)$。即，不管事件$A$发生还是不发生，都对事件$B$发生的概率没有影响，可以理解为事件$A$和事件$B$之间没有“关系”，或者称事件$A$和事件$B$相互独立。

定义 2：设$A,B$为试验$E$的两个事件，如果满足等式$P(AB)=P(A)P(B)$，则称事件$A$和事件$A$**相互独立**，简称$A,B$**独立**。

定理 2：若事件$A$与事件$B$相互独立，则下列各对事件也相互独立：$A$与$ \overline{B} $，$\overline A$与$B$、$\overline A$与$\overline B$，即，

$P(A B)=P(A) P(B) \\  \Leftrightarrow P(\bar{A} B)=P(\bar{A}) P(B) \\  \Leftrightarrow P(A \bar{B})=P(A) P(\bar{B}) \\  \Leftrightarrow P(\bar{A} \bar{B})=P(\bar{A}) P(\bar{B})$

对于上4对事件，只要有一对是相互独立的，则其余3对也相互独立，可理解为：事件$A$与$B$相互独立，则$A$的发生不会影响$B$发生的概率；$A$的发生也不会影响$B$不发生的概率；$A$的不发生也不会影响$B$发生的概率；$A$的不发生也不会影响$B$不发生的概率。

将相互独立性推广到3各事件的情况，有，

定义 3：设$A,B,C$是试验$E$的三个事件，如果满足等式$P(A B)=P(A) P(B) \\ P(A C)=P(A) P(C) \\  P(B C)=P(B) P(C)$，则称事件$A,B,C$**两两相互独立**。

定义 4：设$A,B,C$是试验$E$的三个事件，如果满足等式$P(A B)=P(A) P(B) \\ P(A C)=P(A) P(C) \\  P(B C)=P(B) P(C) \\ P(ABC)=P(A)P(B)P(C)$，则称事件$A,B,C$**相互独立**。

* 全概率公式与贝叶斯公式

定义：设$E$是随机试验，$\Omega$是相应的样本空间，$ A_1, A_2, \cdots, A_n$为$\Omega$的一个事件组，若满足条件：（1）$A_i \cap A_j=Ø (i \neq j)$；（2）$A_1 \cup A_2 \cup \cdots \cup A_n=\Omega$，则称事件组$ A_1, A_2, \cdots, A_n$为样本空间的一个**完备事件组**，完备事件组完成了对样本空间的一个分割。

定理 1（**全概率公式**）：设$ A_1, A_2, \cdots, A_n$为样本空间$\Omega$的一个完备事件组，且$P\left(A_i\right)>0(i=1,2, \cdots, n)$，$B$为任意事件，则$P(B)=\sum_{i=1}^n P\left(A_i\right) P\left(B \mid A_i\right) $。

定理 2（**贝叶斯公式**）：设$ A_1, A_2, \cdots, A_n$为样本空间$\Omega$的一个完备事件组，且$P\left(A_i\right)>0(i=1,2, \cdots, n)$，$B$为满足条件$P(B)>0$的任一事件，则，$P\left(A_i \mid B\right)=\frac{P\left(A_i\right) P\left(B \mid A_i\right)}{\sum_{i=1}^n P\left(A_i\right) P\left(B \mid A_i\right)}$。

<img src="./imgs/3_5_a/3_5_a_02.jpg" height='auto' width=500 title="caDesign"> 

对全概率公式和贝叶斯公式可以通过上图理解，对于条件概率$P\left(A_i \mid B\right)$，即随机事件$B$发生条件下，$A_i$发生的概率的计算可以转化为$P(B \mid A_i)$条件概率的相关计算，即随机事件$A_i$发生条件下，$B$发生的概率。对全概率公式，通过已知每种“原因”发生的概率，即$P(A)$和$P(\overline A)$已知，求结果$B$发生的概率$P(B)$。这里$P(A)$和$P(\overline A)$又称为**先验概率**；对于贝叶斯公式，则是从已知结果$B$发生的条件下分析由各个可能“原因”引起的条件概率$P(A \mid B)$和$P(\overline A \mid B)$，所以贝叶斯公式也可以看作“已知结果，分析原因”的问题，这里$P(A \mid B)$和$P(\overline A \mid B)$又称为**后验概率**。

又例如，有两个口袋，甲袋中盛有2个白球，1个黑球；乙袋中盛有1个白球，2个黑球，由甲袋中任取一球放入乙袋，再从乙袋取出一球，问从乙袋中取出的球为白球的概率，则为根据以往的数据分析试验结果的概率，为先验概率，计算推导为：$ P(A)=\sum_{i=1}^2 P\left(B_i\right) P\left(A \mid B_i\right)=\frac{2}{3} \times \frac{2}{4}+\frac{1}{3} \times \frac{1}{4}=\frac{5}{12}$；如果已知从乙袋中所取的球是白球，问从甲袋中所取球为白球的概率则是根据试验结果推断引起该结果原因的概率，为后验概率，计算推导为：$ P\left(B_1 \mid A\right)=\frac{P\left(B_1\right) P\left(A \mid B_1\right)}{P\left(B_1\right) P\left(A \mid B_1\right)+P\left(B_2\right) P\left(A \mid B_2\right)}=\frac{\frac{2}{3} \times \frac{2}{4}}{\frac{2}{3} \times \frac{2}{4}+\frac{1}{3} \times \frac{1}{4}}=\frac{4}{5}$。

## 3.5.2 随机变量及其分布

* 随机变量的定义

定义 1：在随机试验$E$中，$\Omega$是相应的样本空间，如果对$\Omega$中的每一个样本点$\omega$，有唯一一个实数$X(\omega)$与它对应，那么就把这个定义域为$\Omega$的单值实值函数（Real-valued function）$X=X(\omega)$称为（一维）随机变量。例如，抛掷一枚均匀的硬币，观察其朝上的面，则样本空间$\Omega = \{H,T\}$（$H$为正面，$T$为反面），随机变量$X$可设置为：

|  样本点 |   | $X$的取值  |
|---|---|---|
| H  |  $ \rightarrow $ | 1  |
| T  | $ \rightarrow $  |  0 |

如果抛掷三枚均匀的硬币，观察其朝上的面， 则样本空间$ \Omega =\{HHH,HHT,HTH,THH,HTT,THT,TTH,TTT\}$。若随机变量$X$表示“三次抛掷中反面朝上的次数”，则随机变量$X$的取值与样本点之间的对应关系可设置为：

|  样本点 |   | $X$的取值  |
|---|---|---|
| HHH  |  $ \rightarrow $ | 0  |
| HHT  | $ \rightarrow $  | 1 |
|HTH|$ \rightarrow $|1|
|THH|$ \rightarrow $|1|
|HTT|$ \rightarrow $|2|
|THT|$ \rightarrow $|2|
|TTH|$ \rightarrow $|2|
|TTT|$ \rightarrow $|3|

从上述例举可知，无论试验结果本身与数量是否有关，都可以把试验的每个结果与实数对应起来，即把试验结果数量化，由于这样的数量依赖于试验的结果，随试验结果的不同而变化，所以它的取值具有随机性，称这样的变量为随机变量，因此可以说，随机变量是试验结果的函数。

随机变量一般用大写字母$X,Y$等表示，随机变量的取值一般用小写字母$x,y$等来表示。如果一个随机变量仅可能取有限或可列个值，则称其为离散型随机变量；如果一个随机变量的取值充满了数轴上的一个区间（或某几个区间的并），则称其为非离散型随机变量。连续型随机变量是非离散型随机变量中常见的一类随机变量。

随机变量定义的直观理解为，随机变量$X$是样本点的函数，这个函数的自变量是样本点，可以是数，也可以不是数，定义域是样本空间；而因变量必须是实数，这个函数可以让不同的样本点对应不同的实数，也可以让多个样本点对应于同一个实数。

* 随机变量的分布函数

随机变量$X$是样本点$\omega$的一个实值函数，为了掌握$X$的统计规律性，需要知道$X$取值于某个区间的概率，由于$\{a<X \leq b\}=\{X \leq b\}-\{X \leq a\}, \\ \{X>c\}= \Omega -\{X \leq c\}$，因此对于任意实数$x$，只需要知道$\{X \leq x \}$的概率，用$F(x)$表示这个概率值。

定义 2：设$X$是一个随机变量，对于任意实数$x$，称函数$F(x)=P(X \leq x), - \infty <x<+ \infty $为随机变量$X$的**分布函数**。对于任意两个实数$- \infty< a<b<+ \infty $，有$P(a<X \leq b)=F(b)-F(a)$，因此，只要已知$X$的分布函数，就可以知道$X$落在任意区间$(a,b]$内的概率，即分布函数可以完整的描述一个随机变量的统计规律性。从定义可以得知：

（1）分布函数是定义在$(- \infty ,+ \infty )$上，取值在$[0,1]$上的一个函数；

（2）任意随机变量$X$都有且仅有一个分布函数，有了分布函数，就可以计算与随机变量$X$相关事件的概率问题。

* 离散型随机变量及其分布律

设$E$是随机试验，$\Omega$是相应的样本空间，$X$是$\Omega$上的随机变量，若$X$的值域（记为$\Omega_X$）为有限集或可列集，此时称$X$为（一维）**离散型随机变量**。

定义 3：若一维离散型随机变量$X$的取值为$x_{1},x_{2}, \ldots ,x_{n}, \ldots   $，称相应的概率$P(X=x_i)=p_i,i=1,2,  \cdots $为离散型随机变量$X$的**分布律（或分布列、概率函数）**。

一维离散型随机变量的分布律可表示为：

| $X$  |  $x_1$ | $x_2$  | $\cdots$  | $x_n$  | $\cdots$  |
|---|---|---|---|---|---|
| 概率  | $p_1$  | $p_2$  | $\cdots$   |  $p_n$ |  $\cdots$  |，

且满足（1）非负性$p_i \geq 0,i=1,2, \cdots $；（2）规范性$ \sum_{i=1}^{\infty} p_i=1$。这两条性质也是判断某一数列是否能成为分布律的充要条件。

例如，设随机变量$X$的分布律为：

|  $X$ |  -1 | 0  | 2  |
|---|---|---|---|
| 概率  | 0.2  | 0.4  | 0.4  |

则可计算，$P(X \leqslant-0.7)=P(X=-1)=0.2$；将分布律转化为分布函数有，$x<-1, P(X \leqslant x)=0;\\-1 \leqslant x<0,P(X \leqslant x)=P(X=-1)=0.2;\\0 \leqslant x<2,P(X \leqslant x)=P(X=-1)+P(X=0)=0.2+0.4=0.6 ;\\ x \geqslant 2,P(X \leqslant x)= P(X=-1)+P(X=0)+P(X=2)=0.2+0.4+0.4=1.$，即$F(x)= \begin{cases}0, & x<-1, \\ 0.2, & -1 \leqslant x<0 \\ 0.6, & 0 \leqslant x<2, \\ 1, & x \geqslant 2 .\end{cases} $。

已知一个离散型随机变量的分布律可以求得其分布函数，同样，已知一个离散型随机变量的分布函数可以求其分布律，有：$P(X=-1)=P(X \leqslant-1)=F(-1)=0.2 \text {, } \\  P(X=0)=P(-1<X \leqslant 0)=F(0)-F(-1)=0.6-0.2=0.4 \text {, } \\  P(X=2)=P(0<X \leqslant 2)=F(2)-F(0)=1-0.6=0.4$

分布函数和分布律对离散型随机变量的取值规律描述是等价的，分布律相对更直观方便。

* 连续型随机变量及其密度函数

连续型随机变量的取值充满了数轴上的一个或者某几个区间的并，在这个区间里有无穷不可列个实时，因此分布律不再适用描述连续型随机变量，而使用概率密度函数表示。

定义 4：设$E$是随机试验，$\Omega$是相应的样本空间，$X$是$\Omega$上的随机变量，$F(x)$是$X$的分布函数，若存在非负函数$f(x)$使得$F(x)=\int_{-\infty}^x f(t) \mathrm{d} t$，则称$X$为（一维）连续型随机变量，$f(x)$称为$X$的（概率）密度函数。其满足，（1）非负性$f(x) \geqslant 0,-\infty<x<+\infty$；（2）规范性$\int_{-\infty}^{+\infty} f(x) \mathrm{d} x=1$。

概率密度函数$f(x)$与分布函数$F(x)$之间的关系可用下图示意，$F(x)=P(X  \leqslant x)$恰好是$f(x)$在区间$(- \infty ,x]$上的积分，为下图绿色填充部分的面积（或对应累积分布函数（CDF）的值）。连续型随机变量具有如下性质：

（1）分布函数$F(x)$是连续函数，在$f(x)$的连续点处，$ F'(x)=f(x) $；

（2）对任意一个常数$c,- \infty <c<+ \infty $，有$P(X=c)=0$，因此，在事件$\{a\leqslant X\leqslant b\}$中剔除$X=a$或剔除$X=b$，都不影响概率的大小，即$P(a \leqslant X \leqslant b)=P(a<X \leqslant b)=P(a \leqslant X<b)=P(a<X<b)$，而离散型随机变量计算的就是“点点概率”。

（3）对任意两个常数$a,b$，有$P(a<X \leqslant b)=\int_a^b f(x) \mathrm{d} x$。


```python
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

fig, ax=plt.subplots(1, 1,figsize=(5,5))

loc,scale=2,1
x=np.linspace(norm.ppf(0.001, loc, scale),norm.ppf(0.999, loc, scale), 100)
ax.plot(x, norm.pdf(x, loc, scale),'r-', lw=5, alpha=0.6, label='norm PDF')
ax.plot(x, norm.cdf(x, loc, scale),'k--', lw=3, alpha=0.6, label='norm CDF')

px=np.arange(-3,3,0.001)
ax.fill_between(px,norm.pdf(px, loc, scale),alpha=0.5, color='g')

ax.text(-2,1, r'$f(x)$', family="monospace",size=20)
ax.text(1.5,0.25, r'$F(x)$', family="monospace",size=20)
ax.text(5,-0.13, r'$x$', family="monospace",size=20)
ax.text(3,-0.13, r'$x$', family="monospace",size=20)

def plot_style(ax):
    # Move the left and bottom spines to x = 0 and y = 0, respectively.
    ax.spines[["left", "bottom"]].set_position(("data", 0))
    # Hide the top and right spines.
    ax.spines[["top", "right"]].set_visible(False)
    ax.plot(1, 0, ">k", transform=ax.get_yaxis_transform(), clip_on=False)
    ax.plot(0, 1, "^k", transform=ax.get_xaxis_transform(), clip_on=False)

plot_style(ax)
plt.legend(loc='center right')
plt.show()
```


<img src="./imgs/3_5_a/output_10_0.png" height='auto' width='auto' title="caDesign">    


* 常用离散型随机变量

1）二项分布

若随机试验$E$只有2个可能结果，$A$和$\overline A$，则称$E$为**伯努利试验（Bernoulli trial）**。设事件$A$在一次试验中发生的概率$P(A)=p(0<p<1)$，则$P(\bar{A})=1-p$。将$E$独立的重复进行$n$次，则称$n$**重伯努利试验**。

记随机变量$X$表示在$n$重伯努利试验中$A$事件发生的次数，可知$X$的所有可能取值为$0,1,2, \cdots ,n$。对每一$k(0 \leq k \leq n)$，事件$\{X=k\}$即为“$n$次试验中事件$A$恰好发生$k$次”，由于各试验是相互独立的，根据事件的独立性，$X$的分布律为：$P(X=k)=\left(\begin{array}{l}n \\ k\end{array}\right) p^k(1-p)^{n-k}, 0<p<1, k=0,1, \cdots, n $，称随机变量$X$服从参数为$n,p$的**二项分布**，记为$ X \sim B(n, p)$。式中，$\left(\begin{array}{l}n \\ k\end{array}\right)$为**组合**（Combination）表示，同符号$C_k^n$，一般从$n$个不同的元素（成员）中，任取$k(k \leq n)$个元素为一组，称为从$n$个元素中取出$k$个元素的一个组合（当且仅当每个组合具有相同的元素时，两个组合是相同的（每个组合中元素的排列无关紧要）），例如给定$n=3$个水果，苹果、橙子和梨子，设$k=2$，则得出3种两两组合，苹果和梨子（同梨子和苹果），2个苹果和2个梨子，计算公式为：$C_n^i = \frac{n(n - 1)\dots (n - i + 1)}{i!} = \frac{n!}{i!(n - i)!}$。

根据二项式展开公式：$(a + b)^n = \sum_{i = 0}^n C_n^i a^i b^{n - i} \quad (n \text{ 为正整数})$，可以推导出$\sum_{k=0}^n P(X=k)=\sum_{k=0}^n\left(\begin{array}{l}n \\ k\end{array}\right) p^k(1-p)^{n-k}=(p+1-p)^n=1$；且，$P(X=k) \geqslant 0, k=0,1, \cdots, n$，满足离散型随机变量分布律的规范性和非负性。

当$n=1$时，$X \sim B\left(1, p\right) $，即有$P(X=k)=\left(\begin{array}{l}1 \\ k\end{array}\right) p^k(1-p)^{1-k}=p^k(1-p)^{1-k}, 0<p<1, k=0,1 $，相应的分布律为：

| $X$ | 0 | 1 |   
|---|---|---|
| 概率  | $1-p$  | $p$  |

表示随机变量$X$只取2个值，分别为 0 和 1，故又可称随机变量$X$服从参数$p(0<p<1)$的$0-1$分布（或两点分布）。

由服从参数为$n,p$二项分布的随机变量$X$的分布律计算公式，定义`P_Xk_binomialDistributio()`函数计算$P(X=k)$。例如某人向同一目标重复独立射击5次，每次命中目标的概率为0.8，求此人命中3次的概率为`PX_a=0.2048`；此人至少命中2次的概率为`PX_b=0.99328`。


```python
# IPython extension to reload modules before executing user code.
%load_ext autoreload 
# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.
%autoreload 2
import usda.pgm as usda_pgm
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
from scipy.stats import poisson
from scipy.stats import expon
import math
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    


```python
PX_a=usda_pgm.P_Xk_binomialDistribution(n=5,k=3,p=0.8)
print(PX_a)
```

    0.20479999999999993
    


```python
PX_b=1-usda_pgm.P_Xk_binomialDistribution(n=5,k=0,p=0.8)-usda_pgm.P_Xk_binomialDistribution(n=5,k=1,p=0.8)
print(PX_b)
```

    0.99328
    

如果向同一目标重复独立射击100次，计算$P(X=k), k=0,1,2,\cdots, 100$，可以发现二项分布近似于正态分布。


```python
n=100
PX_100=[usda_pgm.P_Xk_binomialDistribution(n=n,k=i,p=0.8) for i in range(n+1)]
pts=[i for i in range(n+1)]

fig, ax=plt.subplots(1, 1,figsize=(10,2))
ax.plot(pts, PX_100,'r-', lw=3, alpha=0.6, label='$P(X=k), k=0,1,2,\cdots, 100$')  

plot_style(ax)
plt.legend(loc=10)
plt.show()
```


<img src="./imgs/3_5_a/output_17_0.png" height='auto' width='auto' title="caDesign">    


如果调整命中的概率为$P(A)=0.5$，则可以发现最大概率趋于约中间的位置。


```python
PX_100=[usda_pgm.P_Xk_binomialDistribution(n=n,k=i,p=0.5) for i in range(n+1)]

fig, ax=plt.subplots(1, 1,figsize=(10,2))
ax.plot(pts, PX_100,'r-', lw=3, alpha=0.6, label='$P(X=k), k=0,1,2,\cdots, 100$')

plot_style(ax)
plt.show()
```


<img src="./imgs/3_5_a/output_19_0.png" height='auto' width='auto' title="caDesign">    
    


2） 泊松分布

设随机变量$X$的取值为$0,1,2, \cdots ,n, \cdots $，其分布律为$P(X=k)=\frac{\lambda^k}{k !} \mathrm{e}^{-\lambda}, \lambda>0, k=0,1,2, \cdots, n, \cdots$，称随机变量$X$服从参数为$\lambda$的**泊松分布**，记为$X \sim P(\lambda)$。易知，$P\{X=k\} \geqslant 0, k=0,1,2, \cdots$，且$\sum_{k=0}^{\infty} P\{X=k\}=\sum_{k=0}^{\infty} \frac{\lambda^k}{k !} \mathrm{e}^{-\lambda}=\mathrm{e}^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^k}{k !}=\mathrm{e}^{-\lambda} \cdot \mathrm{e}^\lambda=1$。

泊松分布适合于描述单位时间（或空间）内随机事件发生的次数，如，某一服务设施在一定时间内到达的人数，电话交换机接到呼叫的次数，汽车站台的后客人数，机器出现的故障数，显微镜下单位分区内的细菌分布数等。

下述应用`SciPy`库提供的`poisson`方法绘制泊松分布，横轴$k$为随机事件$A$出现的次数（整数值），$\lambda$是预期的发生率，纵轴是给定$\lambda$时出现$k$次的概率。


```python
fig, ax=plt.subplots(1, 1,figsize=(5,5))
x=np.arange(0,20) # x=np.arange(poisson.ppf(0.001, 10),poisson.ppf(0.999, 10))
ax.plot(x, poisson.pmf(x, 10), 'yo-', ms=8, label='$\lambda=10$')
ax.plot(x, poisson.pmf(x, 4), 'co-', ms=8, label='$\lambda=4$')
ax.plot(x, poisson.pmf(x, 1), 'ko-', ms=8, label='$\lambda=1$')

plot_style(ax)
plt.legend(loc='upper right')
plt.xlabel("$k$")
plt.ylabel("$P(x=k)$")
plt.show()
```


<img src="./imgs/3_5_a/output_21_0.png" height='auto' width='auto' title="caDesign">    


例如，已知一购物网站每周销售某款商品的数量$X$服从参数为6的泊松分布，问周初至少预备多少货源才能保证该周不脱销的概率不小于0.9（假设上周没有库存，且本周不再进货）。由`poisson.ppf`（Percent point function (inverse of cdf — percentiles)）方法可以直接计算$k$（货源量），得$k=9$。并用`poisson.cdf`（Cumulative distribution function，累积分布函数）验证$k=9$时的概率，为0.916，不小于题目给定的0.9。


```python
k=poisson.ppf(q=0.9, mu=6)
print(k)
p=poisson.cdf(k, 6)
print(p)
```

    9.0
    0.9160759830051242
    

泊松分布可以作为二项分布的一种近似，有**泊松定理**，在$n$重伯努利试验中，记事件$A$在一次试验中发生的概率为$p_n$，如果当$n \rightarrow + \infty $时，有$n p_n \rightarrow \lambda(>0)$，则$\lim _{n \rightarrow+\infty}\left(\begin{array}{l}n \\ k\end{array}\right) p_n^k\left(1-p_n\right)^{n-k}=\frac{\lambda^k}{k !} \mathrm{e}^{-\lambda}$。

例如，设某保险公司的某类保险有1000人投保，每个投保人在1年内死亡的概率为0.005，且每个人在1年内是否死亡是相互独立的，试求在未来1年中者1000个投保人中死亡人数不超过10人的概率。因为$n=1000$较大，而$p=0.005$较小，因此下述分别应用二项分布和泊松分布计算，结果近似相等。


```python
n=1000
k=10
p=0.005
PX_1=1-usda_pgm.P_Xk_binomialDistribution(n=n,k=k,p=p)

lamb=n*p
PX_2=poisson.cdf(k, mu=lamb)
print(f'PX_1={PX_1},\nPX_2={PX_2}')
```

    PX_1=0.9820037708176401,
    PX_2=0.9863047314016171
    

* 常用连续型随机变量

1）均匀分布

设$X$为随机变量，对任意2个实数$a,b(a<b)$，概率密度函数为$f(x)= \begin{cases}\frac{1}{b-a}, & a<x<b ， \\ 0, & \text { 其他. }\end{cases} $，则称随机变量$X$服从区间$(a,b)$上的**均匀分布**（下图左），记为$X \sim U(a,b)$。

若$X \sim U(a,b)$，则相应的分布函数（下图右）为$F(x)= \begin{cases}0, & x<a, \\ \frac{x-a}{b-a}, & a \leqslant x<b, \\ 1, & x \geqslant b .\end{cases} $，由此得到，若$X \sim U(a, b), a<c<c+d<b$，则$P(c<X \leqslant c+d)=\int_c^{c+d} \frac{1}{b-a} \mathrm{~d} x=\frac{d}{b-a}$，该结论说明，均匀分布的随机变量$X$，在其取值范围$(a,b)$中的任何子区间取值的概率仅与该区间长度$d$有关而与区间的位置$c$无关。


```python
plt.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False

fig, axs=plt.subplots(1, 2,figsize=(10,5))

a,b=-1,4
axs[0].hlines(y =1/(b-a), xmin = a, xmax = b,linewidth=5, color='b')
axs[0].vlines(x=[a,b],ymin=0,ymax =1/(b-a), linewidth=1, color='k',linestyles='dashed')
axs[0].hlines(y =1/(b-a), xmin = 0, xmax = a,linewidth=1, color='k',linestyles='dashed')
axs[0].text(-2,0.2, r'$f(x)$', family="monospace",size=20)
axs[0].text(4.5,-0.015,'$x$', family="monospace",size=20)
axs[0].text(0.6,1/(b-a)-0.015,'$\\frac{1}{b-a}$', family="monospace",size=15)
axs[0].text(a,-0.02,'$a$', family="monospace",size=15)
axs[0].text(b,-0.02,'$b$', family="monospace",size=15)
axs[0].set_title("均匀分布密度函数$f(x)$")

axs[1].plot([a,b,b+3],[0,1,1],linewidth=5, color='r')
axs[1].vlines(x=b,ymin=0,ymax =1, linewidth=1, color='k',linestyles='dashed')
axs[1].hlines(y =1, xmin = 0, xmax = b,linewidth=1, color='k',linestyles='dashed')
axs[1].text(-3,1, r'$F(x)$', family="monospace",size=20)
axs[1].text(7.5,-0.1,'$x$', family="monospace",size=20)
axs[1].text(a,-0.09,'$a$', family="monospace",size=15)
axs[1].text(b,-0.09,'$b$', family="monospace",size=15)
axs[1].set_title("均匀分布分布函数$F(x)$")

plot_style(axs[0])
plot_style(axs[1])
fig.tight_layout()
plt.show()
```


<img src="./imgs/3_5_a/output_27_0.png" height='auto' width='auto' title="caDesign">    


例如，设随机变量$X \sim U(-1,4)$，求事件$\{|X|<2\}$的概率。因为$X$的概率密度函数为$f(x)= \begin{cases}\frac{1}{5}, & -1<x<4 \\ 0, & \text { 其他. }\end{cases}$，所以$P(|X|<2)=P(-1<X<2)=\int_{-1}^2 \frac{1}{5} \mathrm{~d} x=\frac{3}{5}$。如果事件$Y$表示对$X$作3次相互独立重复观测中事件$\{|X|<2\}$出现的次数，则$Y \sim B\left(3, \frac{3}{5}\right)$，所以$P(Y=2)=\left(\begin{array}{l}3 \\ 2\end{array}\right)\left(\frac{3}{5}\right)^2 \frac{2}{5}=\frac{54}{125}$。

2）指数分布

设$X$为随机变量，概率密度函数（下图左）为$f(x)=\left\{\begin{array}{ll}\lambda \mathrm{e}^{-\lambda x}, & x \geqslant 0, \\ 0, & \text { 其他, }\end{array} \quad \lambda>0 .\right.$，则称随机变量$X$服从参数为$\lambda$的**指数分布**，记为$X \sim E( \lambda )$。

若$X \sim E( \lambda )$，则相应的分布函数（下图右）为$F(x)= \begin{cases}0, & x<0, \\ 1-\mathrm{e}^{-\lambda x}, & x \geqslant 0 .\end{cases} $，由此得到，若$X \sim E( \lambda ), 0<a<b$，则$P(a<X \leqslant b)=F(b)-F(a)=\mathrm{e}^{-\lambda a}-\mathrm{e}^{-\lambda b}$。

服从指数分布的随机变量只能取非负实数，常用于各种“寿命”分布，例如电子元件的寿命，某个特定事件发生所需的等待时间等往往服从指数分布。


```python
def expon_lamb_pdf(x,lamb):
    return lamb*math.e**(-lamb*x)

def expon_lamb_cdf(x,lamb):
    return 1-math.e**(-lamb*x)

plt.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False

fig, axs=plt.subplots(1, 2,figsize=(10,5))
x=np.linspace(0,60, 60)
lamb=0.1

axs[0].plot(x, expon_lamb_pdf(x,lamb),'b-', lw=5, alpha=0.6, label=f'expon pdf;$\\lambda$={lamb}')
axs[1].plot(x, expon_lamb_cdf(x,lamb),'r-', lw=5, alpha=0.6, label=f'expon cdf;$\\lambda$={lamb}')

for ax in axs: ax.legend(loc='center right')
axs[0].set_title("指数分布密度函数$f(x)$")
axs[1].set_title("指数分布分布函数$F(x)$")
axs[0].text(-15,0.1, r'$f(x)$', family="monospace",size=20)
axs[0].text(65,-0.01,'$x$', family="monospace",size=20)
axs[1].text(-15,1, r'$F(x)$', family="monospace",size=20)
axs[1].text(65,-0.1,'$x$', family="monospace",size=20)

plot_style(axs[0])
plot_style(axs[1])
fig.tight_layout()
plt.show()
```


<img src="./imgs/3_5_a/output_30_0.png" height='auto' width='auto' title="caDesign">    


3） 正态分布

设连续型随机变量$X$的概率密度为$f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^2}{2 \sigma^2}},-\infty<x<+\infty$，式中，$ \mu , \sigma ( \sigma >0)$为常数，则称$X$服从参数为$ \mu , \sigma $的**正态分布或高斯分布**，记为$X \sim N( \mu ,  \sigma ^{2} )$。服从正态分布的随机变量称为**正态随机变量**。*连续型随机变量及其密度函数*部分给出的图即为正态分布的概率密度函数和分布函数。

* 离散型随机变量函数的分布

设$Y=g(X)$为离散型随机变量$X$的函数，则对$Y$的任一可能取值$y$，有，$P\{Y=y\}=P\{g(X)=y\}=P\{X \in\{x: g(x)=y\}\}$。一般的，若$X$是离散型随机变量，$X$的分布律为：

| $X$  |  $x_1$ | $x_2$  | $\cdots$  | $x_n$  | $\cdots$  |
|---|---|---|---|---|---|
| $p_k$  | $p_1$  | $p_2$  | $\cdots$   |  $p_n$ |  $\cdots$  |

则$Y=g(X)$的分布律为：

| $Y=g(X)$  |  $g(x_1)$ | $g(x_2)$  | $\cdots$  | $g(x_n)$  | $\cdots$  |
|---|---|---|---|---|---|
| $p_k$  | $p_1$  | $p_2$  | $\cdots$   |  $p_n$ |  $\cdots$  |

* 连续型随机变量函数的分布

设$X$是连续型随机变量，$y=g(x)$是连续函数，一般来说，Y=g(X)也是连续型随机变量，令$f_X(x), f_Y(y)$分布为$X,Y$的概率密度函数，$F_X(x), F_Y(y)$分别为$X,Y$的分布函数，则$F_Y(y)=P\{Y \leqslant y\}=P\{g(X) \leqslant y\}=P\{X \in\{x: g(x) \leqslant y\}\}$。利用$X$的分布函数求出的概率即得$Y$的分布函数；若求$Y$的概率密度函数$f_Y(y)$，只需对$F_Y(y)$求导。

## 3.5.3 多维随机变量及其分布

* 多维随机变量

定义 1：设有随机试验$E$，其样本空间为$\Omega$，若对$\Omega$中的每一个样本点$\omega$都有一对有序实数$(X(\omega),Y(\omega))$与其对应，则称$(X,Y)$为**二维随机变量或二维随机向量**，称$(X,Y)$的取值范围为它的值域，记为$\Omega_{(XY)}$。可以说二维随机变量$(X,Y)$是一个特殊的二元函数，其定义域为样本空间$\Omega$，值域$\Omega_{(X,Y)} \subset  R^{2} $。

例：现有一枚骰子相互独立地上抛两次的随机试验$E$，观察两次出现的点数，样本空间$\Omega$为如下计算结果`Omega`，总共36个样本点（两两组合的结果）。


```python
import itertools
from IPython.display import display, Latex
```


```python
Omega=list(itertools.product(range(1,7),range(1,7)))
print(len(Omega))
display(Latex(f'$\Omega$={Omega}'))
```

    36
    


$\Omega$=[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]


设随机变量$X$表示“第1次出现的点数”，随机变量$Y$表示“两次出现点数的最小值”，并设$\omega_i$为$\Omega$中的第$i$个样本点，则对应样本点定义域转化为随机变量对应的值域，计算结果为`XY`，如下打印了一一对应结果。


```python
XY=[(i[0],min(i)) for i in Omega]
i=1
for xy,omega in zip(XY,Omega):
    display(Latex(f'$\omega_{{{i}}}$={omega},$X(\omega_{{{i}}}),Y(\omega_{{{i}}})$={xy};'))    
    i+=1
```


$\omega_{1}$=(1, 1),$X(\omega_{1}),Y(\omega_{1})$=(1, 1);



$\omega_{2}$=(1, 2),$X(\omega_{2}),Y(\omega_{2})$=(1, 1);



$\omega_{3}$=(1, 3),$X(\omega_{3}),Y(\omega_{3})$=(1, 1);



$\omega_{4}$=(1, 4),$X(\omega_{4}),Y(\omega_{4})$=(1, 1);



$\omega_{5}$=(1, 5),$X(\omega_{5}),Y(\omega_{5})$=(1, 1);



$\omega_{6}$=(1, 6),$X(\omega_{6}),Y(\omega_{6})$=(1, 1);



$\omega_{7}$=(2, 1),$X(\omega_{7}),Y(\omega_{7})$=(2, 1);



$\omega_{8}$=(2, 2),$X(\omega_{8}),Y(\omega_{8})$=(2, 2);



$\omega_{9}$=(2, 3),$X(\omega_{9}),Y(\omega_{9})$=(2, 2);



$\omega_{10}$=(2, 4),$X(\omega_{10}),Y(\omega_{10})$=(2, 2);



$\omega_{11}$=(2, 5),$X(\omega_{11}),Y(\omega_{11})$=(2, 2);



$\omega_{12}$=(2, 6),$X(\omega_{12}),Y(\omega_{12})$=(2, 2);



$\omega_{13}$=(3, 1),$X(\omega_{13}),Y(\omega_{13})$=(3, 1);



$\omega_{14}$=(3, 2),$X(\omega_{14}),Y(\omega_{14})$=(3, 2);



$\omega_{15}$=(3, 3),$X(\omega_{15}),Y(\omega_{15})$=(3, 3);



$\omega_{16}$=(3, 4),$X(\omega_{16}),Y(\omega_{16})$=(3, 3);



$\omega_{17}$=(3, 5),$X(\omega_{17}),Y(\omega_{17})$=(3, 3);



$\omega_{18}$=(3, 6),$X(\omega_{18}),Y(\omega_{18})$=(3, 3);



$\omega_{19}$=(4, 1),$X(\omega_{19}),Y(\omega_{19})$=(4, 1);



$\omega_{20}$=(4, 2),$X(\omega_{20}),Y(\omega_{20})$=(4, 2);



$\omega_{21}$=(4, 3),$X(\omega_{21}),Y(\omega_{21})$=(4, 3);



$\omega_{22}$=(4, 4),$X(\omega_{22}),Y(\omega_{22})$=(4, 4);



$\omega_{23}$=(4, 5),$X(\omega_{23}),Y(\omega_{23})$=(4, 4);



$\omega_{24}$=(4, 6),$X(\omega_{24}),Y(\omega_{24})$=(4, 4);



$\omega_{25}$=(5, 1),$X(\omega_{25}),Y(\omega_{25})$=(5, 1);



$\omega_{26}$=(5, 2),$X(\omega_{26}),Y(\omega_{26})$=(5, 2);



$\omega_{27}$=(5, 3),$X(\omega_{27}),Y(\omega_{27})$=(5, 3);



$\omega_{28}$=(5, 4),$X(\omega_{28}),Y(\omega_{28})$=(5, 4);



$\omega_{29}$=(5, 5),$X(\omega_{29}),Y(\omega_{29})$=(5, 5);



$\omega_{30}$=(5, 6),$X(\omega_{30}),Y(\omega_{30})$=(5, 5);



$\omega_{31}$=(6, 1),$X(\omega_{31}),Y(\omega_{31})$=(6, 1);



$\omega_{32}$=(6, 2),$X(\omega_{32}),Y(\omega_{32})$=(6, 2);



$\omega_{33}$=(6, 3),$X(\omega_{33}),Y(\omega_{33})$=(6, 3);



$\omega_{34}$=(6, 4),$X(\omega_{34}),Y(\omega_{34})$=(6, 4);



$\omega_{35}$=(6, 5),$X(\omega_{35}),Y(\omega_{35})$=(6, 5);



$\omega_{36}$=(6, 6),$X(\omega_{36}),Y(\omega_{36})$=(6, 6);


上述对应样本点随机变量的值，存在重复值，将其转化为集合，仅保留唯一值，即为$(X,Y)$的值域，如下`Omega_XY`，总计有21个值。


```python
Omega_XY=set(XY)
print(len(Omega_XY))
display(Latex(f'$\Omega_{{X,Y}}$={Omega_XY}'))
```

    21
    


$\Omega_{X,Y}$={(4, 3), (3, 1), (5, 4), (5, 1), (2, 2), (6, 2), (6, 5), (4, 2), (3, 3), (5, 3), (2, 1), (6, 1), (6, 4), (3, 2), (4, 1), (5, 2), (4, 4), (5, 5), (1, 1), (6, 6), (6, 3)}


将二维随机变量的定义推广至$n$维，

定义 2：设有随机试验$E$，其样本空间为$\Omega$，若对$\Omega$中的每一个样本点$\omega$都有一组有序实数列$(X_1(\omega),X_2(\omega), \cdots ,X_n(\omega))$与其对应，则称$(X_1,X_2, \cdots ,X_n)$为$n$**维随机变量或**$n$**维随机向量**，称$(X_1,X_2, \cdots ,X_n)$的取值范围为它的**值域**，记为$ \Omega_{X_1,X_2, \cdots ,X_n}$。

* 联合分布函数

二维随机变量，$(X,Y)$的分布不仅要包含每个随机变量各自的信息，还要包含两者之间相互关系的信息，因此称它们的分布为联合分布。

定义 3：设$(X,Y)$为二维随机变量，对任意的$(x,y) \in R^2$，称$F(x, y)=P(X \leqslant x, Y \leqslant y)$为随机变量$(X,Y)$的**（联合）分布函数**。式中，$P(X \leqslant x, Y \leqslant y)$中的逗号表示对事件$\{X \leqslant x\}$和事件$\{Y \leqslant y\}$取积事件，$P(X \leqslant x, Y \leqslant y)=P\left(\{X \leqslant x\}: \cap\{Y \leqslant y\})=P\left((X, Y) \in D_{x y}\right) \right.$，式中$D_{xy}$区域如下图。联合分布函数描述了二维随机变量的统计规律，如果$(X,Y)$看作平面$x \bigcirc y$上随机点的坐标，那么其分布函数$F(x, y)$在$(x, y)$处的函数值就表示随机变量$(X,Y)$落在以点$(x,y)$为顶点且位于该点左下方的无穷矩形区域内$D_{xy}$的概率。

<img src="./imgs/3_5_a/3_5_A_03.jpg" height='auto' width=300 title="caDesign"> 

对于$n$维随机变量$\left(X_1, X_2, \cdots, X_n\right)$的联合分布概率的定义。

定义 4：设$\left(X_1, X_2, \cdots, X_n\right)$为$n$维随机变量，对任意的$\left(x_1, x_2, \cdots, x_n\right) \in R^n$，称$F\left(x_1, x_2, \cdots, x_n\right)=P\left(X_1 \leqslant x_1, \cdots, X_n \leqslant x_n\right)$为**随机变量**$\left(X_1, X_2, \cdots, X_n\right)$**的（联合）分布函数**。

联合分布函数具有如下性质，

定理 1（**联合分布函数的性质**）：设$F(x,y)$是二维随机变量$(X,Y)$的联合分布函数，则，

（1）$0 \leqslant F(x,y) \leqslant 1$；

（2）当固定$y$值时，$F(x,y)$是变量$x$的非减函数，当固定$x$值时，$F(x,y)$是变量$y$的非减函数；

（3）$\lim _{x \rightarrow-\infty} F(x, y)=0, \lim _{y \rightarrow-\infty} F(x, y)=0, \lim _{\substack{x \rightarrow-\infty \\ y \rightarrow-\infty}} F(x, y)=0, \lim _{\substack{x \rightarrow+\infty \\ y \rightarrow+\infty}} F(x, y)=1$；

（4）当固定$y$值时，$F(x,y)$是变量$x$的右连续函数，当固定$x$值时，$F(x,y)$是变量$y$的右连续函数；

（5）$P\left(x_1<X \leqslant x_2, y_1<Y \leqslant y_2\right)=F\left(x_2, y_2\right)-F\left(x_2, y_1\right)-F\left(x_1, y_2\right)+F\left(x_1, y_1\right)$。

> 除了性质（5）,其它4条性质都可以推广至高维随机变量的联合分布函数。

* 二维离散型随机变量及其联合分布律

定义 5：如何二维随机变量$(X,Y)$仅可能取有限个或可列无限个值，则称$(X,Y)$为**二维离散型随机变量**。

二维离散型随机变量$(X,Y)$的分布可用联合分布律表示。

定义 6：称$P\left(X=x_i, Y=y_j\right)=p_{i j}, i, j=1,2, \cdots$为二维随机变量$(X,Y)$的**联合分布律**，式中，$p_{i j} \geqslant 0, i, j=1,2, \cdots, \sum_i \sum_j p_{i j}=1$。

二维离散型随机变量$(X,Y)$的联合分布律可用表格发、公式法或图像法表示，其中最为简洁和常用的是表格法（Joint Distribution Table，联合分布表），如：

| $Y  \backslash  X$  | $x_1$  | $x_2$  | $\cdots$  |
|---|---|---|---|
|  $y_1$ | $p_{11}$  | $p_{21}$  | $\cdots$   |
| $y_2$  | $p_{12}$  |  $p_{22}$ |  $\cdots$  |
| $ \vdots $   |  $ \vdots $  |  $ \vdots $  |   |

例如，分析一个年级的成绩分布，定义随机变量$(X,Y)$为，$X =\begin{cases}1 & 数学为优,\\0 & 数学不为优.\end{cases} $，$Y =\begin{cases}1 & 语文为优,\\0 & 语文不为优.\end{cases} $。已知数学为优的占20%，语文为优的占10%，都为优的占8%，计算$(X,Y)$的联合分布律，已知$P(Y=1)=0.1, P(X=1)=0.2,P(X=1,Y=1)=0.08$，有$P(X=0,Y=1)=P(Y=1)-P(X=1,Y=1)=0.02$；$P(X=1,Y=0)=P(X=1)-P(X=1,Y=1)=0.12$。因为$ \sum_i \sum_j p_{i j}=1 $，所以$P(X=0,Y=0)=1-P(X=1,Y=1)-P(X=0,Y=1)-P(X=1,Y=0)=1-0.08-0.02-0.12=0.78$。

使用[datascience](https://github.com/data-8/datascience)<sup>①</sup>库的`Table()`方法，根据计算结果建立联合分布表`joint_dist`，计算结果如下。


```python
from datascience import *
from prob140 import *
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
plt.style.use('fivethirtyeight')
```


```python
k=np.arange(2)

def joint_probability(x,y):
    if x==0 and y==0: return 0.78
    elif x==0 and y==1: return 0.02
    elif x==1 and y==0: return 0.12
    elif x==1 and y==1: return 0.08

joint_dist=Table().values('X',k,'Y',k).probability_function(joint_probability)
joint_dist
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.02</td>
      <td>0.08</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.78</td>
      <td>0.12</td>
    </tr>
  </tbody>
</table>
</div>



计算概率$P(X \leqslant Y)=1-P(X>Y)=1-P(X=1,Y=0)=1-0.12=0.88$。使用定义的`joint_dist`联合分布表，定义随机变量的关系函数`indicator_equal`计算结果同。


```python
def indicator_equal(i, j):
    return i <= j  

joint_dist.event(indicator_equal, 'X', 'Y')
```

    P(Event) = 0.88
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.02</td>
      <td>0.08</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.78</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>



$(X,Y)$的值域为$\Omega_{(X,Y)}=\{(0,0),(0,1),(1,0),(1,1)\}$，由$F(x, y)=P(X \leqslant x, Y \leqslant y)$得联合分布函数为：$F(x, y)=\left\{\begin{array}{ll}0, & x<0 \text { 或 } y<0, \\ 0.78, & 0 \leqslant x<1,0 \leqslant y<1, \\ 0.8, & 0 \leqslant x<1, y \geqslant 1, \\ 0.9, & x \geqslant 1,0 \leqslant y<1, \\ 1, & x \geqslant 1, y \geqslant 1 .\end{array}\right.$。



对*多维随机变量*部分将一枚骰子相互独立地上抛两次的随机试验$E$，建立联合分布表（分布律）如下。


```python
import collections
import numpy as np

k=np.arange(1,7)

def joint_probability(i,j):
    n=len(XY)
    frequency=dict(collections.Counter(XY))
    if (i,j) in frequency.keys():
        return frequency[(i,j)]/n
    else:
        return 0

joint_dist=Table().values('X',k,'Y',k).probability_function(joint_probability)
joint_dist
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=1</th>
      <th>X=2</th>
      <th>X=3</th>
      <th>X=4</th>
      <th>X=5</th>
      <th>X=6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=6</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=5</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.055556</td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=4</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.083333</td>
      <td>0.027778</td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=3</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.111111</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=2</th>
      <td>0.000000</td>
      <td>0.138889</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.166667</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
      <td>0.027778</td>
    </tr>
  </tbody>
</table>
</div>



计算$P(X=Y)=\sum_{i=1}^6 P(X=i, Y=i)=\frac{6}{36}+\frac{5}{36}+\frac{4}{36}+\frac{3}{36}+\frac{2}{36}+\frac{1}{36}=\frac{7}{12}$，代码方法如下。


```python
joint_dist.event(lambda i,j:i==j, 'X', 'Y')
```

    P(Event) = 0.5833333333333334
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=1</th>
      <th>X=2</th>
      <th>X=3</th>
      <th>X=4</th>
      <th>X=5</th>
      <th>X=6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=6</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>0.027778</td>
    </tr>
    <tr>
      <th>Y=5</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>0.055556</td>
      <td></td>
    </tr>
    <tr>
      <th>Y=4</th>
      <td></td>
      <td></td>
      <td></td>
      <td>0.083333</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=3</th>
      <td></td>
      <td></td>
      <td>0.111111</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=2</th>
      <td></td>
      <td>0.138889</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.166667</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>



计算$P\left(X^2+Y^2<8\right)=P(X=1, Y=1)+P(X=2, Y=1)=\frac{7}{36}$，代码方法如下。


```python
joint_dist.event(lambda i,j:(pow(i,2)+pow(j,2))<8, 'X', 'Y')
```

    P(Event) = 0.19444444444444442
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=1</th>
      <th>X=2</th>
      <th>X=3</th>
      <th>X=4</th>
      <th>X=5</th>
      <th>X=6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=6</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=5</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=4</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=3</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=2</th>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.166667</td>
      <td>0.027778</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>



* 二维连续型随机变量及其联合密度函数

定义 7：设二维随机变量$(X,Y)$的联合分布函数为$F(x,y)$，如果存在一个二元非负实值函数$f(x,y)$，使得对于任意$(x,y) \in R^2$有$F(x, y)=\int_{-\infty}^x \int_{-\infty}^y f(u, v) \mathrm{d} u \mathrm{~d} v$成立，则称$(X,Y)$为**二维连续型随机变量**，$f(x,y)$为二维连续型随机变量$(X,Y)$的**联合（概率）密度函数**。式中，$\int_{-\infty}^x \int_{-\infty}^y f(u, v) \mathrm{d} u \mathrm{~d} v$表示二重积分$\iint_{D_{x y}} f(u, v) \mathrm{d} u \mathrm{~d} v$，其中积分区域$D_{x y}=(-\infty, x] \cdot(-\infty, y]$。

定义 8：设$n$维随机变量$\left(X_1, X_2, \cdots, X_n\right)$的联合分布函数为$F\left(x_1, x_2, \cdots, x_n\right)$，如果存在一个$n$元非负函数$f\left(x_1, x_2, \cdots, x_n\right)$，使得对任意的$\left(x_1, x_2, \cdots, x_n\right) \in R^n$有$F\left(x_1, x_2, \cdots, x_n\right)=\int_{-\infty}^{x_1} \cdots \int_{-\infty}^{x_n} f\left(u_1, u_2, \cdots, u_n\right) \mathrm{d} u_1 \mathrm{~d} u_2 \cdots \mathrm{d} u_n $ 成立，则称$\left(X_1, X_2, \cdots, X_n\right)$为$n$**维连续型随机变量**，$f\left(x_1, x_2, \cdots, x_n\right)$为$n$维连续型随机变量$\left(X_1, X_2, \cdots, X_n\right)$的**联合（概率）密度函数**。

二维连续型随机变量$(X,Y)$的联合密度函数有：

定理 2（**联合密度函数的性质**）：设$f(x,y)$为二维连续型随机变量$(X,Y)$的联合密度函数，则

(1) 非负性，$f(x, y) \geqslant 0,-\infty<x, y<+\infty$;

(2) 规范性 $\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x, y) \mathrm{d} x \mathrm{~d} y=1$。

联合密度函数的规范性意味着以曲面$f(x,y)$为顶，以整个$x \bigcirc y$平面与$\Omega_{X,Y}$的交集区域为底的曲顶柱体的体积为1。如下图，其联合密度函数为$f(x, y)=\left\{\begin{array}{rr}120 x(y-x)(1-y), \quad 0<x<y<1 \\ 0 \quad & \text { otherwise }\end{array}\right. $，有$\int_0^1 \int_0^y 120 x(y-x)(1-y) d x d y \\  =120 \int_0^1(1-y)\left(\int_0^y\left(x y-x^2\right) d x\right) d y \\  =20 \int_0^1(1-y) y^3 d y=20\left(\frac{1}{4}-\frac{1}{5}\right)=1$。

使用[SimPy](https://docs.sympy.org/latest/modules/integrals/integrals.html)<sup>②</sup>和[datascience](https://github.com/data-8/datascience)<sup>①</sup>库定义二维连续型随机变量的联合密度函数并打印显示。


```python
from sympy import Symbol,Integral
import numpy as np 
import matplotlib.pyplot as plt
```


```python
def joint(x,y):
    if y < x:
        return 0
    else:
        return 120 * x * (y-x) * (1-y)
    
Plot_3d(x_limits=(0,1), y_limits=(0,1), f=joint, cstride=4, rstride=4,interactive=True)    
```


<img src="./imgs/3_5_a/3_5_a_04.jpg" height='auto' width='auto' title="caDesign">


```python
x = Symbol('x', positive=True)
y = Symbol('y', positive=True)

f = 120*x*(y-x)*(1-y)
f
```




$\displaystyle 120 x \left(1 - y\right) \left(- x + y\right)$



使用`Integral`方法定义二重积分。


```python
F_XY=Integral(f, (x, 0, y), (y, 0, 1))
F_XY
```




$\displaystyle \int\limits_{0}^{1}\int\limits_{0}^{y} 120 x \left(1 - y\right) \left(- x + y\right)\, dx\, dy$



`doit()`方法估计该二重积分的结果为1。


```python
F_XY.doit()
```




$\displaystyle 1$



为了方便观察随机变量$(X,Y)$的数值区间，以平面形式表述。


```python
coords=np.arange(0,1+0.1,0.1)
pts_y=[[0,i] for i in coords]
pts_x=[[i,i] for i in coords]
pts_x.reverse()
pts=np.array(pts_y+pts_x)

plt.figure(figsize=(3,3))
t=plt.Polygon(pts, color='gray')
plt.gca().add_patch(t)

plt.xlabel("$x$")
plt.ylabel("$y$")
plt.xticks(fontsize=10);plt.yticks(fontsize=10)
plt.show()
```


<img src="./imgs/3_5_a/output_64_0.png" height='auto' width='auto' title="caDesign">    


计算概率$\begin{aligned} P(Y>4 X) & =\int_0^1 \int_0^{y / 4} 120 x(y-x)(1-y) d x d y \\ & =120 \int_0^1(1-y)\left(\int_0^{y / 4}\left(x y-x^2\right) d x\right) d y \\ & =120\left(\frac{1}{32}-\frac{1}{192}\right) \int_0^1(1-y) y^3 d y \\ & =120\left(\frac{1}{32}-\frac{1}{192}\right) \cdot \frac{1}{20}=0.15625\end{aligned}$，代码计算如下。


```python
pts_x_d1=[[i/4,i] for i in coords]
pts_x_d1.reverse()
pts_d1=np.array(pts_y+pts_x_d1)

plt.figure(figsize=(3,3))
t=plt.Polygon(pts, color='gray')
plt.gca().add_patch(t)

t1=plt.Polygon(pts_d1,color='g')
plt.gca().add_patch(t1)

plt.xlabel("$x$")
plt.ylabel("$y$")
plt.xticks(fontsize=10);plt.yticks(fontsize=10)
plt.show()
```


<img src="./imgs/3_5_a/output_66_0.png" height='auto' width='auto' title="caDesign">    



```python
f_1=Integral(f, (x, 0, y/4), (y, 0, 1))
f_1
```




$\displaystyle \int\limits_{0}^{1}\int\limits_{0}^{\frac{y}{4}} 120 x \left(1 - y\right) \left(- x + y\right)\, dx\, dy$




```python
f_1.doit()
```




$\displaystyle \frac{5}{32}$



计算概率$P(X>0.25, Y>0.5)=\int_{0.5}^1 \int_{0.25}^y 120 x(y-x)(1-y) d x d y$，代码计算如下。


```python
coords_d2=[i for i in coords if i>=0.5]
pts_y_d2=[[0.25,i] for i in coords_d2]

pts_x_d2=[[i,i] for i in coords_d2 if i >=0.25]
pts_x_d2.reverse()
pts_d2=np.array(pts_y_d2+pts_x_d2)

plt.figure(figsize=(3,3))
t=plt.Polygon(pts, color='gray')
plt.gca().add_patch(t)

t2=plt.Polygon(pts_d2,color='g')
plt.gca().add_patch(t2)

plt.xlabel("$x$")
plt.ylabel("$y$")
plt.xticks(fontsize=10);plt.yticks(fontsize=10)
plt.show()
```


<img src="./imgs/3_5_a/output_70_0.png" height='auto' width='auto' title="caDesign">    


```python
f_2=Integral(f, (x, 0.25, y), (y, 0.5, 1))
f_2
```




$\displaystyle \int\limits_{0.5}^{1}\int\limits_{0.25}^{y} 120 x \left(1 - y\right) \left(- x + y\right)\, dx\, dy$




```python
f_2.doit()
```




$\displaystyle 0.578125$



* 常用的多维随机变量

1）二维均匀分布

设二维随机变量$(X,Y)$的联合密度函数为$f(x, y)=\left\{\begin{array}{l}\frac{1}{S_G}, \quad(x, y) \in G, \\ 0, \quad \text { 其他. }\end{array}\right.$，式中，$G$是$x \bigcirc y$平面上的某个区域，$S_G$为$G$的面积，则称$(X,Y)$服从区域$G$上的**二维均匀分布**。

2）二维正态分布$N(\mu_1, \mu_2, \sigma_1^2,\sigma_2^2,\rho)$

如果$(X,Y)$的联合密度函数为$f(x, y)=\frac{1}{2 \pi \sigma_1 \sigma_2 \sqrt{1-\rho^2}} \exp \left\{-\frac{1}{2\left(1-\rho^2\right)}\left[\frac{\left(x-\mu_1\right)^2}{\sigma_1^2}-2 \rho \frac{\left(x-\mu_1\right)\left(y-\mu_2\right)}{\sigma_1 \sigma_2}+\frac{\left(y-\mu_2\right)^2}{\sigma_2^2}\right]\right\},-\infty<x, y<+\infty$，则称$(X,Y)$服从**二维正态分布**，并记为$(X, Y) \sim N\left(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho)\right.$，式中，$- \infty <\mu_1, \mu_2<+ \infty , \sigma_1\sigma_2>0, \mid \rho \mid<1 $。

二维正态分布的联合密度函数图像如下。


```python
def joint(x,y,mu1=0.5,mu2=0.5,sig1=0.15,sig2=0.15,rho=0.1):
    return 1/(2*np.pi*sig1*sig2*np.sqrt(1-rho**2))*np.exp(-1/(2*(1-rho**2))
                                                          *(((x-mu1)**2/sig1**2) 
                                                          - 2*rho*(x-mu1)*(y-mu2)/(sig1*sig2) 
                                                          + (y-mu2)**2/sig2**2))
    
Plot_3d(x_limits=(0,1), y_limits=(0,1), f=joint, cstride=4, rstride=4,interactive=True) 
```


<img src="./imgs/3_5_a/3_5_a_05.jpg" height='auto' width='auto' title="caDesign">


* 边缘分布

二维随机变量$(X,Y)$中，$X$和$Y$也都是随机变量，分别有各自的概率分布，称$X$和$Y$的概率分布为二维随机变量$(X,Y)$关于$X$和关于$Y$的**边缘概率分布**，简称**边缘分布**。

定义 1：设二维随机变量$(X,Y)$的联合分布函数为$F(x,y)$，称$F_X(x)=P(X \leqslant x)=P(X \leqslant x, Y \leqslant+\infty)=F(x,+\infty),-\infty<x<+\infty$为**随机变量**$X$**的边缘分布函数**；称$ F_Y(y)=P(Y \leqslant y)=P(X \leqslant+\infty, Y \leqslant y)=F(+\infty, y),-\infty<y<+\infty$为**随机变量**$Y$**的边缘分布函数**。

定义 2：设二维离散型随机变量$(X,Y)$的联合分布律为$P\left(X=x_i, Y=y_j\right)=p_{i j}, i, j=1,2, \cdots$，称概率$P\left(X=x_i\right)=P\left(X=x_i, \cup_j Y=y_j\right)=\sum_j P\left(X=x_i, Y=y_j\right)=\sum_j p_{i j}, \quad i=1,2, \cdots $为**随机变量**$X$**的边缘分布律**，记为$p_i .$，并有$p_i .=P\left(X=x_i\right)=\sum_j p_{i j}, i=1,2, \cdots$；类似，称概率$P\left(Y=y_j\right), j=1,2, \cdots$为**随机变量**$Y$**的边缘分布律**，记为$P_{\cdot j}$，并有$ P_{\cdot j}=P\left(Y=y_j\right)=\sum_i p_{i j}, j=1,2, \cdots$。即，求$X$的边缘分布律为求$(X,Y)$联合分布律表格中的列（或行）和，求$Y$的边缘分布律为求$(X,Y)$联合分布律表格中的行（或列）和。因为边缘分布律位于联合分布律表格的边缘，因此称其为边缘分布律。

下面计算了前文关于一个年级数学和语文成绩分布的联合分布表及其边缘分布律。


```python
from sympy import Symbol,Integral
import numpy as np 
import matplotlib.pyplot as plt
import matplotlib
import pandas as pd
from fractions import Fraction
```


```python
k=np.arange(2)

def joint_probability(x,y):
    if x==0 and y==0: return 0.78
    elif x==0 and y==1: return 0.02
    elif x==1 and y==0: return 0.12
    elif x==1 and y==1: return 0.08

joint_table=Table().values('X',k,'Y',k).probability_function(joint_probability)
joint_table.both_marginals() 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>Sum: Marginal of Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.02</td>
      <td>0.08</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.78</td>
      <td>0.12</td>
      <td>0.9</td>
    </tr>
    <tr>
      <th>Sum: Marginal of X</th>
      <td>0.80</td>
      <td>0.20</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
joint_table.marginal('Y')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>Sum: Marginal of Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.02</td>
      <td>0.08</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.78</td>
      <td>0.12</td>
      <td>0.9</td>
    </tr>
  </tbody>
</table>
</div>




```python
joint_table.marginal('X')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.02</td>
      <td>0.08</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.78</td>
      <td>0.12</td>
    </tr>
    <tr>
      <th>Sum: Marginal of X</th>
      <td>0.80</td>
      <td>0.20</td>
    </tr>
  </tbody>
</table>
</div>



定义 3：设二维连续型随机变量$X,Y$的联合分布函数为$F(x,y)$，联合密度函数为$f(x,y)$，根据$F_X(x)=F(x,+\infty),-\infty<x<+\infty$，得$\int_{-\infty}^x f_X(u) \mathrm{d} u=\int_{-\infty}^x\left[\int_{-\infty}^{+\infty} f(u, y) \mathrm{d} y\right] \mathrm{d} u$，所以$X$**的边缘密度函数**为$f_X(x)=\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} y$；类似，$Y$**的边缘密度函数**为$f_Y(y)=\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} x$。

例如，定义二维连续型随机变量的联合密度函数$f(x, y)=\left\{\begin{array}{l}30(y-x)^4, \quad 0<x<y<1 \\ 0 \quad \text { otherwise }\end{array}\right.$，绘制图形如下。


```python
def jt_dens(x,y):
    if y < x:
        return 0
    else:
        return 30 * (y-x)**4

Plot_3d(x_limits=(0,1), y_limits=(0,1), f=jt_dens, cstride=4, rstride=4,interactive=True)
```


<img src="./imgs/3_5_a/3_5_a_06.jpg" height='auto' width='auto' title="caDesign">


联合密度函数的二重积分定义为变量`jt_dens_pdf`。


```python
x = Symbol('x', positive=True)
y = Symbol('y', positive=True)

joint_density = 30*(y-x)**4
jt_dens_pdf=Integral(joint_density, (y, x, 1), (x, 0, 1))
jt_dens_pdf
```




$\displaystyle \int\limits_{0}^{1}\int\limits_{x}^{1} 30 \left(- x + y\right)^{4}\, dy\, dx$



估计二重积分的结果为1。


```python
jt_dens_pdf.doit()
```




$\displaystyle 1$



下图表述了$x$约为0.25时，事件$X \in dx$的概率$P(X \in dx)$，为固定$x$，沿$y$的积分。


```python
coords=np.arange(0,1+0.1,0.1)
pts_y=[[0,i] for i in coords]
pts_x=[[i,i] for i in coords]
pts_x.reverse()
pts=np.array(pts_y+pts_x)

plt.figure(figsize=(3,3))
t=plt.Polygon(pts, color='gray')
plt.gca().add_patch(t)

plt.vlines(x=0.25,ymin=0.25,ymax =1, linewidth=3, color='green',linestyles='-')

plt.xlabel("$x$")
plt.ylabel("$y$")
plt.xticks(fontsize=10);plt.yticks(fontsize=10)
plt.show()
```

<img src="./imgs/3_5_a/output_87_0.png" height='auto' width='auto' title="caDesign">


计算$X$的边缘密度函数$f_X(x)=\int_x^1 30(y-x)^4 d y \\  =\left.30 \cdot \frac{1}{5}(y-x)^5\right|_x ^1 \\  =6(1-x)^5$；计算$Y$的边缘密度函数$f_Y(y)=\int_0^y 30(y-x)^4 d x=6 y^5 $。下面打印了两者的边缘密度函数曲线。


```python
import matplotlib as mpl
mpl.rcParams.update(mpl.rcParamsDefault)

def marginal_density_X(x):
    return 6*(1-x)**5

def marginal_density_Y(y):
    return 6*y**5

plt.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False

fig, axs=plt.subplots(1, 2,figsize=(10,5))
x=np.arange(0,1+0.1,0.1)

axs[0].plot(x, marginal_density_X(x),'b-', lw=5, alpha=0.6)
axs[1].plot(x, marginal_density_Y(x),'r-', lw=5, alpha=0.6)

axs[0].set_title("$f_{X}$:Density of $X$")
axs[1].set_title("$f_{Y}$:Density of $Y$")


axs[0].set_xlabel("$x$")
axs[0].set_ylabel("$f_{X}(X)$")
axs[1].set_xlabel("$y$")
axs[1].set_ylabel("$f_{Y}(Y)$")
plot_style(axs[0])
plot_style(axs[1])
fig.tight_layout()
plt.show()
```

<img src="./imgs/3_5_a/output_89_0.png" height='auto' width='auto' title="caDesign">
    


定理 1：如果$(X, Y) \sim N\left(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho\right) $，则$X \sim N\left(\mu_1, \sigma_1^2\right), Y \sim N\left(\mu_2, \sigma_2^2\right)$。

* 条件分布

对于二维随机变量$(X,Y)$中的两个随机变量$X$和$Y$，在许多问题中它们的取值往往彼此影响，这使得条件分布成为研究变量之间相依关系的有利工具。对于二维随机变量$(X,Y)$，随机变量$X$的条件分布是在给定$Y$取某个值条件下$X$的分布。

1）二维离散型随机变量的条件分布律

定义 1：设二维离散型随机变量$(X,Y)$的联合分布律为$P\left(X=x_i, Y=y_j\right)=p_{i j}, i, j=1,2, \cdots$，对于固定的$y_i \in \Omega_Y$，记在给定条件$\{Y=y_j\}$下的随机变量$X$为$X \mid Y=y_j$，其值域记为$\Omega_{X \mid Y=y_j}=\left\{x_i: P\left(X=x_i, Y=y_j\right) \neq 0\left(y_j \text { 固定 }\right), i=1,2, \cdots\right\}$。条件分布律$\frac{p_{i j}}{p_{\cdot j}}, i=1,2, \cdots$满足分布律的两条性质：

（1）$P\left(X=x_i \mid Y=y_j\right)=\frac{p_{i j}}{p_{\cdot j}}>0, x_i \in \Omega_X \mid Y=y_j$；

（2）$\sum_i P\left(X=x_i \mid Y=y_j\right)=\sum_i \frac{p_{i j}}{p_{\cdot j}}=1$.

当$x \in \Omega_X$时，在给定条件$\{X=x_j\}$下的随机变量$Y$的条件分布律为$P\left(Y=y_j \mid X=x_i\right)=\frac{p_{i j}}{p_i \cdot}, j=1,2, \cdots $。对于固定的$x_i \in \Omega_X$，记在给定条件$\{X=x_i\}$下的随机变量$Y$为$Y \mid X=x_i$，其值域为$\Omega_{Y \mid X=x_i}=\left\{y_j: P\left(X=x_i, Y=y_j\right) \neq 0\left(x_i\right.\right.$ 固定 $\left.), j=1,2, \cdots\right\}$。同理，条件分布律$\frac{p_{i j}}{p_i \cdot}, j=1,2, \cdots$也满足分布律的两条性质。

定义一个二维离散型随机变量的条件分布律表格`joint_table`，如下。


```python
k = np.arange(3)
arr=np.array([[Fraction(1,18),Fraction(2,9),Fraction(1,18)],[Fraction(2,15),Fraction(2,15),Fraction(1,15)],[Fraction(1,6),Fraction(1,9),Fraction(1,18)]])
print(pd.DataFrame(arr))

def joint_probability(x, y):
    return (arr[x,y])

joint_table=Table().values('X', k, 'Y', k).probability_function(joint_probability)
print(f'total probability={joint_dist.total_probability()}')
joint_table
```

          0     1     2
    0  1/18   2/9  1/18
    1  2/15  2/15  1/15
    2   1/6   1/9  1/18
    total probability=1.0
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>X=2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=2</th>
      <td>0.055556</td>
      <td>0.066667</td>
      <td>0.055556</td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.222222</td>
      <td>0.133333</td>
      <td>0.111111</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.055556</td>
      <td>0.133333</td>
      <td>0.166667</td>
    </tr>
  </tbody>
</table>
</div>



计算随机变量$X$和$Y$的边缘分布律。


```python
joint_table.both_marginals()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>X=2</th>
      <th>Sum: Marginal of Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=2</th>
      <td>0.055556</td>
      <td>0.066667</td>
      <td>0.055556</td>
      <td>0.177778</td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.222222</td>
      <td>0.133333</td>
      <td>0.111111</td>
      <td>0.466667</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.055556</td>
      <td>0.133333</td>
      <td>0.166667</td>
      <td>0.355556</td>
    </tr>
    <tr>
      <th>Sum: Marginal of X</th>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



假设知道$Y=1$，则提取满足条件的行，可知该行和的概率为$P(Y=3)=0.466$，并不为1。由$P(X=x \mid Y=1)=\frac{P(X=x, Y=1)}{P(Y=1)}$，计算给定条件$Y=1$时$X$的条件分布为，$P(X=0 \mid Y=3)=\frac{0.222}{0.466}=0.476 \\  P(X=1 \mid Y=3)=\frac{0.133}{0.466}=0.285 \\  P(X=2 \mid Y=3)=\frac{0.111}{0.466}=0.238$。可以直接调用`conditional_dist`方法计算。


```python
def indicator_Y_equals_1(i, j):
    return j==1

joint_table.event(indicator_Y_equals_1, 'X', 'Y')
```

    P(Event) = 0.4666666666666666
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>X=2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=2</th>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.222222</td>
      <td>0.133333</td>
      <td>0.111111</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>



以$Y$为条件计算$X$的条件分布律。 


```python
joint_table.conditional_dist('X', 'Y') # conditional distribution of X given each different value of Y
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>X=2</th>
      <th>Sum</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dist. of X | Y=2</th>
      <td>0.312500</td>
      <td>0.375000</td>
      <td>0.312500</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Dist. of X | Y=1</th>
      <td>0.476190</td>
      <td>0.285714</td>
      <td>0.238095</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Dist. of X | Y=0</th>
      <td>0.156250</td>
      <td>0.375000</td>
      <td>0.468750</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Marginal of X</th>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



以$X$为条件计算$Y$的条件分布律。


```python
joint_table.conditional_dist('Y', 'X') # conditional distribution of Y given each different value of X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dist. of Y | X=0</th>
      <th>Dist. of Y | X=1</th>
      <th>Dist. of Y | X=2</th>
      <th>Marginal of Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=2</th>
      <td>0.166667</td>
      <td>0.2</td>
      <td>0.166667</td>
      <td>0.177778</td>
    </tr>
    <tr>
      <th>Y=1</th>
      <td>0.666667</td>
      <td>0.4</td>
      <td>0.333333</td>
      <td>0.466667</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.166667</td>
      <td>0.4</td>
      <td>0.500000</td>
      <td>0.355556</td>
    </tr>
    <tr>
      <th>Sum</th>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



2）二维连续型随机变量的条件密度函数

定义 2：设$f(x,y)$为二维连续型随机变量$(X,Y)$的联合密度函数，当$y \in \Omega_Y$时，在给定$\{Y=y\}$条件下$X$的条件密度函数为$f_{X \mid Y}(x \mid y)=\frac{f(x, y)}{f_Y(y)},-\infty<x<+\infty \text {, 其中 } f_Y(y)>0$。对于固定的$y \in \Omega_Y$，记在给定条件$\{Y=y\}$下的随机变量$X$为$X \mid Y=y$，其值域记为$\Omega_{X \mid Y=y}=\{x: f(x, y) \neq 0(y$ 固定 $)\}$。条件密度函数$f_{X \mid Y}(x \mid y)$满足密度函数的两条性质：

（1）$f_{X \mid Y}(x \mid y)=\frac{f(x, y)}{f_Y(y)}>0, x \in \Omega_X \mid Y=y$；

（2）$\int_{-\infty}^{+\infty} f_{X \mid Y}(x \mid y) \mathrm{d} x=\int_{-\infty}^{+\infty} \frac{f(x, y)}{f_Y(y)} \mathrm{d} x=\frac{\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} x}{f_Y(y)}=1$。

当$x \in \Omega_X$时，在给定$X=x$条件下$Y$的条件密度函数为$f_{Y \mid X}(y \mid x)=\frac{f(x, y)}{f_X(x)},-\infty<y<+\infty \text {, 其中 } f_X(x)>0$。对于固定的$x \in \Omega_X$，记在给定条件$\{X=x\}$下的随机变量$Y$为$Y \mid X=x$，其值域记为$\Omega_{Y \mid X=x}=\{y: f(x, y) \neq 0(x$ 固定 $)\}$。同理，可以验证$f_{Y \mid X}(y \mid x)$满足密度函数的两条性质。

定义 3：设$f(x,y)$为二维连续型随机变量$(X,Y)$的联合密度函数，当$y \in \Omega_Y$时，在给定条件$\{Y=y\}$下$X$的条件分布函数为$F_{X \mid Y}(x \mid y)=\int_{-\infty}^x f_{X \mid Y}(u \mid y) \mathrm{d} u=\int_{-\infty}^x \frac{f(u, y)}{f_Y(y)} \mathrm{d} u,-\infty<x<+\infty \text {, 其中 } f_Y(y)>0$；当$x \in \Omega_X$时，在给定$\{X=x\}$条件下$Y$的条件分布函数为$F_{Y \mid X}(y \mid x)=\int_{-\infty}^y f_{Y \mid X}(v \mid x) \mathrm{d} v=\int_{-\infty}^y \frac{f(x, v)}{f_X(x)} \mathrm{d} v, \quad-\infty<y<+\infty$, 其中 $f_X(x)>0$。

继续*边缘分布：二维连续型随机变量的联合密度函数*部分的案例，给定条件$X=0.4$时，$Y$的条件密度函数为$f_{Y \mid X=0.4}(y)=\frac{30(y-0.4)^4}{6(1-0.4)^5}=\frac{5}{0.6^5}(y-0.4)^4 \quad y \in(0.4,1)$。同时绘制$Y$的边缘密度函数$f_Y(y)$和条件密度函数$f_{Y \mid X=0.4}(y)$，如下。


```python
y=Symbol('y', positive=True)
conditional_density_Y_given_X_is_04=(5/(0.6**5)) * (y - 0.4)**4
Integral(conditional_density_Y_given_X_is_04, (y, 0.4, 1)).doit()
```




$\displaystyle 0.999999999999999$




```python
def conditional_density_Y_given_X_is_04_func(y):
    return 5/0.6**5*(y-0.4)**4

def marginal_density_Y(y):
    return 6*y**5

fig, ax=plt.subplots(1, 1,figsize=(5,5))
x=np.arange(0,1+0.05,0.05)
x_c=np.array([i for i in x if i>=0.4])

ax.plot(x, marginal_density_Y(x),'r-', lw=5, alpha=0.6,label="Density of Y")
ax.plot(x_c, conditional_density_Y_given_X_is_04_func(x_c),'k-', lw=5, alpha=0.6,label="Density of Y given X=0.4")

ax.set_xlabel("$y$")
ax.set_ylabel("$P(Y)$")
plot_style(ax)
ax.legend(loc='upper center')
fig.tight_layout()
plt.show()
```


<img src="./imgs/3_5_a/output_103_0.png" height='auto' width='auto' title="caDesign">    
    


由条件密度函数$f_{Y \mid X=0.4}(y)$可以计算条件概率（probabilities）和条件期望（expectations），例如$P(Y>0.9 \mid X=0.4)=\int_{0.9}^1 \frac{5}{0.6^5}(y-0.4)^4 d y$。


```python
p_1=Integral(conditional_density_Y_given_X_is_04, (y, 0.9, 1))
print(p_1.doit())
p_1
```

    0.598122427983537
    




$\displaystyle \int\limits_{0.9}^{1} 64.3004115226338 \left(y - 0.4\right)^{4}\, dy$



由条件密度函数计算条件期望值，$E(Y \mid X=0.4)=\int_{0.4}^1 y \frac{5}{0.6^5}(y-0.4)^4 d y=0.9$。


```python
Integral(y*conditional_density_Y_given_X_is_04, (y, 0.4, 1)).doit()
```




$\displaystyle 0.899999999999998$



* 随机变量的独立性

当两个随机变量的取值规律互不影响时，称它们是相互独立的。

定义 4：设$(X,Y)$为二维随机变量，若对任意$x,y \in R$，都有$F(x, y)=F_X(x) F_Y(y)$成立，则称**随机变量**$X$**与**$Y$**相互独立**。式中，$F(x, y)$为$(X,Y)$的联合分布函数，$F_X(x)$和$ F_Y(y)$分别为$X$和$Y$的边缘分布函数。

定理 2：设计$(X,Y)$为二维离散型随机变量，那么，$X$与$Y$相互独立的充分必要条件是对任意的$i,j=1,2,\cdots$，都有$p_{i j}=p_{i \cdot} p_{\cdot j}$成立，式中，$p_{i j}, i, j=1,2, \cdots$为$(X,Y)$的联合分布律，$p_{i \cdot}, i=1,2, \cdots$和$p_{\cdot j}, j=1,2, \cdots$分别为$X$和$Y$的边缘分布律。相互独立性的直观含义是当$X$取定$x_i$时，$Y$的取值规律不受任何影响，即$P\left(Y=y_j \mid X=x_i\right)=\frac{P\left(X=x_i, Y=y_j\right)}{P\left(X=x_i\right)}=\frac{p_{i j}}{p_i .}=\frac{p_{i \cdot} p_{\cdot j}}{p_i .}=p_{\cdot _j}=P\left(Y=y_j\right)$

例如下述二维随机变量$(X,Y)$中$X$和$Y$相互独立，可以验证$i,j=1,2$都有$p_{i j}=p_{i \cdot} p_{\cdot j}$成立。


```python
k=np.arange(2)

def joint_probability(x,y):
    if x==0:return 0.4
    if x==1: return 0.1

joint_table=Table().values('X',k,'Y',k).probability_function(joint_probability)
joint_table.both_marginals() 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X=0</th>
      <th>X=1</th>
      <th>Sum: Marginal of Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Y=1</th>
      <td>0.4</td>
      <td>0.1</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Y=0</th>
      <td>0.4</td>
      <td>0.1</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Sum: Marginal of X</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



定理 3：若$(X,Y)$为二维连续型随机变量，那么，$X$与$Y$相互独立的充分必要条件是在$f(x,y)$、$f_X(x)$及$f_Y(y)$的一切公共连续点上都有$f(x, y)=f_X(x) \cdot f_Y(y)$成立。式中，$f(x, y)$为$(X,Y)$的联合密度函数，$f_X(x) $和$ f_Y(y)$为$X$和$Y$的边缘密度函数。

定义 5：设$\left(X_1, X_2, \cdots, X_n\right)$为$n$维随机变量，若对任意$\left(x_1, x_2, \cdots, x_n\right) \in R^n$，都有$F\left(x_1, x_2, \cdots, x_n\right)=\prod_{i=1}^n F_{X_i}\left(x_i\right) $成立，则称**随机变量**$X_1, X_2, \cdots, X_n$**相互独立**。式中，$F\left(x_1, x_2, \cdots, x_n\right)$为$\left(X_1, X_2, \cdots, X_n\right)$的联合分布函数，$ F_{X_i}\left(x_i\right)$为$X_i$的边缘分布函数，$i=1,2, \cdots,n$。

当$\left(X_1, X_2, \cdots, X_n\right)$为离散型随机变量时，随机变量$X_1, X_2, \cdots, X_n$相互独立的充要条件是对任意的$x_i \in \Omega_{X_i}, \quad i=1,2, \cdots, n$，都有，$P\left(X_1=x_1, X_2=x_2, \cdots, X_n=x_n\right)=\prod_{i=1}^n P\left(X_i=x_i\right)$成立，式中，$P\left(X_1=x_1, X_2=x_2, \cdots, X_n \right)$为$\left(X_1, X_2, \cdots, X_n\right)$的联合分布律，$P\left(X_i=x_i\right)$为$X_i$的边缘分布律，$i=1,2, \cdots,n$。

当$\left(X_1, X_2, \cdots, X_n\right)$为连续型随机变量时，随机变量$X_1, X_2, \cdots, X_n$相互独立的充要条件是在$f\left(x_1, x_2, \cdots, x_n\right), f_{X_1}\left(x_1\right), f_{X_2}\left(x_2\right), \cdots, f_{X_n}\left(x_n\right)$的一切公共连续点上都有$f\left(x_1, x_2, \cdots, x_n\right)=\prod_{i=1}^n f_{X_i}\left(x_i\right)$成立。式中，$f\left(x_1, x_2, \cdots, x_n\right)$为$\left(X_1, X_2, \cdots, X_n\right)$的联合密度函数，$f_{X_i}\left(x_i\right)$为$X_i$的边缘密度函数，$i=1,2, \cdots,n$。

* 二维随机变量函数的分布

设$(X,Y)$为二维随机变量，则$Z=g(X,Y)$是$(X,Y)$的函数，且$Z$是一维随机变量。如果要由$(X,Y)$的分布求$Z$的分布，一般要将$Z$的分布转化成有关$(X,Y)$的概率分布。

1）二维离散型随机变量函数的分布

设$(X,Y)$是二维离散型随机变量，其分布律为$P\left\{X=x_i, Y=y_j\right\}=p_{i j}, \quad i, j=1,2, \cdots$，$Z=g(X,Y)$是$(X,Y)$的函数，则$Z$也是离散型随机变量，其分布律为$P\left\{Z=z_k\right\}=P\left\{g(X, Y)=z_k\right\}=\sum_{\left\{\left(x_i, y_j\right)\left|g\left(x_i, y_j\right)=z_k\right\rangle\right.} P\left\{X=x_i, Y=y_j\right\} \\ =\sum_{\left\{\left(x_i, y_j\right) \mid g\left(x_i, y_j\right)=z_k\right\}} p_{i j}, \quad k=1,2, \cdots$。

定理 1：设$X \sim B(m, p), Y \sim B(n, p)$，且$X$与$Y$相互独立，则$X+Y \sim B(m+n, p)$；设$X \sim P\left(\lambda_1\right), Y \sim P\left(\lambda_2\right)$，且$X$与$Y$相互独立，则$X+Y \sim P\left(\lambda_1+\lambda_2\right)$。

2）二维连续型随机变量函数的分布

设二维连续型随机变量$(X,Y)$的联合密度函数为$f(x,y)$，则随机变量$(X,Y)$的二元函数$Z=g(X,Y)$的分布函数为$F_Z(z)=P(Z \leqslant z)=P(g(X, Y) \leqslant z)=P\left((X, Y) \in D_z\right)=\iint_{D_z} f(x, y) \mathrm{d} x \mathrm{~d} y$，式中，$\{(X,Y) \in D_z\}$是与$\{g(X,Y) \leqslant z \}$等价的随机事件，而$D_z=\{(x,y):g(x,y)  \leqslant z\}$是$x \bigcirc y$平面上的点集（通常是一个区域或若干个区域的并集）。则$Z=g(X,Y)$的密度函数为$f_Z(z)=F' _Z(z)$。这种计算二维连续型随机变量函数分布的方法称为分布函数法。

定理 2：设随机变量$(X,Y)$的联合密度函数为$f(x,y)$，且$X$的边缘密度函数为$f_X(x)$，$Y$的边缘密度函数为$f_Y(y)$，则随机变量$(X,Y)$的函数$Z=X+Y$的密度函数为$f_Z(z)=\int_{-\infty}^{+\infty} f(x, z-x) \mathrm{d} x \text { 或 } f_Z(z)=\int_{-\infty}^{+\infty} f(z-y, y) \mathrm{d} y$。特别地，当随机变量$X$和$Y$相互独立时，$f_Z(z)=\int_{-\infty}^{+\infty} f_X(x) f_Y(z-x) \mathrm{d} x \text { 或 } f_Z(z)=\int_{-\infty}^{+\infty} f_X(z-y) f_Y(y) \mathrm{d} y$。这两个公式称为**卷积公式**。在概率论中计算相互独立随机变量之和分布的运算称为卷积运算。

定理 3：设$X \sim N\left(\mu_1, \sigma_1^2\right), \quad Y \sim N\left(\mu_2, \sigma_2^2\right)$，且$X$与$Y$相互独立，则$X+Y \sim N\left(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2\right)$。

定理 4：设连续型随机变量$X$和$Y$相互独立，且$X$的分布函数为$F_X(x)$，$Y$的分布函数为$F_Y(y)$，则

（1）随机变量$U=\max (X, Y)$的分布函数为$F_U(u)=F_X(u) F_Y(u)$；

（2）随机变量$V=\min (X, Y)$的分布函数为$F_V(v)=1-\left(1-F_X(v)\right)\left(1-F_Y(v)\right)$。

由定理 4，推广至$n$个相互独立随机变量的情形有，设连续型随机变量$X_1, X_2, \cdots, X_n$相互独立，且$X_i$的分布函数为$F_{X_i}(x), i=1,2, \cdots, n$，则

（1）随机变量$U=\max \left(X_1, X_2, \cdots, X_n\right)$的分布函数为$F_U(u)=\prod_{i=1}^n F_{X_i}(u)$；

（2）随机变量$V=\min \left(X_1, X_2, \cdots, X_n\right)$的分布函数为$ F_V(v)=1-\prod_{i=1}^n\left(1-F_{X_i}(v)\right)$。

## 3.5.4 随机变量的数字特征

* 级数（补充）<sup>[4]</sup>

**级数**（Series）是数学中一个有穷或无穷的序列，例如$u_{1},u_{2},u_{3},u_{4}\ldots$之和，即$s=u_{1}+u_{2}+u_{3}+\ldots$，如果序列是有穷序列，其和称为有穷级数；反之，称为无穷级数（一般也简称为级数）。序列$u_{1},u_{2},u_{3},u_{4}\ldots$中的项称作级数的通项（或一般项）。级数的通向可以是实数、矩阵或向量等常量，也可以是关于其它变量的函数，不一定是一个数。一般的，如果级数的通项是常量，则称之为常数项级数，如果级数的通项是函数，则称之为函数项级数。常见简单有穷数量的级数有等差数列和等比数列的级数。

无穷级数有发散和收敛的区别，称为无穷级数的敛散性。无穷级数在收敛时才会有一个和；发散的无穷级数在一般意义上没有和，但可以用一些别的方式来定义。

无穷级数一般写作$u_{1}+u_{2}+u_{3}+\ldots$、$\sum u_{n}$或$\sum _{n=1}^{\infty }u_{n}$。级数收敛时，其和通常被表示为$s=\sum _{n=1}^{\infty }u_{n}$。

**无穷级数的定义**，设$(u_n)$是一个无穷序列：$u_{1},u_{2},u_{3},\ldots ,u_{n},\ldots$，其前$n$项的和称为$\sum u_{n}$的**部分和**：$s_{n}=u_{1}+u_{2}+u_{3}+\cdots +u_{n}$。$(u_n)$部分和依次构成另一个无穷序列：$s_{1},s_{2},s_{3},\ldots ,s_{n},\ldots$，这两个序列合成为一个级数，记作$\sum u_{n}$或$\sum _{n=1}^{\infty }u_{n}$。

**无穷级数的敛散性**，对于级数$\sum _{n=1}^{\infty }u_{n}$，如果当$n$趋于正无穷大时，$s_n$趋向一个有限的极限：$s=\lim _{n\to \infty }s_{n}$，那么这个无穷数就是收敛的，$s$称为$\sum _{n=1}^{\infty }u_{n}$的和。如果极限不存在，这个无穷级数就是发散的。收敛的无穷级数存在唯一的一个和$s$。这时可以定义级数$\sum u_{n}$的余项和：$R_{n}=S-S_{n}$。

**任意项级数**，如果级数$\sum _{n=1}^{\infty }u_{n}$中的各项可以是正数、负数或零，则级数$\sum _{n=1}^{\infty }u_{n}$称为任意项级数。将任意项级数各项$u_n$取绝对值，得到正项级数，$\sum _{n=1}^{\infty }|u_{n}|=|u_{1}|+|u_{2}|+|u_{3}|+\cdots +|u_{n}|+\cdots$。

**条件收敛**，如果任意项级数$\sum _{n=1}^{\infty }u_{n}$收敛，而级数$\sum _{n=1}^{\infty }|u_{n}|$发散，则称级数$\sum _{n=1}^{\infty }u_{n}$条件收敛。

**绝对收敛**，如果级数$\sum _{n=1}^{\infty }|u_{n}|$收敛，则称级数绝对收敛。

定理：如果任意性级数$\sum _{n=1}^{\infty }u_{n}$各项绝对值所组成的正向级数$\sum _{n=1}^{\infty }|u_{n}|$收敛，则级数$\sum _{n=1}^{\infty }u_{n}$收敛。

收敛级数的性质：

* 若一个无穷级数$\sum u_{n}\ :\ u_{1}+u_{2}+u_{3}+\cdots +u_{n}+\cdots$收敛，其和为$s$，则如果每一项乘以一个常数$a$，得到的级数$\sum au_{n}:\ au_{1}+au_{2}+au_{3}+\cdots +au_{n}+\cdots$也收敛，且和等于$as$。

* 收敛的无穷级数可以逐项相加或相减，如有两个无穷级数：$\sum _{n=1}^{\infty }u_{n}=s$和$\sum _{n=1}^{\infty }v_{n}=t$，则$\sum _{n=1}^{\infty }(u_{n}\pm v_{n})=s\pm t$。

* 级数前面加上有限项或减去有限项不影响其收敛性，如：$s=u_{1}+u_{2}+u_{3}+\cdots +u_{n}+\cdots$和$s=u_{12}+u_{15}+u_{16}+u_{17}+\cdots +u_{n}+\cdots$，这两个级数的敛散性是一样的。

* 当$n$趋向无限大时，任何一个收敛级数的通项都趋于0：$\lim _{n\to \infty }u_{n}=0$。

借助[SymPy](https://docs.sympy.org/latest/modules/concrete.html)<sup>②</sup>级数求和，例如，


```python
from IPython.display import display, Latex
from sympy import I, oo, Sum, exp, pi,factorial, S,Symbol, oo,pprint,print_latex,pi,Integral,Product
from sympy.abc import x, y, a, b, c, d, n,p,i
import numpy as np
```


```python
Series_Sum_1=Sum(x**n/factorial(n),(n,0,oo))
Series_Sum_1
```




$\displaystyle \sum_{n=0}^{\infty} \frac{x^{n}}{n!}$




```python
Series_Sum_1.doit()
```




$\displaystyle e^{x}$




```python
Series_Sum_2=Sum(n*p**(n-1),(n,1,oo))
Series_Sum_2
```




$\displaystyle \sum_{n=1}^{\infty} n p^{n - 1}$




```python
Series_Sum_2.doit()
```




$\displaystyle \frac{\begin{cases} \frac{p}{\left(1 - p\right)^{2}} & \text{for}\: \left|{p}\right| < 1 \\\sum_{n=1}^{\infty} n p^{n} & \text{otherwise} \end{cases}}{p}$




```python
Series_Sum_3=Sum(p**(n+1)/(n+1),(n,0,oo))
Series_Sum_3
```




$\displaystyle \sum_{n=0}^{\infty} \frac{p^{n + 1}}{n + 1}$




```python
Series_Sum_3.doit()
```




$\displaystyle p \left(\begin{cases} - \frac{\log{\left(1 - p \right)}}{p} & \text{for}\: \left|{p}\right| \leq 1 \wedge p \neq 1 \\\sum_{n=0}^{\infty} \frac{p^{n}}{n + 1} & \text{otherwise} \end{cases}\right)$



用`is_convergent`方法检查级数的敛散性。`is_convergent`检验求和的（`Sum`）收敛性；`is_absolutely_convergent`检验无穷级数的绝对收敛性。


```python
Series_Sum_4=Sum(1/n**(S(6)/5), (n, 1, oo))
print(f'is convergent:{Series_Sum_4.is_convergent()}')
print(f'is absolutely convergent:{Series_Sum_4.is_absolutely_convergent()}')
Series_Sum_4
```

    is convergent:True
    is absolutely convergent:True
    




$\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{\frac{6}{5}}}$



* 数学期望

定义 1：设$X$是离散型的随机变量，其分布律为$P\left(X=x_i\right)=p_i, i=1,2, \cdots$，如果级数$\sum_{i=1}^{\infty} x_i p_i$绝对收敛，则称$E(X)=\sum_{i=1}^{\infty} x_i p_i$为**离散型随机变量**$X$**的数学期望**，也称作**期望**或**均值**。

定义中要求级数$\sum_{i=1}^{\infty} x_i p_i$绝对收敛，是为了保证数学期望的唯一性。如级数$\sum_{i=1}^{\infty} x_i p_i$条件收敛，级数$\sum_{i=1}^{\infty} x_i p_i$改变项的次序后，其和不唯一。只有当$\sum_{i=1}^{\infty} x_i p_i$绝对收敛时，改变项的顺序才不影响和的唯一性，即绝对收敛级数具有可交换性。

例如，有随机变量$X$的分布律为，$P\left(X=\frac{2^i}{i}\right)=\frac{1}{2^i}, \quad i=1,2, \cdots$，检查$E(X)$的敛散性为`False`，即$E(X)$不存在。


```python
ev_1=Sum((2**i/i)*(1/2**i),(i,1,oo))
print(ev_1.is_absolutely_convergent())
ev_1
```

    False
    




$\displaystyle \sum_{i=1}^{\infty} \frac{1}{i}$



同样，对于$P\left(X=(-1)^i \frac{2^i}{i}\right)=\frac{1}{2^i}, \quad i=1,2, \cdots$，$E(X)$不存在。


```python
ev_2=Sum(((-1)**i*2**i/i)*(1/2**i),(i,1,oo))
print(ev_2.is_absolutely_convergent())
ev_2
```

    False
    




$\displaystyle \sum_{i=1}^{\infty} \frac{\left(-1\right)^{i}}{i}$



对于$P\left(X=(-1)^i \frac{2^i}{i^2}\right)=\frac{1}{2^i}, \quad i=1,2, \cdots$，$E(X)$则存在，为$- \frac{\pi^{2}}{12}$。


```python
ev_3=Sum(((-1)**i*2**i/i**2)*(1/2**i),(i,1,oo))
print(ev_3.is_absolutely_convergent())
ev_3
```

    True
    




$\displaystyle \sum_{i=1}^{\infty} \frac{\left(-1\right)^{i}}{i^{2}}$




```python
ev_3_result=ev_3.doit()
print_latex(ev_3_result)
ev_3_result
```

    - \frac{\pi^{2}}{12}
    




$\displaystyle - \frac{\pi^{2}}{12}$



又例如，随机变量$X$的分布律`px_dist`如下定义，计算期望值为2.85。


```python
x=np.arange(1, 6)
probs=make_array(0.15, 0.25, 0.3, 0.2, 0.1)
px_dist=Table().values(x).probabilities(probs)
px_dist
```




<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Value</th> <th>Probability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1    </td> <td>0.15       </td>
        </tr>
        <tr>
            <td>2    </td> <td>0.25       </td>
        </tr>
        <tr>
            <td>3    </td> <td>0.3        </td>
        </tr>
        <tr>
            <td>4    </td> <td>0.2        </td>
        </tr>
        <tr>
            <td>5    </td> <td>0.1        </td>
        </tr>
    </tbody>
</table>




```python
display(Latex(f'$E(X)$={px_table.ev()}')) # 同 sum(x*probs)
Plot(px_dist,show_ev=True)
```


$E(X)$=2.8500000000000005


<img src="./imgs/3_5_a/output_131_1.png" height='auto' width='auto' title="caDesign">
    


离散型随机变量数学期望的定义可推广至连续型随机变量的情形。首先将连续性随机变量$X$的取值“离散化”，即将$X$的值域$\Omega_X$分割成$n$份，记第$i$份为$\left[x_i, x_i+\Delta x_i\right), i=1,2, \cdots, n$，在每一个小区间，$X$的取值近似为$x_i$，相应的概率为$P\left(x_i \leqslant X<x_i+\Delta x_i\right)=\int_{x_i}^{x_i+\Delta x_i} f(x) \mathrm{d} x \approx f\left(x_i\right) \Delta x_i$。$X$“离散化”后视为离散型随机变量，其分布律近似为，

|  $X$ | $x_1 , x_2 , \cdots,x_n , \cdots$  |
|---|---|
| 概率  | $f\left(x_1\right) \Delta x_1 , f\left(x_2\right) \Delta x_2 \quad \ldots,f\left(x_n\right) \Delta x_n \quad \ldots$  |

则$X$的平均值近似为$\sum_{i=1}^n x_i p_i \approx \sum_{i=1}^n x_i f\left(x_i\right) \Delta x_i$，另$n$个小区间长度的最大值$\lambda=\max _{1 \leqslant i \leqslant n}\left(\Delta x_i\right) \rightarrow 0$，得到$X$的平均值精确为$\lim _{\lambda \rightarrow 0} \sum_{i=1}^n x_i p_i=\lim _{\lambda \rightarrow 0} \sum_{i=1}^n x_i f\left(x_i\right) \Delta x_i=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$，这就是连续型随机变量的数学期望。和离散型随机变量类似，要求$\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$绝对收敛。

定义 2：设$X$是连续型随机变量，其密度函数为$f(x)$。如果广义积分$\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$绝对收敛，则称$E(X)=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$为**连续型随机变量**$X$**的数学期望**，也称作**期望或均值**。

例如，设随机变量$X$的密度函数为$f(x)=\frac{1}{\pi} \cdot \frac{1}{1+x^2},-\infty<x<+\infty$，由下述计算可知其$E(X)$不存在。


```python
# 定义密度函数
density_1=1/pi*1/(1+x**2)
density_1
```




$\displaystyle \frac{1}{\pi \left(x^{2} + 1\right)}$




```python
# 计算围合的总面积，满足规范性
total_area_1=Integral(density_1,(x,-oo,+oo))
print(f'total area={total_area_1.doit()}')
total_area_1
```

    total area=1
    




$\displaystyle \int\limits_{-\infty}^{\infty} \frac{1}{\pi \left(x^{2} + 1\right)}\, dx$



通过计算期望，结果为`nan`，因此对于该案例的随机变量$X$，并不存在$E(X)$。


```python
# 定义期望
expectation_1=Integral(x*density_1, (x, -oo,+oo))
print(expectation_1.doit())
expectation_1
```

    nan
    




$\displaystyle \int\limits_{-\infty}^{\infty} \frac{x}{\pi \left(x^{2} + 1\right)}\, dx$



* 随机变量函数的数学期望

定理 1（**随机变量一元函数的期望公式**）：

（1）设$X$是离散型随机变量，其分布律为$P\left(X=x_i\right)=p_i, i=1,2, \cdots$，如果级数$\sum_{i=1}^{\infty} g\left(x_i\right) p_i$绝对收敛，则$X$的一元函数$Y=g(X)$的数学期望为$E[g(X)]=\sum_{i=1}^{\infty} g\left(x_i\right) p_i$。

（2）设$X$是连续型随机变量，其密度函数为$f(x)$，如果广义积分$\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x$绝对收敛，则$X$的一元函数$Y=g(X)$的数学期望为$E[g(X)]=\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x$。

定理 2（**随机变量二元函数的期望公式**）：

（1）设$(X,Y)$是二维离散型随机变量，其联合分布律为$P\left(X=x_i, Y=y_j\right)=p_{i j}, i, j=1,2, \cdots$，如果级数$\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} g\left(x_i, y_j\right) p_{i j}$绝对收敛，则$(X,Y)$二元函数$g(X,Y)$的数学期望为$E[g(X, Y)]=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} g\left(x_i, y_j\right) p_{i j}$；特别地，$E(X)=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} x_i p_{i j}, E(Y)=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} y_j p_{i j} $。

（2）设$(X,Y)$是二维连续型随机变量，其联合密度为$f(x,y)$。如果广义积分$\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y$绝对收敛，则$(X,Y)$的二元函数$g(X,Y)$的数学期望为$E[g(X, Y)]=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y$；特别地，$E(X)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x f(x, y) \mathrm{d} x \mathrm{~d} y$，$E(Y)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} y f(x, y) \mathrm{d} x \mathrm{~d} y$。

* 数学期望的性质

（1）设$c$为常数，则$E(c)=c$；

（2）设$X$为随机变量，且$E(X)$存在，$k,c$为常数，则$E(kX+c)=kE(X)+c$；

（3）设$X,Y$为任意两个随机变量，且$E(X)$和$E(Y)$存在，则$E(X+Y)=E(X)+E(Y)$；

（4）设$X$与$Y$为相互独立的随机变量，且$E(X)$和$E(Y)$存在，则$E(XY)=E(X)E(Y)$。

* 方差和标准差

定义 设$X$是一个随机变量，如果$E\left\{[X-E(X)]^2\right\}$存在，则称$D(X) \triangleq E\left\{[X-E(X)]^2\right\}$为**随机变量**$X$**的方差**。称方差$D(X)$的算数平方根$\sigma_X \triangleq \sqrt{D(X)}$为**随机变量**$X$**的标准差**。实际计算方差时，可用$D(X)=E(X)^2-[E(X)]^2$计算。

定理 方差的性质

（1）$D(X)=0$的充分必要条件是$P(X=c)=1$，即$X$服从参数为$c$的退化分布，其中$c=E(X)$。特别，若$c$为常数，则$D(c)=0$;

（2）设$X$为随机变量，$k,c$为常数，则$D(k X+c)=k^2 D(X)$；

（3）设$X,Y$为相互独立的随机变量，则$D(X \pm Y)=D(X)+D(Y) \pm 2 E\{[X-E(X)][Y-E(Y)]\}$；

（4）设$X$与$Y$为相互独立的随机变量，则$D(X \pm Y)=D(X)+D(Y)$。

* 常用分布及其数学期望与方差

|  $X  \sim $  | 分布律或概率密度  |  $E(X)$  |  $D(X)$   |
|---|---|---|---|
| $$0-1$$分布  | $$P\{X=k\}=p^k q^{1-k}, k=0,1 \\0<p<1, p+q=1$$  | $p$  | $pq$  |
| 二项分布$$B(n, p)$$  |  $$P\{X=k\}=\left(\begin{array}{l}n \\k\end{array}\right) p^k q^{n-k}, k=0,1, \cdots, n, \\n \geqslant 1,0<p<1, p+q=1$$ | $np$  | $npq$  |
| 几何分布$$G(p)$$ | $$P\{X=k\}=p q^{k-1}, k=1,2, \cdots \\0<p<1, p+q=1$$  | $\frac{1}{p}$  | $\frac{q}{p^2}$  |
| 超几何分布$$H(n, M, N)$$  | $$P\{X=k\}=\frac{\left(\begin{array}{c}M \\k\end{array}\right)\left(\begin{array}{c}N-M \\n-k \end{array}\right)}{\left(\begin{array}{l}N \\n\end{array}\right)}, k=0,1,2, \cdots, \min (n, M)$$  | $\frac{nM}{N}$  | $\frac{n M}{N}\left(1-\frac{M}{N}\right)\left(\frac{N-n}{N-1}\right) $  |
| 泊松分布$$\pi(\lambda)$$  | $$P\{X=k\}=\frac{\lambda^k}{k !} \mathrm{e}^{-\lambda}, k=0,1,2, \cdots, \\\lambda>0$$  | $\lambda$  | $\lambda$  |
| 均匀分布$$U(a, b)$$  | $$f(x)= \begin{cases}\frac{1}{b-a}, & a<x<b \\0, & \text { 其他 }\end{cases} $$  | $\frac{a+b}{2}$  | $\frac{(b-a)^2}{12}$  |
| 指数分布$$E(\lambda)$$  |  $$f(x)=\left\{\begin{array}{ll}\lambda \mathrm{e}^{-\lambda x}, & x>0, \\0, & x \leqslant 0,\end{array} \quad \lambda>0\right.$$ | $\frac{1}{\lambda}$  |  $\frac{1}{\lambda^2}$  |
| 正态分布$$N\left(\mu, \sigma^2\right)$$  | $$f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^2}{2 \sigma^2}},-\infty<x<+\infty, \quad \sigma>0$$  |  $\mu $ |  $ \sigma^2$ |

* 切比雪夫不等式

定理 （**切比雪夫不等式**），设随机变量$X$的数学期望$E(X)$与方差$D(X)$存在，则对于任意正数$\varepsilon$，不等式$P\{|X-E(X)| \geqslant \varepsilon\} \leqslant \frac{D(X)}{\varepsilon^2}$成立。切比雪夫不等式可书写为如下形式，$P\{|X-E(X)|<\varepsilon\} \geqslant 1-\frac{D(X)}{\varepsilon^2}$。这个不等式给出了在随机变量$X$的分布未知情况下，事件$\{|X-E(X)| < \varepsilon\}$概率的下限估计。

* 协方差和相关系数

定义 1 设$(X,Y)$是二维随机变量，如果$E\{[X-E(X)][Y-E(Y)]\}$存在，则称$\operatorname{cov}(X, Y) \triangleq E\{[X-E(X)][Y-E(Y)]\}$为**随机变量**$X$**和**$Y$**的协方差**。实际计算协方差时，更多使用如下公式，$\operatorname{cov}(X, Y)=E(X Y)-E(X) E(Y)$。

定理 1（协方差的性质），设$X,Y,X_1,X_2$为任意的随机变量，$c,k,l$为常数，则有，

（1）$\operatorname{cov}(X, c)=0$；

（2）$\operatorname{cov}(X, Y)=\operatorname{cov}(Y, X)$；

（3）$\operatorname{cov}(k X, l Y)=k l \operatorname{cov}(X, Y)$；

（4）$\operatorname{cov}\left(X_1+X_2, Y\right)=\operatorname{cov}\left(X_1, Y\right)+\operatorname{cov}\left(X_2, Y\right) $。

协方差考察了随机变量之间协同变化的关系，但为了避免量纲的影响，将随机变量标准化，$X^*=\frac{X-E(X)}{\sqrt{D(X)}}, Y^*=\frac{Y-E(Y)}{\sqrt{D(Y)}}$，再求协方差$\operatorname{cov}\left(X^*, Y^*\right)$，就是随机变量$X$和$Y$的相关系数，又称为标准化协方差。因为$\operatorname{cov}\left(X^*, Y^*\right)=E\left(X^* Y^*\right)=E\left(\frac{X-E(X)}{\sqrt{D(X)}} \cdot \frac{Y-E(Y)}{\sqrt{D(Y)}}\right)=\frac{\operatorname{cov}(X, Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$，所以定义相关系数如下。

定义 2，设$(X<Y)$是二维随机变量，如果$cov(X,Y)$存在，且$D(X)>0,D(Y)>0$，则称$\rho(X, Y)  \triangleq \frac{\operatorname{cov}(X, Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$为**随机变量**$X$**和**$Y$**的相关系数**，也记作$\rho_{XY}$。

定义 3，设$(X,Y)$是二维随机变量，当$\rho_{XY}=0$时，称$X$与$Y$（线性）无关或（线性）不相关。

定理 2，当$D(X)>0,D(Y)>0$时，下列5个命题是等价的：（1）$\rho_{XY}=0$；（2）$cov(X,Y)=0$；（3）$E(XY)=E(X)E(Y)$；（4）$D(X+Y)=D(X)+D(Y)$；（5）$D(X-Y)=D(X)+D(Y)$。

定理 2，相关系数的性质，设$(X,Y)$是二维随机变量，当$con(X,Y)$存在且$D(X)>0,D(Y)>0$时，有

（1）$\left|\rho_{X Y}\right| \leqslant 1$；

（2）$\left|\rho_{X Y}\right|=1$的充要条件是$P(Y=aX+b)=1$，其中，

当$\rho_{XY}=1$时，$a=\sqrt{\frac{D(Y)}{D(X)}}, b=E(Y)-\sqrt{\frac{D(Y)}{D(X)}} E(X)$,

当$\rho_{XY}=-1$时，$a=-\sqrt{\frac{D(Y)}{D(X)}}, b=E(Y)+\sqrt{\frac{D(Y)}{D(X)}} E(X)$；

（3）若随机变量$X$与$Y$相互独立，则$X$与$Y$线性无关，即$\rho_{XY}=0$。但由$\rho_{XY}=0$不能推断$X$与$Y$相互独立。

定义 4，设二维随机变量$(X,Y)$的相关系数$\rho_{XY}$存在，则

当$\left|\rho_{X Y}\right|=1$时，$(X,Y)$的取值$(x,y)$在直线$y=ax+b$上的概率为1，称$X$与$Y$完全线性相关；

当$\rho_{XY}=1$时，$(X,Y)$的取值$(x,y)$在斜率大于0的直线$y=ax+b$上的概率为1，称$X$与$Y$完全正线性相关；

当$\rho_{XY}=-1$时，$(X,Y)$的取值$(x,y)$在斜率小于0的直线$y=ax+b$上的概率为1，称$X$与$Y$完全负线性相关；

当$\rho_{XY}>0$时，称$X$与$Y$正线性相关；

当$\rho_{XY}<0$时，称$X$与$Y$负线性相关。

定理 4，如果二维随机变量$(X,Y)$服从二维正态分布，则$X$与$Y$相互独立等价于$X$与$Y$不相关。

---

注释（Notes）：

① datascience，（<https://github.com/data-8/datascience>）。

② SymPy，（<https://docs.sympy.org/latest/index.html>）。

参考文献（References）:

[1] (工业和信息化“十二五”规划教材) 同济大学数学系. 概率论与数理统计[M].人民邮电出版社 (2017)

[2] 主编：许伯生 刘春燕；参编：刘瑞娟 肖翔 朱萌 洪银萍 周宇. 概率论与数理统计（第2版）[M].清华大学出版社 (2019)

[3] 数据科学的概率课程（Probability for Data Science）在线教材，<http://prob140.org/textbook/content/README.html>.

[4] 级数（Wikipedia），<https://en.wikipedia.org/wiki/Series_(mathematics)><https://zh.wikipedia.org/wiki/%E7%BA%A7%E6%95%B0>.
