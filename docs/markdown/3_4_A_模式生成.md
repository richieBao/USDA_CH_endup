Created on Sun Mar 19 21:13:49 2023 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.4-A 模式生成：从聚类模式特征到生成对抗网络和计算分析工具的建构

## 3.4.1 聚类方式模式提取

寻找地理空间数据分布的特征、模式组成和结构，在*标记距离*一章通过构建类/簇大小直方图、共现关系和层级分解等标记特征提取土地覆盖类型的分布模式。聚类则可以把相似的样本（或空间栅格单元、点、区域等）聚为同类（簇），同簇样本具有相似的属性特征，不同簇的样本之间则为高度不同的属性特征，因此分析聚类后簇内样本属性特征的组成和结构可以寻找地理空间数据分布的模式。

地理空间数据聚类的空间方式一般有两种，一种是直接将具有多种属性的栅格单元作为样本用于聚类；另一种是按照样方区域统计多元栅格数据后执行聚类。如果仅分析土地覆盖类型一种分类数据源属性，则采用先区域统计（例如土地利用类型频数）再聚类的方式，发现采样样方具有的类型组成模式。

> 关于聚类的详细解释可以参考*机器学习实验*一章。

### 3.4.1.1 基于样方的多源栅格数据区域统计

多源数据通常具有不同的数据格式，不同的高空分辨率，不同的范围，因此需要将其规范为具有同样单元大小和同一分析范围的栅格数据。在获得原始数据之后，需要先查看数据，可以使用 QGIS 工具，下述也定义了`tiled_web_map_show()`方法，以金子塔缩放（zoom）瓦片网络地图形式（tiled web map）显示数据，提高大数据显示效率。

下述实验了6类数据，如表：

|  序号 | 数据名称  | 数据来源  | 数据说明  | 大小  | 数据类型 |时间  |精度|
|---|---|---|---|---|---|---|---|
|  1 | 建筑高度（层高）数据 （Building Footprints (current) ） | [Chicago Data Portal](https://data.cityofchicago.org/Buildings/Building-Footprints-current-/hz9b-7nh8)<sup>①</sup>  | 为芝加哥城建筑轮廓数据，含有层数等字段  | 5.96GB  | JSON  | 2021.08.21  |矢量|
|  2 | 土地利用数据（Land Use Inventory）  |  [Chicago Metropolitan Agency for Planning, CMAP](https://www.cmap.illinois.gov/data/land-use/inventory)<sup>②</sup> | 分类信息查看*不平等性和空间隔离*一章。原始数据为SHP格式  | 2.09GB  | TIFF（SHP）  | 2015  |5m（矢量）|
|  3 | 土地覆盖数据（High-resolution, 7-class, 2010 land cover for the Chicago, IL region.）  | [ArcGIS-Chicago Regional Land Cover ](https://www.arcgis.com/home/item.html?id=782adcff882d4f09a227b509dcaa1628)<sup>③</sup>   |  土地覆盖类型说明：</br>0 - Background；</br>1 - Tree Canopy；</br>2 - Grass/Shrub；</br>3 - Bare Soil；</br>4 - Water；</br>5 - Buildings；</br>6 - Roads/Railroads；</br>7 - Other Paved Surfaces|  17.8GB |  TIFF | 2010  |1m|
|  4 | 地表温度数据（Land surface temperature，LST）(MODIS MYD21A1D v006)  | [USGS EarthExploer](https://earthexplorer.usgs.gov/)<sup>④</sup>   | 选取了冬季和夏季区间的两个数据  |  395MB</br>403MB | TIFF  | 2022.02.26</br>2022.08.10  |1km|
|  5 | DEM（Digital Elevation Model） 数据（GTOPO30）  |  [USGS EarthExploer](https://earthexplorer.usgs.gov/)<sup>④</sup>    | 含两个数据（用于合并）：</br>n41_w088_1arc_v3.tif</br>n42_w088_1arc_v3.tif  | 24.7MB</br>24.7MB  |TIFF   | 1996  |1km|
|  6 | 夜间灯光数据（Annual VNL V2） | [Earth Observation Group](https://eogdata.mines.edu/products/vnl/)<sup>⑤</sup>  | VNL_v21_npp_2021_global_vcmslcfg_c202205302300.average.dat.tif，为2021年的均值数据  | 10.8GB  |TIFF   | 2021  |~500m|



```python
# IPython extension to reload modules before executing user code.
%load_ext autoreload 
# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.
%autoreload 2 

import warnings
warnings.filterwarnings('ignore')

from usda.utils import AttrDict
import usda.database as usda_database
import usda.geodata_process as usda_geoprocess
import usda.models as usda_model 
import usda.pattern_signature  as usda_signature
from usda import data_visualization as usda_vis
from usda import network as usda_network
from scipy.stats import zscore

import matplotlib.pyplot as plt
import matplotlib
import rasterio as rio
import earthpy.plot as ep
import copy
import numpy as np
from rio_tiler.io import COGReader
import geopandas as gpd
import pandas as pd
import seaborn as sns
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    


```python
__C=AttrDict() 
args=__C

__C.gi=AttrDict()
__C.gi.epsg_wgs84=4326
__C.gi.Chicago_epsg=32616

__C.data=AttrDict()
__C.data.footprint_wgs84_fn='G:\data\Building_Footprints\Building_Footprints.shp'
__C.data.footprint_projected_fn='G:\data\Building_Footprints\Building_Footprints_projected.shp'
__C.data.stories_fn='G:\data\Building_Footprints\chicago_building_stories.tif'

__C.data.landuse_fn='E:\data\Chicago_landuse\landuse.tif' 
__C.data.landcover_fn='F:\data\data_01_Chicago\LandCover_2010_ChicagoRegion\landcover_2010_chicagoregion.img'
__C.data.lst_0226_fn=r'E:\data\LST\lst_0226_chicago.tif' # <MDI key="RANGEBEGINNINGDATE">2023-02-26</MDI> <MDI key="RANGEBEGINNINGTIME">00:00:00</MDI> <MDI key="RANGEENDINGDATE">2023-02-26</MDI> <MDI key="RANGEENDINGTIME">23:59:59</MDI>
__C.data.lst_0810_fn=r'E:\data\LST\lst_0810_chicago.tif' # <RangeEndingTime>23:59:59.000000</RangeEndingTime> <RangeEndingDate>2022-08-10</RangeEndingDate> <RangeBeginningTime>00:00:00.000000</RangeBeginningTime> <RangeBeginningDate>2022-08-10</RangeBeginningDate>
__C.data.nightlight_fn=r'D:\data\night_light\vnl_chicago_year.tif'

__C.data.mosaic_dem_root=r'G:\data\chicago_dem\mosaic_data'
__C.data.dem_fn=r'G:/data/chicago_dem/chicago_dem.tif'

__C.data.chicago_boundary_fn=r'G:\data\Chicago_boundaries_city\Chicago_boundaries_city.shp'
__C.data.zs_gdf_fn=r'D:\data\zonal_stats_gdf.gpkg'
__C.data.zs_norm_gdf_fn=r'D:\data\zonal_stats_norm_gdf.gpkg'

__C.data.naip_root=r'F:\data\NAIP_chicago'
```

#### 1) 原始数据预处理与打印观察

*  建筑高度（层高）数据

定义`json2gdf()`方法将JSON格式数据读取为GeoDataFrame格式，并存储为SHP格式用于调用定义的`create_multiband_raste()`方法，将SHP转为栅格数据，栅格单元大小同一配置为10m，投影同一配置为EPSG:32616。


```python
building_footprints=usda_database.json2gdf(args.data.footprint_wgs84_fn,numeric_columns={'no_stories':'int','stories':'int'},epsg=args.gi.Chicago_epsg)
building_footprints.to_file(args.data.footprint_projected_fn)
```


```python
usda_geoprocess.create_multiband_raster(['stories'],args.data.footprint_projected_fn,args.data.stories_fn,cellSize=10,NoData_value=0) 
```

    The raster was written successfully!
    

调用`tiled_web_map_show()`方法打印地图是，可以配置球面墨卡托投影金字塔缩放比例`z`参数，为0-23级，显示的范围越大，数值越大。参数`centroid_latlon`可以配置缩放的中心点，为经纬度。


```python
centroid_latlon=(41.887857,-87.668474)
_=usda_geoprocess.tiled_web_map_show(args.data.stories_fn,z=12,cmap='hot',centroid_latlon=centroid_latlon,figsize=(20,20)) 
```

    CRS: EPSG:32616
    影像边界坐标： (-87.94015009829613, 41.642095322269824, -87.52374193269772, 42.02378751932716)
    瓦片的形状： (512, 512, 1)
    

<img src="./imgs/3_4_A/output_8_1.png" height='auto' width='auto' title="caDesign">
    


* 土地利用数据

使用*不平等性和空间隔离*一章处理后，单元大小为5m的栅格数据。


```python
np.random.seed(0)
cmap=matplotlib.colors.ListedColormap (np.random.rand(256,3))

_=usda_geoprocess.tiled_web_map_show(args.data.landuse_fn,z=12,cmap=cmap,centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: EPSG:32616
    影像边界坐标： (-88.71487753316414, 41.19605815460622, -87.51987719192424, 42.50552725246455)
    瓦片的形状： (512, 512, 1)
    


<img src="./imgs/3_4_A/output_10_1.png" height='auto' width='auto' title="caDesign">    
    


* 土地覆盖数据

原始数据为栅格数据，因此直接读取查看数据是否正确。


```python
_=usda_geoprocess.tiled_web_map_show(args.data.landcover_fn,z=12,cmap=cmap,centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: PROJCS["Albers Conical Equal Area",GEOGCS["NAD83",DATUM["North_American_Datum_1983",SPHEROID["GRS 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","6269"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4269"]],PROJECTION["Albers_Conic_Equal_Area"],PARAMETER["latitude_of_center",23],PARAMETER["longitude_of_center",-96],PARAMETER["standard_parallel_1",29.0833333333333],PARAMETER["standard_parallel_2",45.0833333333333],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["meters",1],AXIS["Easting",EAST],AXIS["Northing",NORTH]]
    影像边界坐标： (-88.84156993936557, 41.05502222871079, -86.28757940502697, 42.56699636977984)
    瓦片的形状： (512, 512, 1)
    


<img src="./imgs/3_4_A/output_12_1.png" height='auto' width='auto' title="caDesign">    


* 地表温度（LST） 数据 

选用了夏季和冬季区域两个数据，用于观察夏季降温和冬季保温效果，数据分别标识为0810（夏季）和0226（冬季）。


```python
centroid_latlon=(41.887857,-87.668474)
lst_tile=usda_geoprocess.tiled_web_map_show(args.data.lst_0226_fn,z=9,cmap='flag',centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: EPSG:4326
    影像边界坐标： (-88.00282277592254, 41.583333329333335, -87.46106746458194, 42.09166666266667)
    瓦片的形状： (512, 512, 1)
    


<img src="./imgs/3_4_A/output_14_1.png" height='auto' width='auto' title="caDesign">    



```python
lst_tile=usda_geoprocess.tiled_web_map_show(args.data.lst_0810_fn,z=9,cmap='flag',centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: PROJCS["unnamed",GEOGCS["Unknown datum based upon the custom spheroid",DATUM["Not specified (based on custom spheroid)",SPHEROID["Custom spheroid",6371007.181,0]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]]],PROJECTION["Sinusoidal"],PARAMETER["longitude_of_center",0],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Easting",EAST],AXIS["Northing",NORTH]]
    影像边界坐标： (-88.74908925022875, 41.5666666631397, -86.73220428347186, 42.091666663061076)
    瓦片的形状： (512, 512, 1)
    


<img src="./imgs/3_4_A/output_15_1.png" height='auto' width='auto' title="caDesign">    

* DEM 数据

定义`raster_mosaic()`方法合并两个DEM数据覆盖芝加哥城全部区域。


```python
_=usda_geoprocess.raster_mosaic(args.data.mosaic_dem_root,args.data.dem_fn,dtype=rio.int32) 
```


```python
lst_tile=usda_geoprocess.tiled_web_map_show(args.data.dem_fn,z=12,cmap='copper',centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: EPSG:4326
    影像边界坐标： (-88.00013888888888, 40.99986111111111, -86.9998611111111, 43.000138888888884)
    瓦片的形状： (512, 512, 1)
    


<img src="./imgs/3_4_A/output_18_1.png" height='auto' width='auto' title="caDesign">    


* 夜间灯光数据


```python
nighlight_tile=usda_geoprocess.tiled_web_map_show(args.data.nightlight_fn,z=8,cmap='hot',centroid_latlon=centroid_latlon,figsize=(20,20))
```

    CRS: EPSG:4326
    影像边界坐标： (-91.61041595954998, 39.147916379849995, -79.79791586504999, 44.97291642645)
    瓦片的形状： (512, 512, 1)
    

<img src="./imgs/3_4_A/output_20_1.png" height='auto' width='auto' title="caDesign">
    


#### 2) 多源数据的区域统计与数据合并

定义`rec_quadrats_bounded_gdf()`方法可以实现根据指定的区域构建样方，此次实验定义的样方大小为150m，基本为芝加哥城一个街区的大小。样方数为 25731 个。


```python
boundary=gpd.read_file(args.data.chicago_boundary_fn)
boundary.to_crs(args.gi.Chicago_epsg,inplace=True)

grids=usda_geoprocess.rec_quadrats_bounded_gdf(boundary,h_distance=150,v_distance=150)
print(grids.shape)
```

    (25731, 1)
    


```python
grids.boundary.plot(figsize=(20,20));
```

<img src="./imgs/3_4_A/output_23_0.png" height='auto' width='auto' title="caDesign">
    


多源数据的区域统计使用定义的`zonal_stats_raster_batch()`方法实现，其参数`raster_info`为一个字典，值列表中的第1个值为数据文件路径，第2个值为区域统计方法，可以传入一个包含多个统计方法的列表。区域统计的方法包括'count', 'min', 'max', 'mean', 'sum', 'std', 'median', 'majority', 'minority', 'unique', 'range', 'nodata', 'nan'等，及自定义的频数统计'frequency'方式。对于分类数据（土地利用和覆盖类型数据）采用频数统计的方法，即一个样方中各类型的数量或占比；其它的数据按样方计算均值。基于样方的区域统计计算需要一段时间，将计算结果存储为`GPKG`格式于本地磁盘，避免重复计算。


```python
raster_info={    
    'lst0226':[args.data.lst_0226_fn,'mean'],
    'lst0810':[args.data.lst_0810_fn,'mean'],
    'stories':[args.data.stories_fn,'mean'],    
    'dem':[args.data.dem_fn,'mean'],
    'nightlight':[args.data.nightlight_fn,['mean']],
    'landuse':[args.data.landuse_fn,'frequency'],
    'landcover':[args.data.landcover_fn,'frequency'],
    }

zs_gdf=usda_geoprocess.zonal_stats_raster_batch(raster_info,grids,upscale_mu=2) 
zs_gdf.to_file(args.data.zs_gdf_fn,driver='GPKG')
```

    Processing img: 1/7-lst0226
    resampling upscale=9
    Processing img: 2/7-lst0810
    resampling upscale=9
    Processing img: 3/7-stories
    Processing img: 4/7-dem
    Processing img: 5/7-nightlight
    resampling upscale=6
    Processing img: 6/7-landuse
    Processing img: 7/7-landcover
    

区域统计多源数据于一个GeoDataFrame格式数据下，通过字段名标识不同数据统计结果。


```python
zs_gdf=gpd.read_file(args.data.zs_gdf_fn)
# zs_gdf.fillna(0,inplace=True)
print(zs_gdf.shape)
print(zs_gdf.columns)
zs_gdf.head(3)
```

    (25731, 71)
    Index(['on', 'lst0226_mean', 'lst0810_mean', 'stories_mean', 'dem_mean',
           'nightlight_mean', 'landuse_fre_31', 'landuse_fre_28', 'landuse_fre_55',
           'landuse_fre_29', 'landuse_fre_10', 'landuse_fre_43', 'landuse_fre_54',
           'landuse_fre_19', 'landuse_fre_42', 'landuse_fre_0', 'landuse_fre_2',
           'landuse_fre_18', 'landuse_fre_4', 'landuse_fre_1', 'landuse_fre_12',
           'landuse_fre_46', 'landuse_fre_14', 'landuse_fre_41', 'landuse_fre_8',
           'landuse_fre_47', 'landuse_fre_30', 'landuse_fre_16', 'landuse_fre_9',
           'landuse_fre_50', 'landuse_fre_40', 'landuse_fre_56', 'landuse_fre_23',
           'landuse_fre_20', 'landuse_fre_33', 'landuse_fre_13', 'landuse_fre_32',
           'landuse_fre_45', 'landuse_fre_6', 'landuse_fre_37', 'landuse_fre_27',
           'landuse_fre_34', 'landuse_fre_26', 'landuse_fre_49', 'landuse_fre_24',
           'landuse_fre_11', 'landuse_fre_15', 'landuse_fre_25', 'landuse_fre_48',
           'landuse_fre_51', 'landuse_fre_7', 'landuse_fre_39', 'landuse_fre_5',
           'landuse_fre_52', 'landuse_fre_53', 'landuse_fre_17', 'landuse_fre_38',
           'landuse_fre_22', 'landuse_fre_35', 'landuse_fre_36', 'landuse_fre_44',
           'landuse_fre_3', 'landcover_fre_2', 'landcover_fre_7',
           'landcover_fre_5', 'landcover_fre_6', 'landcover_fre_1',
           'landcover_fre_4', 'landcover_fre_3', 'landcover_fre_0', 'geometry'],
          dtype='object')
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>on</th>
      <th>lst0226_mean</th>
      <th>lst0810_mean</th>
      <th>stories_mean</th>
      <th>dem_mean</th>
      <th>nightlight_mean</th>
      <th>landuse_fre_31</th>
      <th>landuse_fre_28</th>
      <th>landuse_fre_55</th>
      <th>landuse_fre_29</th>
      <th>...</th>
      <th>landuse_fre_3</th>
      <th>landcover_fre_2</th>
      <th>landcover_fre_7</th>
      <th>landcover_fre_5</th>
      <th>landcover_fre_6</th>
      <th>landcover_fre_1</th>
      <th>landcover_fre_4</th>
      <th>landcover_fre_3</th>
      <th>landcover_fre_0</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>290.759983</td>
      <td>314.046661</td>
      <td>0.0</td>
      <td>204.314286</td>
      <td>51.582413</td>
      <td>506.0</td>
      <td>356.0</td>
      <td>38.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>8646.0</td>
      <td>7153.0</td>
      <td>4278.0</td>
      <td>1879.0</td>
      <td>560.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POLYGON ((422430.905 4645394.671, 422280.905 4...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>290.760010</td>
      <td>314.477295</td>
      <td>0.0</td>
      <td>205.464286</td>
      <td>51.738358</td>
      <td>516.0</td>
      <td>384.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>11055.0</td>
      <td>6545.0</td>
      <td>2257.0</td>
      <td>2655.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POLYGON ((422430.905 4645544.671, 422280.905 4...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>290.759995</td>
      <td>314.740021</td>
      <td>0.0</td>
      <td>203.657143</td>
      <td>49.593369</td>
      <td>531.0</td>
      <td>160.0</td>
      <td>209.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>5966.0</td>
      <td>8464.0</td>
      <td>3730.0</td>
      <td>4233.0</td>
      <td>123.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POLYGON ((422430.905 4645694.671, 422280.905 4...</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 71 columns</p>
</div>



下面打印了处理后的各个数据，检查处理后的数据是否正确。

DEM数据检查。


```python
zs_gdf.plot(column='dem_mean',legend=False,linewidth=0,figsize=(20,20),cmap='terrain');
```

<img src="./imgs/3_4_A/output_29_0.png" height='auto' width='auto' title="caDesign">
    


建筑高度数据检查。


```python
zs_gdf.plot(column='stories_mean',legend=False,linewidth=0,figsize=(20,20),cmap='gist_stern');
```

<img src="./imgs/3_4_A/output_31_0.png" height='auto' width='auto' title="caDesign">
    


夜间灯光数据检查。


```python
zs_gdf.plot(column='nightlight_mean',legend=False,figsize=(20,20),cmap='gist_ncar');
```

<img src="./imgs/3_4_A/output_33_0.png" height='auto' width='auto' title="caDesign">
    


地表温度数据检查。对空值（数值为0的值）采用`polynomial`插值方法补全数据。


```python
zs_gdf['lst0226_mean']=zs_gdf['lst0226_mean'].replace(0,None).interpolate(method='polynomial',order=5)
```

冬季地表温度数据检查。


```python
zs_gdf.plot(column='lst0226_mean',legend=False,figsize=(20,20),cmap='coolwarm');
```

<img src="./imgs/3_4_A/output_37_0.png" height='auto' width='auto' title="caDesign">
    


夏季地表温度数据检查。


```python
zs_gdf['lst0810_mean']=zs_gdf['lst0810_mean'].replace(0,None).interpolate(method='polynomial',order=5)
```


```python
zs_gdf.plot(column='lst0810_mean',legend=False,figsize=(20,20),cmap='coolwarm');
```

<img src="./imgs/3_4_A/output_40_0.png" height='auto' width='auto' title="caDesign">
    

土地覆盖类型数据检查。


```python
zs_gdf.plot(column='landcover_fre_1',legend=False,figsize=(20,20),cmap=matplotlib.cm.get_cmap('summer_r'));
```

    C:\Users\richi\AppData\Local\Temp\ipykernel_30148\2541163892.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
      zs_gdf.plot(column='landcover_fre_1',legend=False,figsize=(20,20),cmap=matplotlib.cm.get_cmap('summer_r'));
    

<img src="./imgs/3_4_A/output_42_1.png" height='auto' width='auto' title="caDesign">
    


土地利用类型数据检查。仅提取了索引值为0，即“独栋单户住宅”类型数据。


```python
zs_gdf.plot(column='landuse_fre_0',legend=False,figsize=(20,20),cmap='coolwarm');
```

<img src="./imgs/3_4_A/output_44_0.png" height='auto' width='auto' title="caDesign">
    


* 标准化区域统计数据

根据不同数据类型采用不同的标准化方法，分为两类，一类是分类数据（土地利用和覆盖类型），采用各样方中各类型所占样方单元数的比例方式；另一类是连续值（地表温度、建筑高度、夜间灯光和DEM等），采用针对全部样方数据的最大最小值的归一化方法。


```python
landuse_cols=[i for i in zs_gdf.columns if i.split('_')[0]=='landuse']
landcover_cols=[i for i in zs_gdf.columns if i.split('_')[0]=='landcover']
others_cols=['lst0810_mean','lst0226_mean','stories_mean','dem_mean','nightlight_mean']
```


```python
zs_norm_gdf=zs_gdf.copy(deep=True)
zs_norm_gdf.fillna(0,inplace=True)
zs_norm_gdf[landuse_cols]=zs_norm_gdf.apply(lambda row:[row[i]/row[landuse_cols].sum() for i in landuse_cols],axis=1,result_type="expand")
zs_norm_gdf[landcover_cols]=zs_norm_gdf.apply(lambda row:[row[i]/row[landcover_cols].sum() for i in landcover_cols],axis=1,result_type="expand")
zs_norm_gdf.loc[:,others_cols]=zs_norm_gdf.loc[:,others_cols].apply(lambda x: (x-x.min())/ (x.max()-x.min()), axis=0)
zs_norm_gdf.to_file(args.data.zs_norm_gdf_fn,driver='GPKG')
```


```python
zs_norm_gdf=gpd.read_file(args.data.zs_norm_gdf_fn)
cols=landuse_cols+landcover_cols+others_cols
zs_norm_df=zs_norm_gdf[cols]
zs_norm_df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>landuse_fre_31</th>
      <th>landuse_fre_28</th>
      <th>landuse_fre_55</th>
      <th>landuse_fre_29</th>
      <th>landuse_fre_10</th>
      <th>landuse_fre_43</th>
      <th>landuse_fre_54</th>
      <th>landuse_fre_19</th>
      <th>landuse_fre_42</th>
      <th>landuse_fre_0</th>
      <th>...</th>
      <th>landcover_fre_6</th>
      <th>landcover_fre_1</th>
      <th>landcover_fre_4</th>
      <th>landcover_fre_3</th>
      <th>landcover_fre_0</th>
      <th>lst0810_mean</th>
      <th>lst0226_mean</th>
      <th>stories_mean</th>
      <th>dem_mean</th>
      <th>nightlight_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.562222</td>
      <td>0.395556</td>
      <td>0.042222</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.083452</td>
      <td>0.024871</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.783021</td>
      <td>0.988374</td>
      <td>0.0</td>
      <td>0.705866</td>
      <td>0.143921</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.573333</td>
      <td>0.426667</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.117937</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.802192</td>
      <td>0.988374</td>
      <td>0.0</td>
      <td>0.726938</td>
      <td>0.144447</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.590000</td>
      <td>0.177778</td>
      <td>0.232222</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.188000</td>
      <td>0.005463</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.813889</td>
      <td>0.988374</td>
      <td>0.0</td>
      <td>0.693825</td>
      <td>0.137212</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 69 columns</p>
</div>



### 3.4.1.2 聚类模式特征分析

6类多源数据可以根据因果归为两类，因包括土地利用、土地覆盖、建筑高度和DEM数据；果包括地表温度和夜间灯光。这里聚类因中的土地覆盖、建筑高度和DEM数据，分析聚类簇的模式组成和结构；并计算果中地表温度局部空间自相关系数的冷热点，通过夏季和冬季两个数据提取夏季降温和冬季保温的区域，统计该区域聚类簇的频数，尝试找到形成冬夏相对舒适区域的影响因素。

#### 1) 聚类模式组成结构

聚类的算法采用了`MiniBatchKMeans`，并通过`SelectKBest`方法计算各个因素对聚类结果的影响分数（贡献度）。`MiniBatchKMeans`聚类方式需要指定聚类簇数，簇数的不同可能因素的贡献度不同，因此定义`clustering_minibatchkmeans_selectkbest_ns()`方法实现上述计算同时，可以指定簇数列表，返回不同簇的聚类簇和因素贡献度结果。


```python
from sklearn.feature_selection import f_classif

lu_stories_dem_cols=landcover_cols+['stories_mean','dem_mean',]    
ns=list(range(2,51))
lu_stories_dem_labels,lu_stories_dem_best_scores=usda_model.clustering_minibatchkmeans_selectkbest_ns(zs_norm_df,lu_stories_dem_cols,ns,f_classif)    
```

    100%|████████████████████████████████████████████████████████████████████████| 49/49 [00:20<00:00,  2.43it/s]
    

返回的贡献度为一个数组，将其转换为DataFrame格式，其行为影响因素（区域统计结果对象）；列为因素对应簇数的贡献度得分。


```python
lu_stories_dem_best_scores_df=pd.DataFrame(lu_stories_dem_best_scores,columns=lu_stories_dem_cols,index=ns).T
lu_stories_dem_best_scores_df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>...</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
      <th>46</th>
      <th>47</th>
      <th>48</th>
      <th>49</th>
      <th>50</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>landcover_fre_2</th>
      <td>12170.457812</td>
      <td>22459.522565</td>
      <td>16231.941444</td>
      <td>11790.434016</td>
      <td>9118.860970</td>
      <td>9429.347640</td>
      <td>8557.231325</td>
      <td>7214.913680</td>
      <td>7831.697691</td>
      <td>8716.563207</td>
      <td>...</td>
      <td>4744.033372</td>
      <td>4469.700813</td>
      <td>4195.207935</td>
      <td>3990.582413</td>
      <td>4132.263827</td>
      <td>4249.036397</td>
      <td>3964.436883</td>
      <td>4304.538001</td>
      <td>3818.249952</td>
      <td>3854.999734</td>
    </tr>
    <tr>
      <th>landcover_fre_7</th>
      <td>9475.753986</td>
      <td>4988.439700</td>
      <td>3516.760594</td>
      <td>4461.817585</td>
      <td>9013.292078</td>
      <td>3485.742367</td>
      <td>7245.912793</td>
      <td>6365.899941</td>
      <td>7775.607421</td>
      <td>6488.888081</td>
      <td>...</td>
      <td>3416.716437</td>
      <td>3424.960984</td>
      <td>3439.572117</td>
      <td>3313.335208</td>
      <td>3408.007615</td>
      <td>3582.073340</td>
      <td>3330.831808</td>
      <td>3214.935771</td>
      <td>3114.674266</td>
      <td>3042.314222</td>
    </tr>
    <tr>
      <th>landcover_fre_5</th>
      <td>2575.552250</td>
      <td>3793.440838</td>
      <td>3093.660988</td>
      <td>7101.933962</td>
      <td>5759.085705</td>
      <td>6024.705570</td>
      <td>5963.282042</td>
      <td>4453.227444</td>
      <td>5019.705187</td>
      <td>6700.553769</td>
      <td>...</td>
      <td>3828.882111</td>
      <td>3567.061152</td>
      <td>3558.039171</td>
      <td>3327.922843</td>
      <td>3503.589146</td>
      <td>3663.726931</td>
      <td>3463.296281</td>
      <td>3449.474086</td>
      <td>3351.366060</td>
      <td>3146.704440</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 49 columns</p>
</div>



为了方便查看打印结果，将土地覆盖类型的索引值映射为对应的类型名称。下述打印的折线图横轴为簇数，纵轴为因素的贡献度得分。可以观察到簇数小于10左右时，因素贡献度的排序变化较大；大于簇数10左右时趋于稳定，其中水体对簇结果的影响较大；建筑高度、DEM和道路分类数据对结果的贡献度相对较小；其它土地覆盖类型贡献度相对集中。


```python
lc_mapping={
    'landcover_fre_0':'Background',
    'landcover_fre_1':'Tree_Canopy',
    'landcover_fre_2':'Grass_Shrub',
    'landcover_fre_3':'Bare_Soil',
    'landcover_fre_4':'Water',    
    'landcover_fre_5':'Buildings',
    'landcover_fre_6':'Roads_Railroads',
    'landcover_fre_7':'Other_Paved_Surfaces'}
```


```python
fig, ax=plt.subplots(figsize=(20,15))

np.random.seed(50)
cmap=matplotlib.colors.ListedColormap (np.random.rand(256,3))
lu_stories_dem_best_scores_df.reset_index(names=['lu'],inplace=True)
lu_stories_dem_best_scores_df.replace({'lu':lc_mapping},inplace=True)
pd.plotting.parallel_coordinates(lu_stories_dem_best_scores_df,'lu',ax=ax,colormap=cmap,axvlines=False,linewidth=3)
ax.grid(color='grey', linestyle='--', linewidth=1,alpha=0.2)
plt.show()
```

<img src="./imgs/3_4_A/output_55_0.png" height='auto' width='auto' title="caDesign">
    


下述打印簇数为10的聚类结果地图，观察分布特征。


```python
lu_stories_dem_labels_10=lu_stories_dem_labels[10-2]
clustering10_lu_stories_dem_gdf=zs_norm_gdf.copy(deep=True)
clustering10_lu_stories_dem_gdf['label']=lu_stories_dem_labels_10

np.random.seed(90)
cmap=matplotlib.colors.ListedColormap (np.random.rand(256,3))

clustering10_lu_stories_dem_gdf.plot(column='label',cmap=cmap,categorical=True,figsize=(20,20),legend=True);
```

<img src="./imgs/3_4_A/output_57_0.png" height='auto' width='auto' title="caDesign">
    


分析聚类簇模式组成结构，通过计算簇中影响因素的频数比例进行分析。借鉴类/簇大小直方图样方标记特征，将频数分为3个组距，为(0.0, 0.3]、(0.3, 0.6]和(0.6, 1.0]。统计因素在各区间所占的比例，观察簇中因素的主要构成。从下述打印的各簇因素组距直方图可以得知，

1. 簇0以建筑为主，其次为道路和铺地；
2. （不明显）簇1以林木、草地为主，其次为建筑；
3. 簇2以草地，林木为主，其次为建筑；
4. 簇3以水体为主要，其次为草地；
5. 簇4以铺地为主，其次为道路、建筑等；
6. 簇5以裸地为主，其次为草地；
7. 簇6以道路为主，其次为草地；
8. 簇7以草地为主，其次为道路；
9. 簇8以林木为主，其次为从草地；
10. （不明显）簇9以建筑为主，其次为草地。

上述标识为（不明显）的簇不含有(0.6, 1.0]区间值。通过因素组距直方图分析，可以找到簇数为10各簇较为明显的组成因素，及各因素的组成份额。


```python
lu_storites_dem_gbh_signature=usda_signature.group_bins_histogram(clustering10_lu_stories_dem_gdf[lu_stories_dem_cols+['label']],lu_stories_dem_cols+['label'],'label',bins=[0,0.3,0.6,1])
lu_storites_dem_gbh_signature
signature_cluster_0=lu_storites_dem_gbh_signature[0].rename(columns=lc_mapping)
signature_cluster_0
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Grass_Shrub</th>
      <th>Other_Paved_Surfaces</th>
      <th>Buildings</th>
      <th>Roads_Railroads</th>
      <th>Tree_Canopy</th>
      <th>Water</th>
      <th>Bare_Soil</th>
      <th>Background</th>
      <th>stories_mean</th>
      <th>dem_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.0, 0.3]</th>
      <td>0.973634</td>
      <td>0.755718</td>
      <td>0.131512</td>
      <td>0.889454</td>
      <td>0.971728</td>
      <td>0.028907</td>
      <td>0.12770</td>
      <td>0.0</td>
      <td>0.891677</td>
      <td>0.194409</td>
    </tr>
    <tr>
      <th>(0.3, 0.6]</th>
      <td>0.000318</td>
      <td>0.237929</td>
      <td>0.794473</td>
      <td>0.065756</td>
      <td>0.000000</td>
      <td>0.002541</td>
      <td>0.00413</td>
      <td>0.0</td>
      <td>0.016836</td>
      <td>0.775731</td>
    </tr>
    <tr>
      <th>(0.6, 1.0]</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.074015</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.002541</td>
      <td>0.029860</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, axs=plt.subplots(len(lu_storites_dem_gbh_signature.keys()), 1,figsize=(20,20)) # sharex=True,sharey=True,
i=0
for c,sig in lu_storites_dem_gbh_signature.items():
    width=0.25
    multiplier=0
    x=np.arange(len(sig.columns))  # the label locations
    for attribute, measurement in sig.iterrows():
        offset=width*multiplier
        rects=axs[i].bar(x+offset, measurement, width, label=attribute)
        ax.bar_label(rects, padding=3)
        multiplier+=1    
    axs[i].set_title(f'cluster_{c}')
    axs[i].set_ylabel('frequency')
    axs[i].set_xticks(x + width, signature_cluster_0.columns)
    # axs[i].legend(loc='upper right', ncols=1)
    axs[i].set_ylim(0, 1)
    i+=1
    
handles, labels = axs[0].get_legend_handles_labels()
fig.legend(handles, labels, loc='upper right')    
fig.tight_layout()    
plt.show()      
```


<img src="./imgs/3_4_A/output_60_0.png" height='auto' width='auto' title="caDesign">    

计算各簇之间的距离，可以分析各簇相似度（或不相似度），距离算法采用`Jensen-Shan`方法。从下述图表可以观察到，簇0-簇9（0.278），簇1-簇9（0.340），簇2-簇1（0.673），簇3-簇5（0.943），簇4-簇9（0.700），簇5-簇9（0.738），簇6-簇9（0.877），簇7-簇2（0.771），簇8-簇1（0.580），簇9-簇0（0.278），是各簇对应的最相似的簇。其中簇9出现5次，一定程度上可以说明簇数选择上可以聚类为9簇更为合理，从上述折线图中也可以观察到为簇数9时，各因素的贡献度相对分开不聚拢。为了证实因素贡献度的集聚情况和离散程度，借鉴最近邻指数（Nearest Neighbor Index，NNI）（参考*更新策略*一章）计算方法，将其转换为一维度情况，定义`nni_1d()`函数，并计算标准差（参考值），按最近邻指数排序簇数，可以得知簇数为9时排序第6（总共49个簇数）。


```python
sig_distance=[]
for i,sig_i in lu_storites_dem_gbh_signature.items():
    temp=[]
    for j,sig_j in lu_storites_dem_gbh_signature.items():
        sig_d=usda_signature.Distances(sig_i.to_numpy().flatten(),sig_j.to_numpy().flatten()).shannon()['Jensen-Shan']
        temp.append(sig_d)    
    sig_distance.append(temp)
sig_distance_matrix=np.array(sig_distance)
sig_distance_matrix_df=pd.DataFrame(sig_distance_matrix,index=lu_storites_dem_gbh_signature.keys(),columns=lu_storites_dem_gbh_signature.keys())
sig_distance_matrix_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.795558</td>
      <td>1.266796</td>
      <td>1.382026</td>
      <td>0.827412</td>
      <td>1.025276</td>
      <td>1.160620</td>
      <td>1.467070</td>
      <td>1.387805</td>
      <td>0.278598</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.795558</td>
      <td>0.000000</td>
      <td>0.673072</td>
      <td>1.417022</td>
      <td>1.052836</td>
      <td>0.936881</td>
      <td>1.069788</td>
      <td>1.449296</td>
      <td>0.580868</td>
      <td>0.340732</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.266796</td>
      <td>0.673072</td>
      <td>0.000000</td>
      <td>1.203973</td>
      <td>1.243503</td>
      <td>0.956532</td>
      <td>1.022521</td>
      <td>0.771125</td>
      <td>1.120203</td>
      <td>0.803615</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.382026</td>
      <td>1.417022</td>
      <td>1.203973</td>
      <td>0.000000</td>
      <td>1.319932</td>
      <td>0.943701</td>
      <td>1.151882</td>
      <td>1.242519</td>
      <td>1.546553</td>
      <td>1.175315</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.827412</td>
      <td>1.052836</td>
      <td>1.243503</td>
      <td>1.319932</td>
      <td>0.000000</td>
      <td>1.014741</td>
      <td>1.114610</td>
      <td>1.530795</td>
      <td>1.457485</td>
      <td>0.700409</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.025276</td>
      <td>0.936881</td>
      <td>0.956532</td>
      <td>0.943701</td>
      <td>1.014741</td>
      <td>0.000000</td>
      <td>0.971058</td>
      <td>1.154118</td>
      <td>1.171058</td>
      <td>0.738562</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.160620</td>
      <td>1.069788</td>
      <td>1.022521</td>
      <td>1.151882</td>
      <td>1.114610</td>
      <td>0.971058</td>
      <td>0.000000</td>
      <td>1.206701</td>
      <td>1.305287</td>
      <td>0.877695</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.467070</td>
      <td>1.449296</td>
      <td>0.771125</td>
      <td>1.242519</td>
      <td>1.530795</td>
      <td>1.154118</td>
      <td>1.206701</td>
      <td>0.000000</td>
      <td>1.441653</td>
      <td>1.327839</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.387805</td>
      <td>0.580868</td>
      <td>1.120203</td>
      <td>1.546553</td>
      <td>1.457485</td>
      <td>1.171058</td>
      <td>1.305287</td>
      <td>1.441653</td>
      <td>0.000000</td>
      <td>1.058073</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.278598</td>
      <td>0.340732</td>
      <td>0.803615</td>
      <td>1.175315</td>
      <td>0.700409</td>
      <td>0.738562</td>
      <td>0.877695</td>
      <td>1.327839</td>
      <td>1.058073</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>



打印两两距离矩阵。


```python
sig_distance_matrix_df.style.background_gradient(cmap ='viridis').set_properties(**{'font-size': '20px'})
```




<style type="text/css">
#T_c49ba_row0_col0, #T_c49ba_row1_col1, #T_c49ba_row2_col2, #T_c49ba_row3_col3, #T_c49ba_row4_col4, #T_c49ba_row5_col5, #T_c49ba_row6_col6, #T_c49ba_row7_col7, #T_c49ba_row8_col8, #T_c49ba_row9_col9 {
  background-color: #440154;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row0_col1 {
  background-color: #1e9c89;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row0_col2, #T_c49ba_row3_col8, #T_c49ba_row4_col7, #T_c49ba_row7_col0, #T_c49ba_row7_col1, #T_c49ba_row7_col4, #T_c49ba_row7_col9, #T_c49ba_row8_col3, #T_c49ba_row8_col5, #T_c49ba_row8_col6 {
  background-color: #fde725;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col3 {
  background-color: #b8de29;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col4, #T_c49ba_row1_col0 {
  background-color: #1f9a8a;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row0_col5 {
  background-color: #addc30;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col6 {
  background-color: #b5de2b;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col7 {
  background-color: #e5e419;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col8 {
  background-color: #bade28;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row0_col9 {
  background-color: #404688;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row1_col2 {
  background-color: #1f988b;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row1_col3 {
  background-color: #c8e020;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row1_col4 {
  background-color: #3fbc73;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row1_col5 {
  background-color: #7ad151;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row1_col6, #T_c49ba_row2_col5 {
  background-color: #86d549;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row1_col7, #T_c49ba_row8_col0 {
  background-color: #dde318;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row1_col8 {
  background-color: #2c728e;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row1_col9 {
  background-color: #3a538b;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row2_col0, #T_c49ba_row4_col5 {
  background-color: #a5db36;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row2_col1 {
  background-color: #24878e;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row2_col3 {
  background-color: #6ece58;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row2_col4, #T_c49ba_row3_col7 {
  background-color: #81d34d;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row2_col6 {
  background-color: #70cf57;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row2_col7 {
  background-color: #21918c;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row2_col8, #T_c49ba_row4_col1 {
  background-color: #50c46a;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row2_col9 {
  background-color: #23a983;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row3_col0, #T_c49ba_row4_col8, #T_c49ba_row8_col7 {
  background-color: #dae319;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col1 {
  background-color: #f1e51d;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col2, #T_c49ba_row8_col4 {
  background-color: #dfe318;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col4 {
  background-color: #a2da37;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col5, #T_c49ba_row6_col2 {
  background-color: #7fd34e;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col6 {
  background-color: #b0dd2f;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row3_col9, #T_c49ba_row8_col2 {
  background-color: #b2dd2d;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row4_col0 {
  background-color: #1fa088;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row4_col2 {
  background-color: #f4e61e;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row4_col3, #T_c49ba_row4_col6 {
  background-color: #9dd93b;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row4_col9 {
  background-color: #1f978b;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row5_col0 {
  background-color: #42be71;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row5_col1 {
  background-color: #2eb37c;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row5_col2, #T_c49ba_row5_col7, #T_c49ba_row5_col8 {
  background-color: #60ca60;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row5_col3 {
  background-color: #25ab82;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row5_col4, #T_c49ba_row6_col9 {
  background-color: #34b679;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row5_col6, #T_c49ba_row6_col3 {
  background-color: #5ac864;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row5_col9 {
  background-color: #1f9e89;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row6_col0 {
  background-color: #75d054;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row6_col1 {
  background-color: #56c667;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row6_col4 {
  background-color: #52c569;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row6_col5 {
  background-color: #8ed645;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row6_col7 {
  background-color: #73d056;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row6_col8 {
  background-color: #98d83e;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row7_col2 {
  background-color: #24aa83;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row7_col3 {
  background-color: #7cd250;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row7_col5 {
  background-color: #f6e620;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row7_col6 {
  background-color: #cde11d;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row7_col8 {
  background-color: #d2e21b;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row8_col1 {
  background-color: #2a788e;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row8_col9 {
  background-color: #77d153;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row9_col0 {
  background-color: #424086;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col1 {
  background-color: #3d4e8a;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col2 {
  background-color: #2ab07f;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col3 {
  background-color: #63cb5f;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row9_col4 {
  background-color: #24868e;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col5 {
  background-color: #29af7f;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col6 {
  background-color: #38b977;
  color: #f1f1f1;
  font-size: 20px;
}
#T_c49ba_row9_col7 {
  background-color: #a8db34;
  color: #000000;
  font-size: 20px;
}
#T_c49ba_row9_col8 {
  background-color: #3dbc74;
  color: #f1f1f1;
  font-size: 20px;
}
</style>
<table id="T_c49ba">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_c49ba_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_c49ba_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_c49ba_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_c49ba_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_c49ba_level0_col4" class="col_heading level0 col4" >4</th>
      <th id="T_c49ba_level0_col5" class="col_heading level0 col5" >5</th>
      <th id="T_c49ba_level0_col6" class="col_heading level0 col6" >6</th>
      <th id="T_c49ba_level0_col7" class="col_heading level0 col7" >7</th>
      <th id="T_c49ba_level0_col8" class="col_heading level0 col8" >8</th>
      <th id="T_c49ba_level0_col9" class="col_heading level0 col9" >9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_c49ba_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_c49ba_row0_col0" class="data row0 col0" >0.000000</td>
      <td id="T_c49ba_row0_col1" class="data row0 col1" >0.795558</td>
      <td id="T_c49ba_row0_col2" class="data row0 col2" >1.266796</td>
      <td id="T_c49ba_row0_col3" class="data row0 col3" >1.382026</td>
      <td id="T_c49ba_row0_col4" class="data row0 col4" >0.827412</td>
      <td id="T_c49ba_row0_col5" class="data row0 col5" >1.025276</td>
      <td id="T_c49ba_row0_col6" class="data row0 col6" >1.160620</td>
      <td id="T_c49ba_row0_col7" class="data row0 col7" >1.467070</td>
      <td id="T_c49ba_row0_col8" class="data row0 col8" >1.387805</td>
      <td id="T_c49ba_row0_col9" class="data row0 col9" >0.278598</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_c49ba_row1_col0" class="data row1 col0" >0.795558</td>
      <td id="T_c49ba_row1_col1" class="data row1 col1" >0.000000</td>
      <td id="T_c49ba_row1_col2" class="data row1 col2" >0.673072</td>
      <td id="T_c49ba_row1_col3" class="data row1 col3" >1.417022</td>
      <td id="T_c49ba_row1_col4" class="data row1 col4" >1.052836</td>
      <td id="T_c49ba_row1_col5" class="data row1 col5" >0.936881</td>
      <td id="T_c49ba_row1_col6" class="data row1 col6" >1.069788</td>
      <td id="T_c49ba_row1_col7" class="data row1 col7" >1.449296</td>
      <td id="T_c49ba_row1_col8" class="data row1 col8" >0.580868</td>
      <td id="T_c49ba_row1_col9" class="data row1 col9" >0.340732</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_c49ba_row2_col0" class="data row2 col0" >1.266796</td>
      <td id="T_c49ba_row2_col1" class="data row2 col1" >0.673072</td>
      <td id="T_c49ba_row2_col2" class="data row2 col2" >0.000000</td>
      <td id="T_c49ba_row2_col3" class="data row2 col3" >1.203973</td>
      <td id="T_c49ba_row2_col4" class="data row2 col4" >1.243503</td>
      <td id="T_c49ba_row2_col5" class="data row2 col5" >0.956532</td>
      <td id="T_c49ba_row2_col6" class="data row2 col6" >1.022521</td>
      <td id="T_c49ba_row2_col7" class="data row2 col7" >0.771125</td>
      <td id="T_c49ba_row2_col8" class="data row2 col8" >1.120203</td>
      <td id="T_c49ba_row2_col9" class="data row2 col9" >0.803615</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_c49ba_row3_col0" class="data row3 col0" >1.382026</td>
      <td id="T_c49ba_row3_col1" class="data row3 col1" >1.417022</td>
      <td id="T_c49ba_row3_col2" class="data row3 col2" >1.203973</td>
      <td id="T_c49ba_row3_col3" class="data row3 col3" >0.000000</td>
      <td id="T_c49ba_row3_col4" class="data row3 col4" >1.319932</td>
      <td id="T_c49ba_row3_col5" class="data row3 col5" >0.943701</td>
      <td id="T_c49ba_row3_col6" class="data row3 col6" >1.151882</td>
      <td id="T_c49ba_row3_col7" class="data row3 col7" >1.242519</td>
      <td id="T_c49ba_row3_col8" class="data row3 col8" >1.546553</td>
      <td id="T_c49ba_row3_col9" class="data row3 col9" >1.175315</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_c49ba_row4_col0" class="data row4 col0" >0.827412</td>
      <td id="T_c49ba_row4_col1" class="data row4 col1" >1.052836</td>
      <td id="T_c49ba_row4_col2" class="data row4 col2" >1.243503</td>
      <td id="T_c49ba_row4_col3" class="data row4 col3" >1.319932</td>
      <td id="T_c49ba_row4_col4" class="data row4 col4" >0.000000</td>
      <td id="T_c49ba_row4_col5" class="data row4 col5" >1.014741</td>
      <td id="T_c49ba_row4_col6" class="data row4 col6" >1.114610</td>
      <td id="T_c49ba_row4_col7" class="data row4 col7" >1.530795</td>
      <td id="T_c49ba_row4_col8" class="data row4 col8" >1.457485</td>
      <td id="T_c49ba_row4_col9" class="data row4 col9" >0.700409</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_c49ba_row5_col0" class="data row5 col0" >1.025276</td>
      <td id="T_c49ba_row5_col1" class="data row5 col1" >0.936881</td>
      <td id="T_c49ba_row5_col2" class="data row5 col2" >0.956532</td>
      <td id="T_c49ba_row5_col3" class="data row5 col3" >0.943701</td>
      <td id="T_c49ba_row5_col4" class="data row5 col4" >1.014741</td>
      <td id="T_c49ba_row5_col5" class="data row5 col5" >0.000000</td>
      <td id="T_c49ba_row5_col6" class="data row5 col6" >0.971058</td>
      <td id="T_c49ba_row5_col7" class="data row5 col7" >1.154118</td>
      <td id="T_c49ba_row5_col8" class="data row5 col8" >1.171058</td>
      <td id="T_c49ba_row5_col9" class="data row5 col9" >0.738562</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_c49ba_row6_col0" class="data row6 col0" >1.160620</td>
      <td id="T_c49ba_row6_col1" class="data row6 col1" >1.069788</td>
      <td id="T_c49ba_row6_col2" class="data row6 col2" >1.022521</td>
      <td id="T_c49ba_row6_col3" class="data row6 col3" >1.151882</td>
      <td id="T_c49ba_row6_col4" class="data row6 col4" >1.114610</td>
      <td id="T_c49ba_row6_col5" class="data row6 col5" >0.971058</td>
      <td id="T_c49ba_row6_col6" class="data row6 col6" >0.000000</td>
      <td id="T_c49ba_row6_col7" class="data row6 col7" >1.206701</td>
      <td id="T_c49ba_row6_col8" class="data row6 col8" >1.305287</td>
      <td id="T_c49ba_row6_col9" class="data row6 col9" >0.877695</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_c49ba_row7_col0" class="data row7 col0" >1.467070</td>
      <td id="T_c49ba_row7_col1" class="data row7 col1" >1.449296</td>
      <td id="T_c49ba_row7_col2" class="data row7 col2" >0.771125</td>
      <td id="T_c49ba_row7_col3" class="data row7 col3" >1.242519</td>
      <td id="T_c49ba_row7_col4" class="data row7 col4" >1.530795</td>
      <td id="T_c49ba_row7_col5" class="data row7 col5" >1.154118</td>
      <td id="T_c49ba_row7_col6" class="data row7 col6" >1.206701</td>
      <td id="T_c49ba_row7_col7" class="data row7 col7" >0.000000</td>
      <td id="T_c49ba_row7_col8" class="data row7 col8" >1.441653</td>
      <td id="T_c49ba_row7_col9" class="data row7 col9" >1.327839</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_c49ba_row8_col0" class="data row8 col0" >1.387805</td>
      <td id="T_c49ba_row8_col1" class="data row8 col1" >0.580868</td>
      <td id="T_c49ba_row8_col2" class="data row8 col2" >1.120203</td>
      <td id="T_c49ba_row8_col3" class="data row8 col3" >1.546553</td>
      <td id="T_c49ba_row8_col4" class="data row8 col4" >1.457485</td>
      <td id="T_c49ba_row8_col5" class="data row8 col5" >1.171058</td>
      <td id="T_c49ba_row8_col6" class="data row8 col6" >1.305287</td>
      <td id="T_c49ba_row8_col7" class="data row8 col7" >1.441653</td>
      <td id="T_c49ba_row8_col8" class="data row8 col8" >0.000000</td>
      <td id="T_c49ba_row8_col9" class="data row8 col9" >1.058073</td>
    </tr>
    <tr>
      <th id="T_c49ba_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_c49ba_row9_col0" class="data row9 col0" >0.278598</td>
      <td id="T_c49ba_row9_col1" class="data row9 col1" >0.340732</td>
      <td id="T_c49ba_row9_col2" class="data row9 col2" >0.803615</td>
      <td id="T_c49ba_row9_col3" class="data row9 col3" >1.175315</td>
      <td id="T_c49ba_row9_col4" class="data row9 col4" >0.700409</td>
      <td id="T_c49ba_row9_col5" class="data row9 col5" >0.738562</td>
      <td id="T_c49ba_row9_col6" class="data row9 col6" >0.877695</td>
      <td id="T_c49ba_row9_col7" class="data row9 col7" >1.327839</td>
      <td id="T_c49ba_row9_col8" class="data row9 col8" >1.058073</td>
      <td id="T_c49ba_row9_col9" class="data row9 col9" >0.000000</td>
    </tr>
  </tbody>
</table>




计算1维度的最近邻指数。


```python
lu_stories_dem_best_scores_nni_df=lu_stories_dem_best_scores_df.copy(deep=True).T
val_names=lu_stories_dem_best_scores_nni_df.columns
max_val=lu_stories_dem_best_scores_nni_df.to_numpy().max()
lu_stories_dem_best_scores_nni_df['nni']=lu_stories_dem_best_scores_nni_df.apply(lambda row:usda_network.nni_1d(row[val_names].tolist(),max_val)[0],axis=1)
lu_stories_dem_best_scores_nni_df['std']=lu_stories_dem_best_scores_nni_df.apply(lambda row:row[val_names].std(),axis=1)
lu_stories_dem_best_scores_nni_df.sort_values(by=['nni','std'],ascending=False).head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>landcover_fre_2</th>
      <th>landcover_fre_7</th>
      <th>landcover_fre_5</th>
      <th>landcover_fre_6</th>
      <th>landcover_fre_1</th>
      <th>landcover_fre_4</th>
      <th>landcover_fre_3</th>
      <th>landcover_fre_0</th>
      <th>stories_mean</th>
      <th>dem_mean</th>
      <th>nni</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>16231.941444</td>
      <td>3516.760594</td>
      <td>3093.660988</td>
      <td>989.125102</td>
      <td>8734.821306</td>
      <td>74.130180</td>
      <td>26173.520524</td>
      <td>2.799040</td>
      <td>215.947590</td>
      <td>682.967678</td>
      <td>95.385941</td>
      <td>8766.510256</td>
    </tr>
    <tr>
      <th>3</th>
      <td>22459.522565</td>
      <td>4988.439700</td>
      <td>3793.440838</td>
      <td>1434.945622</td>
      <td>11541.859972</td>
      <td>135.938953</td>
      <td>439.467173</td>
      <td>5.870753</td>
      <td>284.113732</td>
      <td>853.990535</td>
      <td>83.738066</td>
      <td>7218.601958</td>
    </tr>
    <tr>
      <th>6</th>
      <td>9118.860970</td>
      <td>9013.292078</td>
      <td>5759.085705</td>
      <td>3007.994768</td>
      <td>7225.832439</td>
      <td>23415.699430</td>
      <td>1762.266628</td>
      <td>2.006683</td>
      <td>190.642039</td>
      <td>718.323101</td>
      <td>80.672665</td>
      <td>7056.920076</td>
    </tr>
    <tr>
      <th>7</th>
      <td>9429.347640</td>
      <td>3485.742367</td>
      <td>6024.705570</td>
      <td>1331.593805</td>
      <td>10040.757827</td>
      <td>19355.818289</td>
      <td>13482.805925</td>
      <td>0.325885</td>
      <td>226.188558</td>
      <td>754.925089</td>
      <td>65.629799</td>
      <td>6546.507263</td>
    </tr>
    <tr>
      <th>16</th>
      <td>6317.341453</td>
      <td>4758.620227</td>
      <td>5108.953287</td>
      <td>3411.664533</td>
      <td>7678.583321</td>
      <td>18053.644870</td>
      <td>9543.521979</td>
      <td>1.568578</td>
      <td>275.353404</td>
      <td>1146.152946</td>
      <td>64.154270</td>
      <td>5382.480896</td>
    </tr>
    <tr>
      <th>9</th>
      <td>7214.913680</td>
      <td>6365.899941</td>
      <td>4453.227444</td>
      <td>4908.185638</td>
      <td>7460.832452</td>
      <td>14521.325463</td>
      <td>9844.067084</td>
      <td>0.498452</td>
      <td>182.778024</td>
      <td>1732.738458</td>
      <td>43.884935</td>
      <td>4492.743137</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8557.231325</td>
      <td>7245.912793</td>
      <td>5963.282042</td>
      <td>5666.462124</td>
      <td>7402.586293</td>
      <td>16569.805873</td>
      <td>11275.608840</td>
      <td>0.385508</td>
      <td>256.813604</td>
      <td>604.669381</td>
      <td>42.747869</td>
      <td>5234.060065</td>
    </tr>
    <tr>
      <th>20</th>
      <td>5744.841661</td>
      <td>4878.385927</td>
      <td>4722.899831</td>
      <td>4109.115905</td>
      <td>5858.137077</td>
      <td>14234.930618</td>
      <td>7470.585373</td>
      <td>0.802378</td>
      <td>259.786855</td>
      <td>1124.097743</td>
      <td>42.652099</td>
      <td>4160.576003</td>
    </tr>
    <tr>
      <th>22</th>
      <td>6112.810738</td>
      <td>4578.179482</td>
      <td>4682.451513</td>
      <td>3396.653274</td>
      <td>5951.361424</td>
      <td>12747.017421</td>
      <td>3853.346397</td>
      <td>1.224067</td>
      <td>254.889555</td>
      <td>1429.874818</td>
      <td>38.160046</td>
      <td>3677.024369</td>
    </tr>
    <tr>
      <th>23</th>
      <td>5146.010926</td>
      <td>4281.806473</td>
      <td>5000.470527</td>
      <td>3561.352320</td>
      <td>6132.901170</td>
      <td>12182.092363</td>
      <td>6393.615917</td>
      <td>1.651258</td>
      <td>247.517775</td>
      <td>1415.834755</td>
      <td>37.920809</td>
      <td>3569.211497</td>
    </tr>
  </tbody>
</table>
</div>



#### 2） 基于 LST 冷热点舒适区域与地表覆盖类型的簇分布统计

上述通过对“因”类数据聚类，分析了聚类簇的模式组成和结构。下述提取“果”的地表温度数据，计算局部空间自相关系数，提取夏季冷点和冬季非冷点的区域交集作为舒适区域。分析舒适区域簇数为10聚类结果各类簇的数量，分析簇与地表温度的关系。

首先计算冬季地表温度的局部空间自相关系数，提取统计显著性的冷热点。


```python
la_lst0226=usda_model.moran_local_autocorrelation_gdf(zs_norm_gdf,'lst0226_mean')

from matplotlib import colors
cmap=colors.ListedColormap([ 'lightgrey', 'red', 'lightblue', 'blue', 'pink'])
usda_vis.gdf_plot_annotate(la_lst0226,"cl_li",annotate_fontsize=10,categorical=True,cmap=cmap,figsize=(20,20))
```

    ('WARNING: ', 1505, ' is an island (no neighbors)')
    [1 1 1 ... 3 3 3]
    [0.01601994 0.01602003 0.01602001 ... 0.10347612 0.10290653 0.10158318]
    p_value<0.05 num: 12179
    

<img src="./imgs/3_4_A/output_68_1.png" height='auto' width='auto' title="caDesign">
    


计算夏季地表温度的局部空间自相关系数，提取统计显著性的冷热点。


```python
la_lst0810=usda_model.moran_local_autocorrelation_gdf(zs_norm_gdf,'lst0810_mean')
usda_vis.gdf_plot_annotate(la_lst0810,"cl_li",annotate_fontsize=10,categorical=True,cmap=cmap,figsize=(20,20))
```

    ('WARNING: ', 1505, ' is an island (no neighbors)')
    [1 1 1 ... 3 3 3]
    [0.23452559 0.32599225 0.4316199  ... 4.88349186 4.03110304 4.6460232 ]
    p_value<0.05 num: 11736
    

<img src="./imgs/3_4_A/output_70_1.png" height='auto' width='auto' title="caDesign">
    

```python
la_lst0810.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>lst0810_mean</th>
      <th>li</th>
      <th>p_value_li</th>
      <th>li_005</th>
      <th>cl_li</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>POLYGON ((422430.905 4645394.671, 422280.905 4...</td>
      <td>0.783021</td>
      <td>1</td>
      <td>0.192</td>
      <td>0</td>
      <td>0 ns</td>
    </tr>
    <tr>
      <th>1</th>
      <td>POLYGON ((422430.905 4645544.671, 422280.905 4...</td>
      <td>0.802192</td>
      <td>1</td>
      <td>0.108</td>
      <td>0</td>
      <td>0 ns</td>
    </tr>
    <tr>
      <th>2</th>
      <td>POLYGON ((422430.905 4645694.671, 422280.905 4...</td>
      <td>0.813889</td>
      <td>1</td>
      <td>0.075</td>
      <td>0</td>
      <td>0 ns</td>
    </tr>
    <tr>
      <th>3</th>
      <td>POLYGON ((422430.905 4645844.671, 422280.905 4...</td>
      <td>0.819604</td>
      <td>1</td>
      <td>0.070</td>
      <td>0</td>
      <td>0 ns</td>
    </tr>
    <tr>
      <th>4</th>
      <td>POLYGON ((422430.905 4645994.671, 422280.905 4...</td>
      <td>0.814433</td>
      <td>1</td>
      <td>0.096</td>
      <td>0</td>
      <td>0 ns</td>
    </tr>
  </tbody>
</table>
</div>



计算夏季冷点和冬季非冷点的交集区域，为舒适区。


```python
lst_evaluation=la_lst0810[['geometry']]
lst_evaluation['cozy']=np.array(la_lst0810.cl_li=='3 cold spot') & np.array(la_lst0226.cl_li!='3 cold spot')
```


```python
lst_evaluation.plot(column='cozy');
```


<img src="./imgs/3_4_A/output_74_0.png" height='auto' width='auto' title="caDesign">    

统计舒适区域簇的频数，得知簇2排序第1，其以草地和林地为主；其次为簇7、9、8；频数最小的为簇0和簇6，分布以建筑和道路为主要分布。上述结果与一般常识相符合。


```python
lst_evaluation['label']=clustering10_lu_stories_dem_gdf.label
```


```python
cozy_labels=lst_evaluation.label[lst_evaluation.cozy==True]
cozy_clusters_fre=cozy_labels.value_counts().sort_values(ascending=False)
cozy_clusters_fre
```




    2    486
    7    351
    9    344
    8    343
    3    267
    1    223
    5    217
    4    170
    0     93
    6     59
    Name: label, dtype: int64



按照舒适区簇频数排序，分类为3个等级，'low'、'moderate'和'high'，绘制如下地图。'high'值区域相对具有较多草地和林地组成的样方，舒适度较好。


```python
cozy_clusters_mapping={0:'low',1:'moderate',2:'high',3:'moderate',4:'moderate',5:'moderate',6:'low',7:'high',8:'high',9:'high'}
lst_evaluation['cozy_rank']=lst_evaluation.label.apply(lambda x:cozy_clusters_mapping[x])
```


```python
cmap=colors.ListedColormap([ 'yellowgreen', 'skyblue', 'wheat'])
lst_evaluation.plot(column='cozy_rank',cmap=cmap,categorical=True,figsize=(20,20),legend=True);
```

<img src="./imgs/3_4_A/output_80_0.png" height='auto' width='auto' title="caDesign">
 

## 3.4.2 生成对抗网络（Generative Adversarial Networks，GAN） 的模式生成

生成对抗网络由 Ian J. Goodfellow 等人<sup>[1]</sup>于2014年提出，是一种深度神经网络架构，由一个生成网络（generative model，G）和一个判别网络（discriminative model，D）组成。通过 G 生成“假”数据，并试图欺骗 D 网络；而 D 网络对生成数据进行真伪鉴别，试图正确识别所有“假”数据。

生成对抗网络的提出，使得深度学习具有了“创造”的能力。GAN 目前已经发展到很多领域，例如字体生成、动漫角色生成、交互式图像生成、文字转图片、3D对象生成、图像编辑、面部年龄变化、人体姿态估计、风格样式迁移、高分辨率图像生成、物体检测识别、视频生成及预测、合成数据生成、实时人脸重建等<sup>[2]</sup>。上述应用中的风格样式迁移（style-transfer, pix2pix, sketch2image）、图像生成等，从一般意义的数据分析也跨度到了设计领域，为设计生成提供了深度学习网络模型原型。
    
就已有 GAN 网络模型的发展，结合城市空间数据分析内容，其中可以拓展的模式生成方式有，
    
1. 学习已有城市地理空间数据，例如土地利用和覆盖、遥感航拍影像等随机生成对应类型的数据（无条件约束）；
2. 使用 [Pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)<sup>⑥</sup>条件对抗网络（Conditional Adversarial Networks）进行图像（图块模式，例如土地覆盖；或线条模式）到图像（例如遥感航拍影像）的转换<sup>[3]339</sup>（有条件约束）；
3. 修复或填充地理空间数据的空白区域<sup>[4]</sup>（有条件约束）；
4. 通过提高地理空间数据精度获得样方单元的生成信息<sup>[5]</sup>（有条件约束）；
5. DEM 表征三维空间二维数据的生成<sup>[6]</sup>（无条件约束）；
6. 结合参数化设计生成地理空间设计数据作为 GAN 学习样本，生成空间数据（无条件约束）。 

### 3.4.2.1 NAIP航拍影像数据下载和制作样本数据集
    
#### 1) 数据下载    
    
关于NAIP航拍影像数据的说明可以参考*NAIP航拍影像与分割模型库及Colaboratory和Planetary Computer Hub*一章。此次实验数据的下载方式参考[NAIP: National Agriculture Imagery Program](https://planetarycomputer.microsoft.com/dataset/naip#Example-Notebook)<sup>⑦</sup>提供的方法，通过给定边界`boundary`，指定日期范围`range_date="2015-01-01/2016-01-01"`，直接下载数据。主要使用的核心库为`planetary_computer`和`pystac_client`。


```python
import pathlib
import rioxarray
import pystac_client
import planetary_computer
from shapely.geometry import shape
from IPython.display import Image
import stackstac
```

搜索数据后，返回的`items_naip`为`pystac.item_collection.ItemCollection`对象，可以直接查看数据内容。


```python
catalog = pystac_client.Client.open(
    "https://planetarycomputer.microsoft.com/api/stac/v1",
    modifier=planetary_computer.sign_inplace,
)

boundary=gpd.read_file(args.data.chicago_boundary_fn)

area_of_interest = {
    "type": "Polygon",
    "coordinates": [list(boundary.geometry[0].envelope.exterior.coords)],
    }

range_date="2015-01-01/2016-01-01"
search_naip=catalog.search(collections=["naip"], intersects=area_of_interest, datetime=range_date)
items_naip=search_naip.item_collection()
print(f"{len(items_naip)} Items found in the date range")
items_naip
```

    50 Items found in the date range
    
<img src="./imgs/3_4_A/3_4_08.png" height='auto' width='auto' title="caDesign">



`area_of_overlap`函数可以移除空间重合的数据。例如不同年份时间段获得的影像通常是重合叠加的，一般搜索时配置为一个年份周期，避免重复和不同年份影像的拼接。


```python
area_shape = shape(area_of_interest)
target_area = area_shape.area

def area_of_overlap(item):
    overlap_area = shape(item.geometry).intersection(shape(area_of_interest)).area
    return overlap_area / target_area

items_naip_=sorted(items_naip, key=area_of_overlap, reverse=True)
print(len(items_naip_))
items_naip_[:3]
```

    50
    




    [<Item id=il_m_4108702_sw_16_1_20150822_20151021>,
     <Item id=il_m_4108702_nw_16_1_20150822_20151021>,
     <Item id=il_m_4108710_nw_16_1_20150822_20151021>]



给定图像地址（url），可以直接显示查看图像。


```python
Image(url=items_naip_[0].assets["rendered_preview"].href)
```


<img src="./imgs/3_4_A/3_4_09.png" height='auto' width='auto' title="caDesign">

可以不用传统意义上先下载数据后读取，而是直接读取打开图像数据，用于分析。


```python
ds_0=rioxarray.open_rasterio(items_naip_[0].assets["image"].href).sel(band=[1, 2, 3])
ds_0
```

```
<xarray.DataArray (band: 3, y: 7593, x: 5854)>

  [133348266 values with dtype=uint8]
  Coordinates:
    * band         (band) int32 1 2 3
    * x            (x) float64 4.271e+05 4.271e+05 ... 4.329e+05 4.329e+05
    * y            (y) float64 4.644e+06 4.644e+06 ... 4.636e+06 4.636e+06
      spatial_ref  int32 0
  Attributes:
      AREA_OR_POINT:  Area
      scale_factor:   1.0
      add_offset:     0.0
```





数据下载使用`torchvision`库提供的`download_url`方法。下载前需要提取图像的网络地址（即字符`?`之前的内容）。


```python
naip_url_lst=[item.assets['image'].href.split('?')[0] for item in items_naip_]
from torchvision.datasets.utils import download_url

failed_download_info={}
for idx,item_url in enumerate(naip_url_lst):
    print(idx,end=" ")
    try:
        download_url(item_url,args.data.naip_root)
    except:
        failed_download_info[idx]=item_url
```

    0 Downloading https://naipeuwest.blob.core.windows.net/naip/v002/il/2015/il_100cm_2015/41087/m_4108702_sw_16_1_20150822.tif to F:\data\NAIP_chicago\m_4108702_sw_16_1_20150822.tif
    

    100%|█████████████████████████████████████████████████████| 186139876/186139876 [01:31<00:00, 2028283.34it/s]
    

    1 Downloading https://naipeuwest.blob.core.windows.net/naip/v002/il/2015/il_100cm_2015/41087/m_4108702_nw_16_1_20150822.tif to F:\data\NAIP_chicago\m_4108702_nw_16_1_20150822.tif
    

    100%|█████████████████████████████████████████████████████| 186908973/186908973 [01:00<00:00, 3096779.52it/s]
    

    ...
    

    31 Downloading https://naipeuwest.blob.core.windows.net/naip/v002/il/2015/il_100cm_2015/41087/m_4108719_sw_16_1_20150822.tif to F:\data\NAIP_chicago\m_4108719_sw_16_1_20150822.tif
    

     64%|██████████████████████████████████▋                   | 118751232/184675672 [09:56<05:31, 198995.93it/s]
    

    32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 

#### 2）样本数据制作

可以使用`torchgeo`库构建数据集（dataset）和数据加载器（dataloader），用于 GAN 模型训练。这里则将其转换为包含 RGB 三个通道的 JPG 格式图像，且将其保存为不同大小的图像（同一图像的不同分辨率，使用`resize`方法），置于对应的文件夹中。图像大小包括4、8、16、32、64、128、256和512等8类。一方面选择适合的分辨率用于常规 GAN 模型的训练；另一方面用于实验 [StyleGAN3](https://github.com/NVlabs/stylegan3)<sup>8</sup> 模型<sup>[7]</sup>。数据处理部分代码的实现迁移于[MarsGAN](https://github.com/kheyer/MarsGAN/blob/master/StyleGAN.ipynb)<sup>⑨</sup>，结合`torchgeo`库完成。

1. 用`torchgeo`库构建大小为512的图像数据集和数据加载器，并存储为JPG格式图像

深度学习通常需要“海量”的样本，根据样本数量的需求，随机生成图像大小为 512 像素的20,000个样本。


```python
from torchgeo.datasets import NAIP,stack_samples 
from torchgeo.samplers import RandomGeoSampler
from torch.utils.data import DataLoader
from pathlib import Path
import os
import PIL 

from fastai import *
from fastai.vision import *
```


```python
batch_size=200
image_size=512
workers=8
length=20000
num_epochs=length//batch_size

naip_dataset=NAIP(args.data.naip_root)
sampler=RandomGeoSampler(naip_dataset, size=image_size, length=length)
dataloader=DataLoader(naip_dataset, sampler=sampler, collate_fn=stack_samples,batch_size=batch_size,num_workers=workers)
```

NAIP影像有4个波段（R、G、B和NIR），保留R、G和B波段存储为 JPG 3通道图像。（PNG 格式的图像存储大小要高于 JPG）


```python
from tqdm import tqdm
import os
p_path=r'I:\data\NAIP4StyleGAN\naip_512'

for i, data in tqdm(enumerate(dataloader, 0),total=num_epochs,position=0, leave=True):
    img_batch=data['image'].numpy()
    for idx,img in enumerate(img_batch):
        plt.imsave(os.path.join(p_path,f'{i}_{idx}.jpg'),img[:3].transpose(1,2,0)/255)  
        
    if i==num_epochs:break
```

    100%|██████████████████████████████████████████████████████████████████████| 100/100 [13:12<00:00,  7.92s/it]
    

2. 建立不同图像大小的样本数据

建立对应不同图像大小的文件夹，用于存储对应大小的图像数据。


```python
path=Path(r'I:\data\NAIP4StyleGAN')
size=[4,8,16,32,64,128,256]
for s in size:
    subpath=os.path.join(path,f'patches_{s}')
    if not os.path.exists(subpath):
        os.makedirs(subpath) 
```

在后续的 GAN 实验中会使用到[fastai](https://docs.fast.ai/)库，方便数据集处理、模型构建和训练等内容。下面代码中部分方法调用于`fastai`库，例如`open_image`等。使用`resize`方法调整图像大小，用`Pillow`（`PIL`）库的方法保存图像。


```python
patch_fnames=os.listdir(path/'naip_512')

for f, filename in enumerate(patch_fnames):    
    if f%1000 == 0:
        print(f)
    
    ims = [open_image(path/'naip_512'/filename) for i in range(7)]
    
    im1 = ims[0].resize((3,256,256))
    im2 = ims[1].resize((3,128,128))    
    im3 = ims[2].resize((3,64,64))
    im4 = ims[3].resize((3,32,32))
    im5 = ims[4].resize((3,16,16))
    im6 = ims[5].resize((3,8,8))
    im7 = ims[6].resize((3,4,4))
    
    PIL.Image.fromarray(image2np(im1.data*255).astype(np.uint8)).save(path/'patches_256'/filename, quality=95)
    PIL.Image.fromarray(image2np(im2.data*255).astype(np.uint8)).save(path/'patches_128'/filename, quality=95)
    PIL.Image.fromarray(image2np(im3.data*255).astype(np.uint8)).save(path/'patches_64'/filename, quality=95)
    PIL.Image.fromarray(image2np(im4.data*255).astype(np.uint8)).save(path/'patches_32'/filename, quality=95)
    PIL.Image.fromarray(image2np(im5.data*255).astype(np.uint8)).save(path/'patches_16'/filename, quality=95)
    PIL.Image.fromarray(image2np(im6.data*255).astype(np.uint8)).save(path/'patches_8'/filename, quality=95)
    PIL.Image.fromarray(image2np(im7.data*255).astype(np.uint8)).save(path/'patches_4'/filename, quality=95)
```

    0
    1000
    2000
    3000
    4000
    5000
    6000
    7000
    8000
    9000
    10000
    11000
    12000
    13000
    14000
    15000
    16000
    17000
    18000
    19000
    

### 3.4.2.2 GAN 理解和`fastai`库 WGAN 实现——航拍影像生成实验

对 GAN 的实现综合使用[PyTorch](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)<sup>⑩</sup>深度学习库和[fastai](https://docs.fast.ai/)<sup>⑪</sup>深度学习高阶 API（Applications）实现快速的数据处理和网络模型构建及训练。对 GAN 的解释主要来源于 [DCGAN TUTORIAL](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)<sup>⑫</sup>，[fastai-GAN](https://docs.fast.ai/vision.gan.html)<sup>⑬</sup>和*Generative Adversarial Nets*<sup>[1]</sup>，并混合解释了 GAN 网络中的 DCGANs（deep convolutional generative adversarial networks ）<sup>[8]</sup>和 WGAN (Wasserstein GAN)<sup>[9]</sup>，及相关的知识点。
 
构建用于深度学习的数据集（dataset）（含变换增强（Transforms，Augmentation））和数据加载器(dataloader)，通常使用基于`PyTorch`的扩展库[PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)<sup>⑭</sup>、[fastai](https://docs.fast.ai/)<sup>⑪</sup>、[TorchGeo](https://pytorch.org/blog/geospatial-deep-learning-with-torchgeo/)<sup>⑮</sup>等。下述使用了`fastai`构建的高阶 API。


```python
from fastai.data.all import *
from fastai.callback.all import *
from fastai.vision.all import *
from fastai.vision.gan import *

from pathlib import Path
import os
```


```python
path=Path(r'I:\data\NAIP4StyleGAN')
naip_imgs_path=path/'patches_64' # Root directory for dataset
ckpts_path=Path('I:\model_ckpts\naip_GAN') # Root directory for model checkpoints
```

前文结合`TorchGeo`，使用 NAIP 航拍影像创建了 20,000个样本数据，通过`get_image_files`方法可以提取图像样本文件路径。

> 因为直接使用，例如 `from fastai.data.all import *` 种方式调入库中方法函数，因此突然出现的一些方法通常为`fastai`库中的方法。


```python
files=get_image_files(naip_imgs_path)
print(files[:3])
len(files)
```

    [Path('I:/data/NAIP4StyleGAN/patches_64/0_0.jpg'), Path('I:/data/NAIP4StyleGAN/patches_64/0_1.jpg'), Path('I:/data/NAIP4StyleGAN/patches_64/0_10.jpg')]
    




    20000



使用`DataBlock`数据块方法快速构建数据集和数据加载器。


```python
image_size=64 # Spatial size of training images. All images will be resized to this size using a transformer.
batch_size=128 # Batch size during training
nz=100 # Size of z latent vector (i.e. size of generator input)

dblock=DataBlock(
    blocks=(TransformBlock, ImageBlock),
    get_x=partial(generate_noise,size=nz),
    get_items=get_image_files,
    splitter=IndexSplitter([]),
    item_tfms=Resize(image_size, method=ResizeMethod.Crop), 
    batch_tfms=Normalize.from_stats(torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])))

dls=dblock.dataloaders(naip_imgs_path, path=naip_imgs_path, bs=batch_size)
```


```python
dls.show_batch(max_n=8)
```


<img src="./imgs/3_4_A/output_109_0.png" height='auto' width='auto' title="caDesign">    

    


GAN 是一个教授深度学习（Deep Learning，DL）模型捕获训练数据分布的一个框架。生成器（网络）不断尝试通过生成越来越好的假图像来“欺骗”判别器，判别器（网络）则努力鉴别，并对真假图像分类，这使得生成器生成的图像好像来自于训练数据真实的图像，而判别器总是以 50% 的置信度（confidence）猜测生成器生成的图像是真或假。

实验中使用转换 NAIP 的3通道（RGB）图像数据，因此配置通道（channel）数参数`nc=3`；图像大小使用 64 像素大小分辨率图像，因此配置生成器输出和判别器输入的图像大小参数`ngf=ndf=64`。


```python
nc=3 # Number of channels in the training images. For color images this is 3
ngf=64 # Size of feature maps in generator
ndf=64 # Size of feature maps in discriminator
```

#### 1）生成器（G）的层结构

`fastai`集成了基本的生成网络，直接调用`basic_generator`方法构建生成器，其中参数`in_sz`为生成的噪声数据大小，配置为 100 维度（也为默认值），即从标准正态分布中采样的潜在空间向量（latent space vector），用$z$表示。$G(z)$表示将$z$映射到训练数据空间（data-space）的生成器函数，即变量`generator`。$G$的目的是估计训练数据的分布$p_{\text {data }}$获得生成器的估计分布$p_g$来生成假数据。

打印`generator`，观察层结构，可以与下图<sup>[10]</sup>对照观察，但需要注意本次实验的生成网络第1个逆卷积（fractionally-strided convolution，deconvolution）<sup>[11]</sup>`ConvTranspose2d`的输出通道（`out_channels`）为512，而图中从1024开始。
    
<img src="./imgs/3_4_A/3_4_01.png" height='auto' width='auto' title="caDesign">

```python
generator=basic_generator(ngf, n_channels=nc,in_sz=100,n_extra_layers=1)
generator
```




    Sequential(
      (0): AddChannels()
      (1): ConvLayer(
        (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): ConvLayer(
        (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (3): ConvLayer(
        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (4): ConvLayer(
        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (5): ConvLayer(
        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (6): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (7): Tanh()
    )



* 逆卷积层 —— ConvTranspose2d

逆卷积层可以对图像进行上采样，扩大图像的尺寸。逆卷积层数据输入和输出形状（shape）计算方法为：

当，输入（input）：$(N, C_{in}, H_{in}, W_{in})$或$(C_{in}, H_{in}, W_{in})$；输出（output）:$(N, C_{out}, H_{out}, W_{out})$或$(C_{out}, H_{out}, W_{out})$，式中$N$为样本数，$C$为图像（一个样本）的通道数，$H$和$W$为图像高和宽大小。

有，$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1$；$W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1$。

逆卷积层可以看作相对于卷积`Conv2d`输入的梯度，计算原理可以从下图<sup>[12]</sup>理解。对$5 \times 5$的输入执行$1 \times 1$填充（padding）值0， $2 \times 2$步幅（stride），$3 \times 3$大小卷积核卷积，为，$i=5,k=3,s=2,p=1$；相当于，用$3 \times 3$大小卷积核卷积$3 \times 3$大小输入，卷积前输入值之间插值1个值0，执行$1 \times 1$填充值0，使用单位步幅，为$i'=3, \widetilde{ i}'=5,  k'=k,s'=1,p'=1$。


<img src="./imgs/3_4_A/3_4_02.png" height='auto' width='auto' title="caDesign">


* 标准化层 —— BatchNorm2d

深度学习每一层输入因为前一层参数的改变，其分布在训练过程中都会发生变化，往往需要较小的学习率和和小心配置初始化参数，从而减慢了训练速度，尤其难以训练具有饱和非线性（例如使用sigmoid、tanh等激活函数）的模型，称这种现象为内部协变量偏移（internal covariate shift）。解决上述问题的方法是标准化（归一化）层输入，对每个训练小批量执行标准化，从而可以使用更高的学习率，且放宽初始化配置要求<sup>[13]</sup>。

如图，假设有两个图像的小批量数据样本，F-1和F-2，每个图像含2个通道C-1和C-2，则该小批量图像通道C-1的值集合表示为$x^{(1)}=\{\mathbf{1 , 1 , 1 , 2 , 0 , - 1 , 2 , 2 ~}\}$；图像通道C-2的值集合表示为$x^{(2)}=\{-\mathbf{1 , 1 , 0 , 1 , 0 , - 1 , 3 , 1 \}}$。计算$x^{(1)}$和$x^{(2)}$的均值及方差有，$\mu_1=\frac{1}{m} \sum_{i=1}^m x_i^{(1)}=1$，$\mu_2=\frac{1}{m} \sum_{i=1}^m x_i^{(2)}=0.5 $；$\sigma_1^2=\frac{1}{m} \sum_{i=1}^m\left(x_i^{(1)}-\mu_1\right)^2=1$，$\sigma_2^2=\frac{1}{m} \sum_{i=1}^m\left(x_i^{(2)}-\mu_2\right)^2=1.5$，即$\mu=\left[\begin{array}{l}1 \\ 0.5\end{array}\right] $，$\sigma^2=\left[\begin{array}{l}1 \\ 1.5\end{array}\right]$。根据小批量标准化公式$\hat{x}_i=\frac{x_i-\mu}{\sqrt{\sigma^2+\varepsilon}}$，更新所有样本图像，所有对应通道的值，式中$\varepsilon$是为了避免分母为0的调整参数，通常配置为$\varepsilon=1e-05$。

小批量标准化公式增加有两个调整参数，分别为$\gamma$和$\beta$，默认情况下$\gamma=1$，$\beta = 0$，公式为：$\hat{x}_i=\frac{x_i-\mu}{\sqrt{\sigma^2+\varepsilon}} \gamma+\beta$，或表示为：$y=\frac{x-\mathrm{E}[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}}  \gamma+\beta$。


<img src="./imgs/3_4_A/3_4_03.png" height='auto' width='auto' title="caDesign">

* 激活层 —— ReLU()和Tanh()

参考*从解析解到数值解，从机器学习到深度学习*一章中的激活函数部分。

下述实验代码是从数据集中提取一个样本，包括一个噪声数据$z$和一个真实图像数据。对$z$执行生成网络生成一个假图像$G(z)$，同时逐层执行$G$，观察数据输入和输出的形状变化，即上采样过程。

可以直接根据图像路径，读取（`Image.open`）和打印（`show_image`）一个真实图像`im1`。


```python
im1=Image.open(files[1])
ax=show_image(im1, figsize=(2,2))
print(im1.shape)
```

    (64, 64)
    


<img src="./imgs/3_4_A/output_117_1.png" height='auto' width='auto' title="caDesign">    


通过`dblock`数据块读取数据，打印噪声数据$z$和图像数据$x$。


```python
dsets=dblock.datasets(naip_imgs_path)
im_xy=dsets[1]
im_xy
```




    (InvisibleTensor([-2.3454e+00, -1.5765e+00,  7.1060e-01, -5.7343e-01,
                       6.4001e-01, -6.0874e-01, -1.4418e-01,  4.7251e-01,
                       4.6599e-01,  3.3402e-01, -1.7018e+00,  3.8870e-01,
                       1.2323e-01, -2.1844e-01,  2.7379e-01,  3.6118e-01,
                      -1.2278e-01, -7.9387e-01,  5.2822e-02, -4.4322e-01,
                       1.5950e+00,  1.0422e+00,  1.0552e+00, -7.9903e-01,
                      -1.5224e+00, -4.7187e-01, -8.1115e-01, -3.8757e-01,
                       1.4381e+00,  5.6067e-01, -2.6452e-01,  1.5304e+00,
                      -1.3662e-01,  6.2670e-01,  7.5018e-01,  1.0567e+00,
                      -6.8847e-01, -1.6186e-01, -5.5967e-01, -2.2661e+00,
                      -3.4319e-01, -3.3552e-01,  1.1318e-01,  5.2318e-01,
                       1.0359e+00, -6.7418e-01,  5.8108e-01,  1.4617e+00,
                       1.0509e-01, -7.4633e-01, -2.3942e-01, -1.1583e+00,
                       2.5868e-01, -6.2029e-01,  1.3135e+00, -5.1513e-02,
                      -1.8016e+00,  5.2038e-01, -1.5848e-01, -1.1061e-01,
                       7.5131e-01, -6.9184e-01, -1.3670e-03, -4.6448e-01,
                       2.2224e+00,  7.4682e-01,  7.6649e-01, -3.5772e-01,
                      -7.1795e-02, -2.2193e+00, -9.1085e-01, -4.9485e-01,
                       5.5689e-01,  4.9285e-01, -1.7096e+00,  2.7568e+00,
                      -1.2357e+00, -2.5135e+00, -1.0657e+00, -1.0262e+00,
                      -1.1649e+00, -8.9837e-02, -1.1978e+00,  4.1369e-01,
                       2.3013e-01, -6.0128e-01,  1.4395e+00, -8.5148e-01,
                      -2.4028e-01, -1.6594e+00,  7.7949e-01,  8.2490e-01,
                      -8.5487e-01, -1.5042e+00,  2.2041e-01, -1.5568e+00,
                       5.8328e-01, -2.7559e-01,  8.5766e-01,  3.1389e-01]),
     PILImage mode=RGB size=64x64)



提取噪声数据为`im_x`；真实图像数据为`im_y`。


```python
im_x=im_xy[0]
im_y=im_xy[1]
print(im_x.shape,im_y.shape)
print(im_x[:10])
```

    torch.Size([100]) (64, 64)
    InvisibleTensor([-2.3454, -1.5765,  0.7106, -0.5734,  0.6400, -0.6087, -0.1442,
                      0.4725,  0.4660,  0.3340])
    


```python
ax=show_image(im_y, figsize=(2,2))
```


<img src="./imgs/3_4_A/output_122_0.png" height='auto' width='auto' title="caDesign">    


$G$的第0层，`AddChannels()`，是将形状为`(1,100)`的噪声数据变换为`(1,100,1,1)`形状，用于卷积层的输入。


```python
addChannels=generator[0]
print(addChannels)
im_x_Channels=addChannels(im_x[None,:])
print(im_x_Channels.shape)
```

    AddChannels()
    torch.Size([1, 100, 1, 1])
    

提取第1个卷积层，可以通过属性查看参数等信息，例如权重值、填充等信息。


```python
layer_1=generator[1]
print(layer_1)
print(layer_1[1].weight)
print(layer_1[0].padding)
```

    ConvLayer(
      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    Parameter containing:
    tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)
    (0, 0)
    

可以单独执行一个卷积层，查看比较数据及形状变化。


```python
im_x_Channels_layer1=layer_1(im_x_Channels)
im_x_Channels_layer1.shape
```




    torch.Size([1, 512, 4, 4])



分别单独执行生成器各层，查看比较数据形状变化，是如何由一个`(1,100)`的噪声数据，变换为`(1,3,64,64)`含3个通道，图像大小为$64 \times 64$的假图像数据。


```python
im=im_x[None,:]
print(im.shape)
for idx,layer in enumerate(generator):        
    im=layer(im)
    print(f'{idx}------{im.shape}')
```

    torch.Size([1, 100])
    0------torch.Size([1, 100, 1, 1])
    1------torch.Size([1, 512, 4, 4])
    2------torch.Size([1, 256, 8, 8])
    3------torch.Size([1, 128, 16, 16])
    4------torch.Size([1, 64, 32, 32])
    5------torch.Size([1, 64, 32, 32])
    6------torch.Size([1, 3, 64, 64])
    7------torch.Size([1, 3, 64, 64])
    

一次性执行`generator`，即生成器$G$，获得假图像数据`im_x_G`。


```python
im_x_G=generator(im_x[None,:])
print(im_x_G.shape)
```

    torch.Size([1, 3, 64, 64])
    

噪声数据的大小可以调整，上述实验的噪声数据为100，下面配置为512，输出同样形状的假数据。


```python
x=torch.randn(1, 512)
generator(im_x[None,:]).shape
```




    torch.Size([1, 3, 64, 64])



#### 2） 判别器（D）的层结构

一个图像表示为$x$，则$D(x)$为$x$执行判别网络$G$的结果，是鉴别$x$来自于训练数据集的真实图像，还是由噪声$z$通过$G$生成的$G(z)$假图像的标量概率。如果$x$来自于训练数据集，则$D(x)$值趋高；如果$x$来自于生成器$G$，则值趋低，因此$D$可以认为是传统意义上的二元分类器（参考*逻辑回归二分类到 SoftMax 回归多分类*一章的解释）。对于来自$G$的生成（假）图像$G(z)$的$D$结果可表示为$D(G(z))$。$D$试图鉴别假图像，表示为$logD(x)$，而$G$试图使生成的假图像趋真，即使$D$的预测输出为假可能性降低，表示为$log(1-D(G(z)))$。因此 GAN 的损失函数表示为： $\min _G \max _D V(D, G)=\mathbb{E}_{x \sim p_{\text {data }}(x)}[\log D(x)]+\mathbb{E}_{z \sim p_z(z)}[\log (1-D(G(z)))]$，理论上极大极小博弈的解是当$p_g=p_{data}$时。

通过`fastai`的`basic_critic`方法直接构建判别网络$D$。与$G$一样，逐层计算观察数据形状变化。$D$网络卷积层包括`Conv2d`二维卷积，`BatchNorm2d`标准化，和激活函数`nn.LeakyReLU`。当使用 WGAN 网络时，$D$的第6层配置为`fastai.layers.Flatten(full=False)`，仅将输入数据压成一维数据；当使用 DCGAN 时，最后一层为`Sigmoid()`层，将值归一化到[0,1]之间的一个标量概率，用于（真假）二元分类。


```python
critic=basic_critic(ndf, n_channels=nc, n_extra_layers=1, act_cls=partial(nn.LeakyReLU, negative_slope=0.2))
critic
```




    Sequential(
      (0): ConvLayer(
        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
      )
      (1): ConvLayer(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.2)
      )
      (2): ConvLayer(
        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.2)
      )
      (3): ConvLayer(
        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.2)
      )
      (4): ConvLayer(
        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.2)
      )
      (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))
      (6): fastai.layers.Flatten(full=False)
    )



* `LeakyReLU`与`ReLU`主要区别是小于0的区间有一个倾斜，而不是完全水平的值0，如下图。


```python
m=nn.LeakyReLU(0.1)
input,_=torch.randn(100).sort()
output=m(input)

fig=plt.figure()
ax=fig.add_subplot(1,1,1)
ax.plot(input,output)
plt.show()
```

<img src="./imgs/3_4_A/output_138_0.png" height='auto' width='auto' title="caDesign">


逐层执行$D$，查看数据和形状变化。输入为一个图像，形状为`(1,3,64,64)`，一个样本，含3个通道，大小为$64 \times 64$的图像；输出为一个标量值。


```python
im=image2tensor(im_y)[None,:]/255.
print(im.shape)
for idx,layer in enumerate(critic):        
    im=layer(im)
    print(f'{idx}------{im.shape}')
```

    torch.Size([1, 3, 64, 64])
    0------torch.Size([1, 64, 32, 32])
    1------torch.Size([1, 64, 32, 32])
    2------torch.Size([1, 128, 16, 16])
    3------torch.Size([1, 256, 8, 8])
    4------torch.Size([1, 512, 4, 4])
    5------torch.Size([1, 1, 1, 1])
    6------torch.Size([1, 1])
    

计算训练数据集真实图像的$D$，并通过`torch.sigmoid`方法归一化。


```python
critic.zero_grad() # to make sure all grads are zero
im_y_D=critic(image2tensor(im_y)[None,:]/255.)
print(im_y_D)
im_y_D_sigmoid=torch.sigmoid(im_y_D)
print(im_y_D_sigmoid)
```

    tensor([[48.6151]], grad_fn=<ViewBackward0>)
    tensor([[1.]], grad_fn=<SigmoidBackward0>)
    

计算$D(G(z))$，即$G$生成图像$G(z)$的$D$，同样`torch.sigmoid`方法归一化。


```python
im_x_G_D=critic(im_x_G)
print(im_x_G_D)
im_x_G_D_sigmoid=torch.sigmoid(im_x_G_D)
print(im_x_G_D_sigmoid)
```

    InvisibleTensor([[39.8883]], grad_fn=<AliasBackward0>)
    InvisibleTensor([[1.]], grad_fn=<AliasBackward0>)
    

为了比较训练图像和生成假图像的$D(x)$结果，另从训练数据中又提取了一个真实图像，以两个真实图像和生成假图像比较。


```python
im_xy_comp=dsets[7]
im_y_comp=im_xy_comp[1]
ax=show_image(im_y_comp, figsize=(2,2))

im_y_comp_D=critic(image2tensor(im_y_comp)[None,:]/255.)
print(im_y_comp_D)
im_y_comp_D_sigmoid=torch.sigmoid(im_y_comp_D)
print(im_y_comp_D_sigmoid)
```

    tensor([[0.9176]], grad_fn=<ViewBackward0>)
    tensor([[0.7146]], grad_fn=<SigmoidBackward0>)
    


<img src="./imgs/3_4_A/output_146_1.png" height='auto' width='auto' title="caDesign">    


#### 3) 训练判别器$D$

使用适用于0/1二分类的二值交叉熵损失（Binary Cross Entropy Loss，BCELoss）计算$D(x)$到真实标签（real label）值1，或假标签（fake labe）值0的距离（概率），其公式为：$\ell(x, y)=L=\left\{l_1, \ldots, l_N\right\}^{\top}, \quad l_n=-\left[y_n \cdot \log x_n+\left(1-y_n\right) \cdot \log \left(1-x_n\right)\right]$，式中，$y_n$为真假标签（1或0），$x_n$为预测输出（即$D(x)$）。BCELoss 的学习目标就是让$D(x)$逼近指定的标签值0或1，因此计算训练数据真实图像指定`BCELossFlat()`方法输入参数`target`为1；计算生成假图像指定`BCELossFlat()`方法输入参数`target`为0，训练模型。下述单样本计算的结果显示，训练数据真实值的 BCELoss 结果为1.047；生成假图像的 BCELoss 结果为0.143；参照图像结果为 0.336。对于生成假图像的计算如果指定的标签为真值1，则公式为$log(1-D(G(z)))$；如果指定的标签为假值0，则公式为$log(D(G(z)))$，因此下述代码`tst(im_x_G_D_sigmoid,label_fake) `和`tst(1-im_x_G_D_sigmoid,label_real)`计算结果同。


```python
tst=BCELossFlat() # 相当于 nn.BCELoss()

label_real=torch.full((im_y_D_sigmoid.size(0),), 1, dtype=torch.float)
label_fake=torch.full((im_y_D_sigmoid.size(0),), 0, dtype=torch.float)
print(f'real label:{label_real};\nfake label:{label_fake}')

im_y_D_sigmoid_tst_real=tst(im_y_D_sigmoid,label_real)
im_x_G_D_sigmoid_tst_fake=tst(im_x_G_D_sigmoid,label_fake) # 同 tst(1-im_x_G_D_sigmoid,label_real)
im_y_comp_D_sigmoid_real=tst(im_y_comp_D_sigmoid,label_real)
print(f'im_y_D_sigmoid_tst_real:\t{im_y_D_sigmoid_tst_real}\nim_x_G_D_sigmoid_tst_fake:\t{im_x_G_D_sigmoid_tst_fake}\nim_y_comp_D_sigmoid_real:\t{im_y_comp_D_sigmoid_real}')
```

    real label:tensor([1.]);
    fake label:tensor([0.])
    im_y_D_sigmoid_tst_real:	TensorBase(1.0470, grad_fn=<AliasBackward0>)
    im_x_G_D_sigmoid_tst_fake:	TensorBase(0.1433, grad_fn=<AliasBackward0>)
    im_y_comp_D_sigmoid_real:	TensorBase(0.3361, grad_fn=<AliasBackward0>)
    

训练$D$的目标就是最大化给定输入（训练数据集真实图像和生成假图像）为真或假的概率，即最大化`errD`（$\log (D(x))+\log (1-D(G(z)))$）的概率。通过对$log(D(x))$，$x$为训练数据真实图像，和$log(1-D(G(z)))$，分别对应的变量为`im_y_D_sigmoid_tst_real`和`im_x_G_D_sigmoid_tst_fake`，对其执行反向传播`.backward`后，结合优化算法更新$D$网络的参数。优化算法对于 DCGAN 参考选择`Adam`，对于 WGAN 参考选择 `RMSProp`。下述针对 DCGAN 使用了`Adam`优化算法。


```python
errD=im_y_D_sigmoid_tst_real+im_x_G_D_sigmoid_tst_fake
print(errD)
```

    TensorBase(1.1903, grad_fn=<AliasBackward0>)
    

查看$D$网络的参数（权重（weights）和偏置（biases））。


```python
list(critic.parameters())[0][:1]
```




    tensor([[[[-0.0611, -0.2790,  0.1526,  0.0098],
              [-0.2067,  0.0547,  0.0916,  0.1760],
              [ 0.2402,  0.2054, -0.0340,  0.0343],
              [ 0.0649,  0.2564,  0.2802, -0.0319]],
    
             [[-0.1696, -0.1078,  0.3393, -0.2552],
              [ 0.1721,  0.2788,  0.1575,  0.2830],
              [-0.3075,  0.3486,  0.0972,  0.2338],
              [-0.2867,  0.0078, -0.0618, -0.1351]],
    
             [[-0.0362,  0.0999,  0.3280,  0.0710],
              [-0.1982,  0.1575,  0.1228,  0.0044],
              [ 0.1492, -0.1891,  0.0745, -0.2384],
              [ 0.3277,  0.0755, -0.2309, -0.1302]]]], grad_fn=<SliceBackward0>)



如果不执行反向传播，并不会更新模型的参数值，如下查看参数结果同上。


```python
lr=0.1 # 2e-4
opt_D=Adam(critic.parameters(), lr=lr)
opt_D.step()
list(critic.parameters())[0][:1]
```




    tensor([[[[-0.0611, -0.2790,  0.1526,  0.0098],
              [-0.2067,  0.0547,  0.0916,  0.1760],
              [ 0.2402,  0.2054, -0.0340,  0.0343],
              [ 0.0649,  0.2564,  0.2802, -0.0319]],
    
             [[-0.1696, -0.1078,  0.3393, -0.2552],
              [ 0.1721,  0.2788,  0.1575,  0.2830],
              [-0.3075,  0.3486,  0.0972,  0.2338],
              [-0.2867,  0.0078, -0.0618, -0.1351]],
    
             [[-0.0362,  0.0999,  0.3280,  0.0710],
              [-0.1982,  0.1575,  0.1228,  0.0044],
              [ 0.1492, -0.1891,  0.0745, -0.2384],
              [ 0.3277,  0.0755, -0.2309, -0.1302]]]], grad_fn=<SliceBackward0>)



通过损失函数（BCELoss）计算预测值（$D(x)$）和对应标签（0/1）的误差后，当对误差张量（error tensor）调用`.backward`时，则会执行反向传播，然后自动梯度（`Autograd`）计算每个模型参数的梯度（gradients），并将其存储在参数的`.grad`属性中，且通过优化算法更新模型参数值。对网络模型（$D$或$G$）定义优化算法（优化器（optimizer）），调用`optimizer.step()`启动梯度下降，优化器通过存储在`.grad`属性中的梯度调整每个模型参数。


```python
im_y_D_sigmoid_tst_real.backward()
im_x_G_D_sigmoid_tst_fake.backward()
```


```python
opt_D.step()
list(critic.parameters())[0][:1]
```




    tensor([[[[ 0.0387, -0.1787,  0.0524, -0.0902],
              [-0.1065,  0.1546, -0.0084,  0.0758],
              [ 0.1403,  0.3051,  0.0661, -0.0657],
              [-0.0352,  0.3561,  0.1799, -0.1318]],
    
             [[-0.0694, -0.0077,  0.2390, -0.3550],
              [ 0.2719,  0.3785,  0.0574,  0.1827],
              [-0.4071,  0.4483,  0.1970,  0.1336],
              [-0.3864,  0.1077,  0.0382, -0.0352]],
    
             [[ 0.0638,  0.1997,  0.2277, -0.0291],
              [-0.0980,  0.2574,  0.0227, -0.0956],
              [ 0.0505, -0.0889,  0.1744, -0.3381],
              [ 0.2274,  0.1754, -0.1307, -0.0301]]]], grad_fn=<SliceBackward0>)



#### 4）训练生成器$G$

在训练判别器$D$计算损失函数时，是最大化训练数据集真图像为真，生成假图像为假的概率。训练生成器$G$时，损失函数计算的方式是生成假图像为真的概率，即 BCELoss 输入参数`taget`的值为真标签值1，对应代码为`tst(im_x_G_D_sigmoid,label_real)`。然后执行反向传播，更新$G$网络。


```python
generator.zero_grad()
im_x_G_D4G=critic(im_x_G)
im_x_G_D4G_sigmoid=torch.sigmoid(im_x_G_D4G)

im_x_G_D4G_sigmoid_tst_real=tst(im_x_G_D4G_sigmoid,label_real)
print(im_x_G_D4G_sigmoid_tst_real)
```

    TensorBase(0., grad_fn=<AliasBackward0>)
    


```python
im_x_G_D4G_sigmoid_tst_real.backward()
opt_G=Adam(generator.parameters(), lr=lr)
opt_G.step()
```

#### 5) 训练模型（WGAN方式）

Goodfellow,I.J.等人提出 GAN 时给出了伪代码<sup>[1]</sup>如下：

```algorithm
% GAN
\begin{algorithm}
\caption{Minibatch stochastic gradient descent training of generative adversarial nets. The number of steps to apply to the discriminator, $k$, is a hyperparameter. We used $k=1$, the least expensive option, in our experiments.}
\begin{algorithmic}
\FOR{number of training iterations}
\FOR{$k$ steps}
\STATE • Sample minibatch of $m$ noise samples $\left\{\boldsymbol{z}^{(1)}, \ldots, \boldsymbol{z}^{(m)}\right\}$ from noise prior $p_g(\boldsymbol{z})$.
\STATE • Sample minibatch of $m$ examples $\left\{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)}\right\}$ from data generating distribution $p_{\text {data }}(\boldsymbol{x})$.
\STATE • Update the discriminator by ascending its stochastic gradient:$\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^m\left[\log D\left(\boldsymbol{x}^{(i)}\right)+\log \left(1-D\left(G\left(\boldsymbol{z}^{(i)}\right)\right)\right)\right] .$
\ENDFOR
\STATE • Sample minibatch of $m$ noise samples $\left\{\boldsymbol{z}^{(1)}, \ldots, \boldsymbol{z}^{(m)}\right\}$ from noise prior $p_g(\boldsymbol{z})$.
\STATE • Update the generator by descending its stochastic gradient:$\nabla_{\theta_g} \frac{1}{m} \sum_{i=1}^m \log \left(1-D\left(G\left(\boldsymbol{z}^{(i)}\right)\right)\right) \text {. }$
\ENDFOR
\STATE The gradient-based updates can use any standard gradient-based learning rule. We used momentum in our experiments.
\end{algorithmic}
\end{algorithm}
```

并用图示拟合一维高斯分布的方法解释了 GAN 的计算过程<sup>[14]</sup>，

<img src="./imgs/3_4_A/3_4_04.png" height='auto' width='auto' title="caDesign">

将$G$的目标理解为学习真实分布的逆累积分布函数（cumulative distribution function，CDF）的缩放（scaling）过程。GAN 通过同时更新$D$（蓝色虚线）进行训练，以便区分真实分布（黑色虚线）$P_r$样本和生成分布（绿色实线）$P_g$样本。下面的水平线是对$z$进行采样的域（domain），本例为均匀采样。上面的水平线是$x$的一部分。向上的箭头显示映射$x=G(z)$是如何将非均匀分布$P_g$强加到变换后的样本上。$G$在$P_g$的高密度区域收缩，并扩展到低密度区域。

（a）这个案例中，$P_g$被初始化为标准正态分布（unit Gaussian）；$D$为随机初始化的深度神经网络定义；

（b）假设$G$保持不变，$D$训练收敛至$D^*(X)=\frac{p_{\text {r }}(x)}{p_{\text {r }}(x)+p_{\text {g }}(x)}$。（实际两者同时训练）；

（c）假设$G$和$D$逐渐训练了一段时间，$G$生成的样本$x$沿着$D$增加的方向流动，以便达到可能被分类为真实分布的区域。同时，对应$G$的参数更新，更新$D$的参数；

（d）在纳什均衡（Nash equilibrium）中，由于$P_g=P_r$，两个参与者都不能提高收益，$D$无法区分这两个分布，即这个常量函数（constant function）表明所有点都同样可能来自任意分布。


上述原始 GAN 达到纳什均衡的理想结果通常很困难，损失函数的误差曲线降不下去（梯度消失，例如$D$训练的越好，$G$的梯度消失越严重）或者波动较大（梯度不稳定），很难从生成器和判别器的损失函数误差曲线上判断训练好坏程度。<sup>[15]</sup>。Arjovsky, M.<sup>[9]</sup>等提出了 WGAN， 应用 wasserstein（或称为 Earth-Mover (EM)） 距离解决了上述问题。

* EM 距离（wasserstein-1 distance）

EM 距离是用来衡量两个概率分布之间差异的方法，为由一个分布转化为另一个分布的最小成本。`SciPy`库的`scipy.stats.wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None)`方法提供了 EM 距离计算，其中，`u_values`和`v_values`为（经验）分布中观测到的值；`u_weights`和`v_weights`可以为每个值指定权重。EM 距离计算公式按 Arjovsky, M.论文中的表述给出为：$W\left(\mathbb{P}_r, \mathbb{P}_g\right)=\inf _{\gamma \in \Pi\left(\mathbb{P}_r, \mathbb{P}_g\right)} \mathbb{E}_{(x, y) \sim \gamma}[\|x-y\|]$，式中，$\Pi\left(\mathbb{P}_r, \mathbb{P}_g\right)$为边缘分布（marginals）分别为$\mathbb{P}_r$和$\mathbb{P}_g$的所有联合分布（joint distributions）$ \gamma(x,y)$。直观的说，$ \gamma(x,y)$ 表示必须将多少“质量（mass）”从$x$传输到$y$，以便将分布$\mathbb{P}_r$转化为分布$\mathbb{P}_g$。

> 关于计算两个概率分布之间差异（距离）的方法可以同时参考*标记距离*一章距离度量部分。

下面应用`wasserstein_distance`方法，假设分布$P$和$Q$，计算两种情况下的 EM 距离。将横轴值作为观测到的值，对应变量`vals`；将纵轴值作为对应观测值观测到的频数，即$P$和$Q$分布。


```python
from scipy.stats import wasserstein_distance
import matplotlib.pyplot as plt

P=[3,5,2,1,3]
Q=[2,3,4,5,0]
vals=[0,1,2,3,4]
print(wasserstein_distance(vals,vals,P,Q))

fig,axs=plt.subplots(1,2,layout='constrained',sharey=True,figsize=(4,2))
axs[0].stem(vals, P)
axs[1].stem(vals,Q)

axs[0].vlines(x=vals,ymin=0,ymax=5,colors='gray',linestyles='dashed')
axs[1].vlines(x=vals,ymin=0,ymax=5,colors='gray',linestyles='dashed')
plt.show()
```

    0.5714285714285714
    


<img src="./imgs/3_4_A/output_162_1.png" height='auto' width='auto' title="caDesign">    


```python
P=[1,2,1]
Q=[1,2,1]
vals_P=[0,1,2]
vals_Q=[3,4,5]
vals=vals_P+vals_Q
print(wasserstein_distance(vals_P,vals_Q,P,Q))

_,axs=plt.subplots(1,2,layout='constrained',sharey=True,figsize=(4,2))
axs[0].stem(vals,P+[0,0,0])
axs[1].stem(vals,[0,0,0]+Q)

axs[0].vlines(x=vals,ymin=0,ymax=5,colors='gray',linestyles='dashed')
axs[1].vlines(x=vals,ymin=0,ymax=5,colors='gray',linestyles='dashed')
plt.show()
```

    3.0
    


<img src="./imgs/3_4_A/output_163_1.png" height='auto' width='auto' title="caDesign">    


从上述第2个假设的分布可以得知，即使$P$和$Q$两个分布没有重叠，EM 距离计算结果也能够反映二者的远近，因此用梯度下降法优化 EM 距离，表示为$W(P,Q)$，可以提供有意义的梯度。结合到 WGAN，$G$的损失函数定义为：$-\mathbb{E}_{x \sim P_g}\left[f_w(x)\right]$；$D$的损失函数定义为：$\mathbb{E}_{x \sim P_g}\left[f_w(x)\right]-\mathbb{E}_{x \sim P_r}\left[f_w(x)\right]$，式中，$f_w$为$D$。$D$的损失函数可以指示训练进程，其值越小，表示生成分布到真实分布的 EM 距离越小，GAN 模型训练的越好。

WGAN 的伪代码<sup>[9]</sup>如下：

```algorithm
% WGAN
\begin{algorithm}
\caption{WGAN, our proposed algorithm. All experiments in the paper used the default values $\alpha=0.00005, c=0.01, m=64, n_{\text {critic }}=5$}
\begin{algorithmic}
\REQUIRE $\alpha$, the learning rate. $c$, the clipping parameter. $m$, the batch size. $n_{\text {critic }}$, the number of iterations of the critic per generator iteration.
\REQUIRE $w_0$, initial critic parameters. $\theta_0$, initial generator's parameters.
\WHILE{$\theta$ has not converged}
\FOR{$t=0, \ldots, n_{\text {critic }}$}
\STATE Sample $\left\{x^{(i)}\right\}_{i=1}^m \sim \mathbb{P}_r$ a batch from the real data.
\STATE Sample $\left\{z^{(i)}\right\}_{i=1}^m \sim p(z)$ a batch of prior samples.
\STATE $g_w \leftarrow \nabla_w\left[\frac{1}{m} \sum_{i=1}^m f_w\left(x^{(i)}\right)-\frac{1}{m} \sum_{i=1}^m f_w\left(g_\theta\left(z^{(i)}\right)\right)\right] $
\STATE $w \leftarrow w+\alpha \cdot \operatorname{RMSProp}\left(w, g_w\right)$
\STATE $w \leftarrow \operatorname{clip}(w,-c, c)$
\ENDFOR
\STATE Sample $\left\{z^{(i)}\right\}_{i=1}^m \sim p(z)$ a batch of prior samples.
\STATE $g_\theta \leftarrow-\nabla_\theta \frac{1}{m} \sum_{i=1}^m f_w\left(g_\theta\left(z^{(i)}\right)\right) $
\STATE $\theta \leftarrow \theta-\alpha \cdot \operatorname{RMSProp}\left(\theta, g_\theta\right)$
\ENDWHILE
\end{algorithmic}
\end{algorithm}
```

因为遥感（航拍）地物繁多，形式复杂且模式近似，用于 MNIST、CIFAR10 等自然图像及 Imagenet 数据集表现良好的 GAN 模型，可能对高分辨率的遥感影像分布学习生成失去作用<sup>[16]</sup>。上述阐释的 WGAN 表现也同样并不理想。 

在训练过程在中，增加了`SaveModelCallback`回调函数，用于根据指定的损失函数`monitor`，变化幅度`min_delta`，保存的文件名`fname`，根据训练情况保存模型参数；同时也使用`leaner.save()`的方法保存模型，用`leaner.load()`可以加载保存的模型。观察下述训练过程的`crit_loss`变化，当学习率配置为`lr=1e-5`时，`crit_loss`能够稳步下降。

> 深度学习模型的训练在[CoLab](https://colab.research.google.com/)中完成。


```python
cbs=[SaveModelCallback(monitor='crit_loss',min_delta=0.01,  with_opt=True,fname='naip_wgan_b_ckpt',)] # EarlyStoppingCallback(monitor='gen_loss', min_delta=0.01, patience=10),
learn=GANLearner.wgan(dls, generator, critic, opt_func=RMSProp,
                      path=ckpts_path,
                      cbs=cbs,
                      lr=1e-5, # 2e-4
                      clip=0.01,
                      switcher=FixedGANSwitcher(n_crit=5, n_gen=1),
                      switch_eval=False
                      )

learn.recorder.train_metrics=True
learn.recorder.valid_metrics=False
```

迭代5轮次，从显示结果可以看到色彩、模式、对象形态还都没有显现。


```python
learn.fit_one_cycle(5,wd=0.) 
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>gen_loss</th>
      <th>crit_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-0.027092</td>
      <td>0.016904</td>
      <td>-0.022706</td>
      <td>00:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-0.268401</td>
      <td>0.159419</td>
      <td>-0.267501</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-0.499596</td>
      <td>0.321357</td>
      <td>-0.620705</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-0.591036</td>
      <td>0.385114</td>
      <td>-0.764294</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-0.613021</td>
      <td>0.403253</td>
      <td>-0.803440</td>
      <td>00:18</td>
    </tr>
  </tbody>
</table>

    

    Better model found at epoch 0 with crit_loss value: -0.02270558290183544.
    Better model found at epoch 1 with crit_loss value: -0.2675013840198517.
    Better model found at epoch 2 with crit_loss value: -0.6207051873207092.
    Better model found at epoch 3 with crit_loss value: -0.764293909072876.
    Better model found at epoch 4 with crit_loss value: -0.8034396767616272.
    

-1.3153190612792969.

0.0058530885726213455.


```python
learn.show_results(max_n=3, ds_idx=0)
```


<img src="./imgs/3_4_A/output_170_2.png" height='auto' width='auto' title="caDesign">
    


继续迭代10轮次，色彩开始趋向于真实样本，对象形态雏形隐约显现。


```python
learn.fit_one_cycle(10)
```


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>gen_loss</th>
      <th>crit_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-0.606376</td>
      <td>0.399832</td>
      <td>-0.815916</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-0.689078</td>
      <td>0.439710</td>
      <td>-0.882295</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-0.789199</td>
      <td>0.498843</td>
      <td>-1.008572</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-0.875738</td>
      <td>0.554583</td>
      <td>-1.128081</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-0.930151</td>
      <td>0.591104</td>
      <td>-1.206856</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>5</td>
      <td>-0.965422</td>
      <td>0.614313</td>
      <td>-1.255906</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>6</td>
      <td>-0.989825</td>
      <td>0.631252</td>
      <td>-1.290740</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>7</td>
      <td>-1.004018</td>
      <td>0.641229</td>
      <td>-1.311686</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>8</td>
      <td>-1.010721</td>
      <td>0.646002</td>
      <td>-1.321508</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>9</td>
      <td>-1.012111</td>
      <td>0.647487</td>
      <td>-1.324434</td>
      <td>00:17</td>
    </tr>
  </tbody>
</table>


    Better model found at epoch 0 with crit_loss value: -0.8159159421920776.
    Better model found at epoch 1 with crit_loss value: -0.8822952508926392.
    Better model found at epoch 2 with crit_loss value: -1.0085723400115967.
    Better model found at epoch 3 with crit_loss value: -1.1280813217163086.
    Better model found at epoch 4 with crit_loss value: -1.206856369972229.
    Better model found at epoch 5 with crit_loss value: -1.255906105041504.
    Better model found at epoch 6 with crit_loss value: -1.29073965549469.
    Better model found at epoch 7 with crit_loss value: -1.311686396598816.
    Better model found at epoch 9 with crit_loss value: -1.32443368434906.
    


```python
learn.show_results(max_n=3, ds_idx=0)
```

<img src="./imgs/3_4_A/output_173_2.png" height='auto' width='auto' title="caDesign">   

继续迭代10轮次，`crit_loss`稳步下降收敛。色彩继续趋于真实分布。


```python
learn.fit_one_cycle(10)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>gen_loss</th>
      <th>crit_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-0.982120</td>
      <td>0.635491</td>
      <td>-1.327267</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-1.029104</td>
      <td>0.657207</td>
      <td>-1.343396</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-1.053444</td>
      <td>0.671278</td>
      <td>-1.372857</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-1.074646</td>
      <td>0.685937</td>
      <td>-1.402718</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-1.095327</td>
      <td>0.696518</td>
      <td>-1.427755</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>5</td>
      <td>-1.111538</td>
      <td>0.706379</td>
      <td>-1.449256</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>6</td>
      <td>-1.126531</td>
      <td>0.715450</td>
      <td>-1.470485</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>7</td>
      <td>-1.136540</td>
      <td>0.722365</td>
      <td>-1.485029</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>8</td>
      <td>-1.141410</td>
      <td>0.725229</td>
      <td>-1.491761</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>9</td>
      <td>-1.142409</td>
      <td>0.726656</td>
      <td>-1.494095</td>
      <td>00:17</td>
    </tr>
  </tbody>
</table>


    Better model found at epoch 0 with crit_loss value: -1.3272665739059448.
    Better model found at epoch 1 with crit_loss value: -1.3433961868286133.
    Better model found at epoch 2 with crit_loss value: -1.3728567361831665.
    Better model found at epoch 3 with crit_loss value: -1.402718424797058.
    Better model found at epoch 4 with crit_loss value: -1.427754521369934.
    Better model found at epoch 5 with crit_loss value: -1.4492558240890503.
    Better model found at epoch 6 with crit_loss value: -1.4704854488372803.
    Better model found at epoch 7 with crit_loss value: -1.4850293397903442.
    


```python
learn.show_results(max_n=3, ds_idx=0)
```


<img src="./imgs/3_4_A/output_176_2.png" height='auto' width='auto' title="caDesign">

    


继续迭代200轮次，色彩基本同真实图像，对象形态继续得到优化。


```python
learn.fit_one_cycle(200)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>gen_loss</th>
      <th>crit_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-1.103175</td>
      <td>0.713960</td>
      <td>-1.490784</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-1.140194</td>
      <td>0.725834</td>
      <td>-1.492246</td>
      <td>00:18</td>
    </tr>    
        <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr> 
    <tr>
      <td>197</td>
      <td>-1.182713</td>
      <td>0.755221</td>
      <td>-1.547309</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>198</td>
      <td>-1.182745</td>
      <td>0.755224</td>
      <td>-1.547347</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>199</td>
      <td>-1.182684</td>
      <td>0.755274</td>
      <td>-1.547368</td>
      <td>00:18</td>
    </tr>    
  </tbody>
</table><p>

    Better model found at epoch 155 with crit_loss value: -1.546173334121704.
    


```python
learn.show_results(max_n=3, ds_idx=0)
```

<img src="./imgs/3_4_A/output_179_2.png" height='auto' width='auto' title="caDesign">    


当训练时间较长时，可以保存模型，避免训练参数丢失。当再需要继续训练时，可以加载模型。


```python
learn.save(ckpts_path/'naip_wgan_b_learn',with_opt=True)
```




    Path('/content/gdrive/MyDrive/Colab_Notebooks/model_checkpoint/ckpts4NaipGAN/naip_wgan_b_learn.pth')




```python
learn.load(ckpts_path/'naip_wgan_b_learn',with_opt=True)
```




    <fastai.vision.gan.GANLearner at 0x7ff1d17cd130>



加载保存的训练模型后，继续训练。


```python
learn.recorder.train_metrics=True
learn.recorder.valid_metrics=False

learn.fit_one_cycle(100) 
```


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>gen_loss</th>
      <th>crit_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-1.143211</td>
      <td>0.743186</td>
      <td>-1.546363</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-1.180329</td>
      <td>0.754740</td>
      <td>-1.546314</td>
      <td>00:18</td>
    </tr>    
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>98</td>
      <td>-1.157531</td>
      <td>0.740918</td>
      <td>-1.515097</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>99</td>
      <td>-1.157991</td>
      <td>0.741140</td>
      <td>-1.515386</td>
      <td>00:18</td>
    </tr>
  </tbody>
</table>


    Better model found at epoch 0 with crit_loss value: -1.546363115310669.
    

迭代 325 轮次后，与截止至 225 时显示结果近似，学习效果已不明显。


```python
learn.show_results(max_n=3, ds_idx=0)
```

<img src="./imgs/3_4_A/output_186_2.png" height='auto' width='auto' title="caDesign">


保存最后训练的模型（为新文件名，未覆盖之前保存的文件）。


```python
learn.save(ckpts_path/'naip_wgan_c_learn',with_opt=True)
```




    Path('/content/gdrive/MyDrive/Colab_Notebooks/model_checkpoint/ckpts4NaipGAN/naip_wgan_c_learn.pth')



## 3.4.3 计算分析工具的建构——Dear PyGUI

建立计算分析工具的主要目的有，集成一些经常用到、重复用到或者专门用到的计算代码，方便以 GUI（Graphical user interface） 可视化的图形用户界面方式调用；将研究内容以 GUI 工具的方式演示，具有可操作性、交互性、便捷性等特点；为未掌握编程语言的团队成员或相关使用者提供计算分析工具软件。

基于 Python 编程语言的 GUI 建构工具日益丰富，例如在*基于NDVI指数解译影像与建立采样工具*一章使用[Tkinter](https://docs.python.org/3/library/tkinter.html)<sup>⑯</sup>建立遥感影像的采样工具；结合[Gradio](https://gradio.app/)<sup>⑰</sup>演示机器学习模型；用[PyQt](https://wiki.python.org/moin/PyQt)<sup>⑱</sup>建构软件；[Pygame](https://www.pygame.org/news)<sup>⑲</sup>设计游戏；及[MD Python Designer](https://labdeck.com/python-designer/)<sup>⑳</sup>、[PySimpleGUI](https://www.pysimplegui.org/en/latest/)<sup>㉑</sup>、[pyglet](https://pyglet.org/)<sup>㉒</sup>、[PySide](https://www.pythonguis.com/pyside6/)<sup>㉓</sup>等。[Dear GUI（DPG）](https://dearpygui.readthedocs.io/en/latest/index.html)<sup>㉔</sup>则更倾向于为数据分析人员使用，是一个易于使用、动态、GPU 加速、跨平台的 Python 图形用户界面工具包，功能包括传统的 GUI 元素，例如按钮、单选按钮、菜单和创建功能布局的各种方法；含有种类繁多的动态图、表格、绘图、调试器和多个资源查看器；同时包含节点（Node）编辑器，建构可视化节点编程工具；且其框架弹性自由，表达形式布局巧妙，形式新颖。DPG 非常适用于创建简单用户界面及开发复杂且要求苛刻的图形界面，为开发科学、工程、游戏、数据科学和其他需要快速交互界面的应用程序提供坚实的框架。因此，对于数据分析工作，在平衡快速、方便的建构，代码书写的Python化、和向专门软件的转化，及 GUI 架构的自由性，使用 DPG 建立相关研究的计算分析工具。

为了方便查看训练后的 WGAN 模型中$G$网络各层数据演化情况，用 DGU 建立`simple WGAN Analysis Visualizer`计算分析工具，构建`Load WGAN64 model`节点；比较$D$网络一批真实图像数据计算结果的分布情况和生成同等数量一批生成假数据计算结果分布情况，并计算EM 距离，构建`WGAN64_D_PDF_plot`节点；同时构建有图像输入显示节点`Input Image`，数据集一批建构`Image Batch`，文件选择节点`File Path Selector`等辅助节点。DPG 的节点编辑器基础架构选择了[DearPyGUI NodeEditor Template](https://codeberg.org/LuminousLizard/DearPyGUI_NodeEditor_Template)<sup>㉕</sup>提供的代码。

<img src="./imgs/3_4_A/3_4_07.png" height='auto' width='auto' title="caDesign">

上述 WGAN 的$G$ 网络包括17个单层，每层生成新数据的形状可能不同，由输入的 100 维（Channel，通道数）`(1,1)`大小的噪声数据（latent space）降维到 3 维（RGB）`(64,64)`大小的（图像）数据。通道数大于3维度时，以多个单通道的`(size,size)`大小网格状显示（最多100个），例如对于`[1, 128, 16, 16]`形状数据`(bs,ch,size,size)`，有1个样本，128个通道（维度），大小为$16 \times 16$，则取前 100 维，每维显示$16 \times 16$的灰度图像，并排列为网格显示这100维数据。对于最后的`[1,3,64,64]`则按RGB方式显示为彩色图像。

基于 $D$ 网络的数据分布和EM 距离计算，输入的为真实图像数据集，而生成图像根据输入真实图像数据的数量构建噪声数据，并由$G$网络生成，用于$D$网络的输入。从打印的真实图像和生成图像的分布曲线可以判断，当前训练的 WGAN 模型的生成图像并不理想。

> `simple WGAN Analysis Visualizer`计算分析工具置于`USDA`下的`tools\DL_layers_visualizer`内。执行`DL_layers_visualizer.py`模块运行。

---

注释（Notes）：

① Chicago Data Portal，（<https://data.cityofchicago.org/Buildings/Building-Footprints-current-/hz9b-7nh8>）。

② Chicago Metropolitan Agency for Planning, CMAP，（<https://www.cmap.illinois.gov/data/land-use/inventory>）。

③ ArcGIS-Chicago Regional Land Cover，（<https://www.arcgis.com/home/item.html?id=782adcff882d4f09a227b509dcaa1628>）。

④ USGS EarthExploer，（<https://earthexplorer.usgs.gov/>）。

⑤ Earth Observation Group，（<https://eogdata.mines.edu/products/vnl/>）。

⑥ Pix2pix，（<https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix>）。

⑦ NAIP: National Agriculture Imagery Program，（<https://planetarycomputer.microsoft.com/dataset/naip#Example-Notebook>）。

⑧ StyleGAN3，（<https://github.com/NVlabs/stylegan3>）。

⑨ MarsGAN，（<https://github.com/kheyer/MarsGAN/blob/master/StyleGAN.ipynb>）。

⑩ PyTorch，（<https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html>）。

⑪ fastai，（<https://docs.fast.ai/>）。

⑫ DCGAN TUTORIAL，（<https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html>）。

⑬ fastai-GAN，（<https://docs.fast.ai/vision.gan.html>）。

⑭ PyTorch Lightning，（<https://lightning.ai/docs/pytorch/stable/>）。

⑮ TorchGeo，（<https://pytorch.org/blog/geospatial-deep-learning-with-torchgeo/>）。

⑯ Tkinter，（<https://docs.python.org/3/library/tkinter.html>）。

⑰ Gradio，（<https://gradio.app/>）。

⑱ PyQt，（<https://wiki.python.org/moin/PyQt>）。

⑲ Pygame，（<https://www.pygame.org/news>）。

⑳ MD Python Designer，（<https://labdeck.com/python-designer/>）。

㉑ PySimpleGUI，（https://www.pysimplegui.org/en/latest/）。

㉒ pyglet，（https://pyglet.org/）。

㉓ PySide，（https://www.pythonguis.com/pyside6/）。

㉔ Dear GUI（DPG），（https://dearpygui.readthedocs.io/en/latest/index.html）。

㉕ DearPyGUI NodeEditor Template，（https://codeberg.org/LuminousLizard/DearPyGUI_NodeEditor_Template）。

参考文献（References）:

[1] Goodfellow, I. J. et al. Generative Adversarial Networks. Preprint at (2014).

[2] gans-awesome-applications，<https://github.com/nashory/gans-awesome-applications>.

[3] Imdat As, Prithwish Basu, Pratap Talwar. Artificial Intelligence in Urban Planning and Design.Imprint: Elsevier (Imprint: Elsevier). 

[4] Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T. & Efros, A. A. Context Encoders: Feature Learning by Inpainting. in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition vols 2016-December 2536–2544 (IEEE Computer Society, 2016).

[5] Image super-resolution through deep learning, <https://github.com/david-gpu/srez>.

[6] 包瑞清.基于机器学习的风景园林智能化分析应用研究[J].风景园林,2019,26(05):29-34.DOI:10.14085/j.fjyl.2019.05.0029.06.

[7] Karras, T. et al. Alias-Free Generative Adversarial Networks. https://nvlabs.github.io/stylegan3.

[8] Radford, A., Metz, L. & Chintala, S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. (2015).

[9] Arjovsky, M., Chintala, S. & Bottou, L. Wasserstein GAN. (2017).

[10] Radford, A., Metz, L. & Chintala, S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. (2015).

[11] Zeiler, M. D., Krishnan, D., Taylor, G. W. & Fergus, R. Deconvolutional Networks.

[12] Dumoulin, V. & Visin, F. A guide to convolution arithmetic for deep learning. (2016).

[13] Ioffe, S. & Szegedy, C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. (2015).

[14] Goodfellow, I. et al. Generative adversarial networks. Commun ACM 63, 139–144 (2020).

[15] Arjovsky, M. & Bottou, L. Towards Principled Methods for Training Generative Adversarial Networks. (2017).

[16] Sun, H. et al. HRPGAN: A GAN-based Model to Generate High-resolution Remote Sensing Images. in IOP Conference Series: Earth and Environmental Science vol. 428 (Institute of Physics Publishing, 2020).
