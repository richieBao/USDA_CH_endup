> Created on Fri Oct 13 09:47:20 2023 @author: Richie Bao-caDesign设计(cadesign.cn)

# 4.10 图神经网络 （Graph Neural Networks，GNN）

## 4.10.1 图嵌入（graph embedding）

图（复杂网络）是一种用于描述和建模复杂系统（complex systems）的通用语言。通过量化的图分析可以更好的理解复杂网络，但是对于包含大量顶点和边及其属性的网络而言，通常需要使用图嵌入技术有效的将高维稀疏图转换为低维、密集和连续的（嵌入）向量空间，最大限度的保留图的结构属性，从而很容易在嵌入向量空间中使用标准度量量化原始复杂不规则空间中顶点的相似度<sup>[1][2]57</sup>。图嵌入的方法有 DeepWalk<sup>[3]</sup>、node2vec<sup>[4]</sup>、Line<sup>[5]</sup>、SDNE<sup>[6]</sup>和 struc2vec<sup>[7]</sup>等。


### 4.10.1.1 DeepWalk

Perozzi, B.等人<sup>[3]</sup>基于自然语言处理中词嵌入的 Word2Vec<sup>[8]</sup> 方法（可以查看*Transformer——自然语言处理*部分）提出了处理复杂网络的 DeepWalk， 该方法以一个图作为输入，通过给定深度（长度、次数）随机漫步（Random Walks）获得每个顶点随机邻接顶点，及随机邻接顶点的随机邻接顶点不断迭代深度的一个行走序列顶点列表来获取每个顶点的局部信息，将其视为自然语言处理中的语料库（corpus）用于学习复杂网络顶点（词）的嵌入向量/潜在表征（latent representations ）。

#### 1） 随机漫步（Random Walks）

以顶点$v_i$为源，其随机漫步的顶点（属性）列表记为$\mathcal{W}_{v_i}$，为一个随机过程，包含给定长度的随机变量 $ \mathcal{W}_{v_i}^1, \mathcal{W}_{v_i}^2, \ldots, \mathcal{W}_{v_i}^k$。对于一个随机变量$\mathcal{W}_{v_i}^{k+1}$，是从顶点$v_k$邻接顶点中随机选择的一个顶点。随机漫步已被用于内容推荐（content recommendation）、社区检测（community detection）等各类问题中的相似性度量。除了作为可以从网络中提取信息的基本工具，随机漫步能够执行并行计算，即可以同时探索一个图中的不同部分信息，提高计算效率；其次，依赖从随机漫步中获得的信息，可以在不需要全局重新计算的情况下适应图结构的微小变化，用新的随机漫步迭代更新已学习到的模型。

定义`RandomWalker`类，其`deepwalk_walk`方法<sup>[9]</sup>实现了网络顶点随机漫步的算法，代码如下，

```python
def deepwalk_walk(self, walk_length, start_node):
    walk = [start_node]

    while len(walk) < walk_length:
        cur = walk[-1]
        cur_nbrs = list(self.G.neighbors(cur))
        if len(cur_nbrs) > 0:
            walk.append(random.choice(cur_nbrs))
        else:
            break
    return walk
```

计算以[NetworkX](https://networkx.org/documentation/stable/index.html)<sup>①</sup>库提供的`erdos_renyi_graph`<sup>[10]</sup>随机图中顶点`0`的随机漫步为例，计算结果如下。


```python
%load_ext autoreload 
%autoreload 2
import usda.network as usda_network 
import usda.network.graph_embedding as usda_ge
import usda.manifold as usda_manifold

import networkx as nx
import pandas as pd
import numpy as np
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
```

    C:\Users\richie\anaconda3\envs\rl\Lib\site-packages\paramiko\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated
      "class": algorithms.Blowfish,
    

`erdos_renyi_graph(n, p, seed=None, directed=False)`方法中，参数`n`为顶点的数量；`p`为创建边的概率。


```python
G_er=nx.erdos_renyi_graph(10, 0.3, seed=1, directed=False)
usda_network.G_drawing(G_er)
```


<img src="./imgs/4_10_4/output_4_0.png" height='auto' width='auto' title="caDesign">    
    


仅计算了图中顶点0的随机漫步，随机选择了其邻接顶点4；而顶点4的随机邻接顶点为7，顶点7的随机邻接顶点为6，以此类推，完成指定长度的随机漫步。


```python
G_er_randomwalk=usda_ge.RandomWalker(G_er)
walk_lst=G_er_randomwalk.deepwalk_walk(walk_length=10, start_node=0)
walk_lst
```




    [0, 4, 7, 6, 4, 5, 4, 5, 4, 3]



#### 2）从自然语言处理的词嵌入到复杂网络的图（顶点）嵌入         

自然语言建模的目的是估计语料库中更容易构成具有意义短语或句子词汇组合的可能性。给出一个词汇组成的序列（句子或短语）$W_1^n=\left(w_0, w_1, \cdots, w_n\right)$，式中， $w_i \in \mathcal{V}$（$ \mathcal{V}$是词汇表），希望对于所有训练的语料库最大化$\operatorname{Pr}\left(w_n \mid w_0, w_1, \cdots, w_{n-1}\right)$。对应到复杂网络，将词汇对应到顶点，将词汇组成的句子对应到随机漫步表征局部网络结构特征的顶点序列上，则观测到顶点$v_i$的可能性的公式可表示为$\operatorname{Pr}\left(v_i \mid\left(v_1, v_2, \cdots, v_{i-1}\right)\right)$。

顶点嵌入向量的估计同词嵌入是要学习到可以表征网络结构顶点间的距离关系，而不仅仅是顶点共现（co-occurrences）的概率分布。因此引入一个映射函数$\Phi: v \in V \mapsto \mathbb{R}^{|V| \times d} $，式中，$\Phi$表示与图中每个顶点$v$相关的嵌入向量空间，并用一个$|V| \times d$大小的矩阵表示，有$\operatorname{Pr}\left(v_i \mid\left(\Phi\left(v_1\right), \Phi\left(v_2\right), \cdots, \Phi\left(v_{i-1}\right)\right)\right)$。在 Word2Vec 中，上述方法称之为 CBOW（Continuous Bag-of-Words），而提出的 Skip-gram 结构模型表现要好于 CBOW，其不是使用上下文语境来预测缺失的词，与其相反，由该词预测上下文中出现词的概率，对应到复杂网络，上述公式调整为$\underset{\Phi}{\operatorname{minimize}} \quad-\log \operatorname{Pr}\left(\left\{v_{i-w}, \cdots, v_{i-1}, v_{i+1}, \cdots, v_{i+w}\right\} \mid \Phi\left(v_i\right)\right)$。给定顶点$v_i$，最大化其邻接顶点在随机漫步中的概率，可以用分类器（如逻辑回归 SoftMax函数）来学习这种后验分布。然而，使用逻辑回归建模将会产生大量（数量等于$\mid V \mid$）的标签，为了加快训练速度，可以使用  Hierarchical Softmax（H-Softmax） 方法近似概率分布。

* 霍夫曼编码（Huffman Coding）

在计算机科学和信息理论中，David A. Huffman <sup>[11]</sup>提出了一种特殊类型的最优前缀码（prefix code），称为霍夫曼编码（Huffman Coding），通常用于无损数据压缩。在下述的试验中，提供了一组字符`data`，包括有`['a',  'b', 'c', 'd', 'e']`等5个字符，假设每个字符在语料库中出现的频率`freq`，为`[0.10, 0.15, 0.30,0.16, 0.29]`，和为1，那么对其进行霍夫曼编码结果如下图。从图中可以观察到霍夫曼编码的过程，将字母按照其权值排序，首先选择最小权值的两个字母`a`和`b`，构造其父顶点，权值为`a`和`b`之和 0.25；继续排序剩余的顶点加上新构造的父顶点，仍旧选择最小权值的两个顶点，`d`和新构造值为0.25的顶点构造其父顶点，以其和为父顶点的权值，即 0.41，以此类推，直至完成所有顶点的图构造，并最终存在一个根顶点。因为字符的频率和为1，因此根顶点的权值为1。而每个字符均位于叶顶点（节点）。且总共增加的新顶点数为$5-1=4$。

如果将每个顶点的左分支标记为0，而右分支标记为1，则可以编码叶顶点，例如对于字符`a`，其霍夫曼编码结果为`010`；对于字符`c`，其霍夫曼编码结果为`11`。从编码结果可以发现，字符出现的频率高，则其编码长度会相对短；而字符出现的频率低，则其编码的长度相对长。如果使用二进制定长编码（给每个字符一个固定长度的编码），对于试验中的5个字符，需要至少长度为3个位数（$3^2-1=8$）满足要求，那么总共位数为 15。而霍夫曼编码结果总位数为12，这要小于定长编码，因此可以有效的压缩数据。


```python
data=['a',  'b', 'c', 'd', 'e']
freq=[0.10, 0.15, 0.30,0.16, 0.29]
size=len(data)

root=usda_network.HuffmanCodes(data, freq, size,verbose=False)
usda_network.draw_tree(root,figsize=(4,4))

huffman_encoding_dict=usda_network.huffman_encoding_dict
print(huffman_encoding_dict)
```

    {'d': [0, 0], 'a': [0, 1, 0], 'b': [0, 1, 1], 'e': [1, 0], 'c': [1, 1]}
    


<img src="./imgs/4_10_4/output_8_1.png" height='auto' width='auto' title="caDesign">    


定义`huffman_encode()`和`huffman_decode()`方法，根据上述构造的霍夫曼编码树`root`，实现对任意给定字符组合的霍夫曼编码和解码。


```python
s='badbed'
s_encoded=usda_network.huffman_encode(s,huffman_encoding_dict)
print(s_encoded)
s_decoded=usda_network.huffman_decode(s_encoded,root)
print(s_decoded)
```

    011010000111000
    badbed
    

* Hierarchical Softmax（H-Softmax）<sup>[12]</sup>

H-Softmax 是一种计算 softmax 的有效方法<sup>[13]</sup>，使用霍夫曼编码树编码词汇表中所有的词汇，如图<sup>[12]</sup>，其中白色圆圈为叶顶点，对应到各个词汇；黑色圆圈为内部（中间）顶点。每个词汇均有一个从根（root）到对应叶顶点的唯一路径，该路径用于估计由叶顶点表示的词汇的概率。例如对于词汇`w_2`，用顶点路径表示的编码长度为$L\left(w_2\right)=4$。$n(w, j)$表示路径中第$j $个顶点。

<img src="./imgs/4_10_4/4_10_4_01.png" height='auto' width='300' title="caDesign"> 

在 H-Softmax 中，一个词汇的概率定义为，$p\left(w=w_O\right)=\prod_{j=1}^{L(w)-1} \sigma\left([\![ n(w, j+1)=\operatorname{ch}(n(w, j)) ]\!] \cdot \mathbf{v}_{n(w, j)}^{\prime}{ }^T \mathbf{h}\right)$，式中，$ch(n)$为顶点$n$的左分支子顶点；$\mathbf{v}_{n(w, j)}^{\prime}$为内部顶点$n(w, j)$的嵌入向量/向量表示（vector representation）；$\mathbf{h}$是隐藏层的输出值，在 Skip-gram 模型中，$\mathbf{h}=\mathbf{v}_{w_I}$，为词汇$w$的嵌入向量<sup>[14]</sup>。在 CBOW 模型中，$\mathbf{h}=\frac{1}{C} \sum_{c=1}^C \mathbf{v}_{w_c}$。因此在 H-Softmax 中，并没有输出词嵌入矩阵，而是为词内部顶点的嵌入向量$\mathbf{v}_{n(w, j)}^{\prime}$；$[\![x]\!]$为一个特殊函数，定义为，$[\![ x ]\!]= \begin{cases}1 & \text { if } x \text { is true; } \\ -1 & \text { otherwise }\end{cases}$。

计算上图中$w_2$作为输出词的概率，该概率定义为从根顶点开始随机漫步，结束于该词对应的叶顶点。对于每个内部顶点（包括根顶点），需要分配向左或向右的概率。如果定义内部顶点$n$向左的概率为$p(n, \text { left })=\sigma\left(\mathbf{v}_n^{\prime T} \cdot \mathbf{h}\right)$，由内部顶点的嵌入向量和该词的嵌入向量确定；因此，内部顶点$n$向右的概率为，$p(n, \text { right })=  1-\sigma\left(\mathbf{v}_n^{\prime T} \cdot \mathbf{h}\right)=\sigma\left(-\mathbf{v}_n^{\prime T} \cdot \mathbf{h}\right) $。因此按照上图给出的词$w_2$的路径，计算$w_2$作为输出词的概率为，$p\left(w_2=w_O\right)  =p\left(n\left(w_2, 1\right), \text { left }\right) \cdot p\left(n\left(w_2, 2\right), \text { left }\right) \cdot p\left(n\left(w_2, 3\right), \text { right }\right) \\ =\sigma\left(\mathbf{v}_{n\left(w_2, 1\right)}^{\prime}{ }^T \mathbf{h}\right) \cdot \sigma\left(\mathbf{v}_{n\left(w_2, 2\right)}^{\prime}{ }^T \mathbf{h}\right) \cdot \sigma\left(-\mathbf{v}_{n\left(w_2, 3\right)}^{\prime}{ }^T \mathbf{h}\right)$，并且，$\sum_{i=1}^V p\left(w_i=w_O\right)=1$。

回到复杂网络，将顶点构造为霍夫曼编码树，对于顶点$u_k \in V$，计算$\operatorname{Pr}\left(u_k \mid \Phi\left(v_j\right)\right)$可以转化为最大化树中特定路径的概率。如果到顶点$u_k$的路径表示为一个树顶点的序列$\left(b_0, b_1, \ldots, b_{\lceil\log |V|\rceil}\right), \quad\left(b_0=\right. root,\left.b_{\lceil\log |V|\rceil}=u_k\right)$，则，$\operatorname{Pr}\left(u_k \mid \Phi\left(v_j\right)\right)=\prod_{l=1}^{\lceil\log |V|\rceil} \operatorname{Pr}\left(b_l \mid \Phi\left(v_j\right)\right)$，式中，$\operatorname{Pr}\left(b_l \mid \Phi\left(v_j\right)\right)$可以通过顶点$b_l$父顶点的二元分类器建模，从而降低了计算$\operatorname{Pr}\left(u_k \mid \Phi\left(v_j\right)\right)$的复杂度， 从$O(\mid V \mid)$降低到$O(\log \mid V \mid)$。

#### 3）空手道俱乐部的 DeepWalk 图嵌入

下述的试验以`NetworkX`库提供的`karate_club_graph`图<sup>[15]</sup>为例计算图嵌入。该图总共有34个顶点，顶点有字段为`club`的属性，表示该节点是属于`Mr. Hi`还是`Officer`阵营。每个边赋予了一个权值，为基于该边相互作用顶点在上下文语境中出现的次数。


```python
G_karate_club=nx.karate_club_graph()
pos=nx.circular_layout(G_karate_club)

nodes_attri=pd.concat({k: pd.DataFrame.from_dict(v, orient='index') for k, v in dict(G_karate_club.nodes(data=True)).items()}, axis=0).reset_index().rename(columns={'level_0':'node','level_1':'attri',0:'club'})
nodes_attri_groups=nodes_attri.groupby("club")["node"].apply(list).reset_index()

edge_attributes=nx.get_edge_attributes(G_karate_club,'weight')
usda_network.G_drawing(G_karate_club,
                       nodes=nodes_attri_groups.node.tolist(),
                       nodes_color=['#616161','#9CCC65'],
                       pos=pos,figsize=(7,7),
                       routes=list(edge_attributes.keys()),
                       edge_widths=list(edge_attributes.values()),
                       edge_labels='weight',
                       edge_colors=['#616161']*len(edge_attributes))
```


<img src="./imgs/4_10_4/output_13_0.png" height='auto' width='auto' title="caDesign">    


查看图的顶点和边属性。


```python
print(list(G_karate_club.nodes(data=True))[17:21])
print(list(G_karate_club.edges(data=True))[:3])
```

    [(17, {'club': 'Mr. Hi'}), (18, {'club': 'Officer'}), (19, {'club': 'Mr. Hi'}), (20, {'club': 'Officer'})]
    [(0, 1, {'weight': 4}), (0, 2, {'weight': 5}), (0, 3, {'weight': 3})]
    

将顶点属性编码为整数值。


```python
nodes_attri['club_int']=nodes_attri.club.apply(lambda x:1 if x=='Officer' else 0)
nodes_attri[8:11]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>node</th>
      <th>attri</th>
      <th>club</th>
      <th>club_int</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>club</td>
      <td>Mr. Hi</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>club</td>
      <td>Officer</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>club</td>
      <td>Mr. Hi</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



定义`DeepWalk`类实现 DeepWalk 图嵌入算法，核心使用`gensim`库的`Word2Vec`方法。配置嵌入向量的维度`embed_size`(`vector_size`)为 128 维；使用 Skip-gram 模型（`sg=1`）和 H-Softmax 算法（`hs=1`）；配置当前顶点到预测顶点间的最大距离`window_size`（`window`）为10；并执行并行计算（`workers=3`）。


```python
model_deepwalk=usda_ge.DeepWalk(G_karate_club, walk_length=10, num_walks=80, workers=1)
model_deepwalk.train(
    window_size=10, 
    iter=30,
    sg=1, # Skip-gram
    hs=1, # Hierarchical softmax
    workers=3,
    embed_size=128,
    );
```

    Learning embedding vectors...
    Learning embedding vectors done!
    

查看计算结果，获得顶点的嵌入矩阵，维度为`(顶点数，嵌入向量维数)`。


```python
embeddings=model_deepwalk.get_embeddings()
embeddings_array=np.array([embeddings[node] for node in G_karate_club.nodes])
embeddings_array.shape
```




    (34, 128)



使用`wv.most_similar`方法可以计算与给定顶点距离最近的多个顶点（由近及远排序）。对于顶点 0，基于上述图结构，与其最近的顶点为 4，距离值约为 0.746（距离度量使用 cosine similarity 算法）。


```python
model_deepwalk.w2v_model.wv.most_similar(positive=[0])
```




    [(4, 0.7461870312690735),
     (10, 0.690133273601532),
     (3, 0.6589341759681702),
     (6, 0.6216689348220825),
     (5, 0.6070966124534607),
     (12, 0.5991224050521851),
     (16, 0.5978891849517822),
     (1, 0.5969511866569519),
     (11, 0.5932941436767578),
     (21, 0.5916509628295898)]



可以直接使用`wv.similarity`方法计算给定两个顶点间的距离。


```python
model_deepwalk.w2v_model.wv.similarity(0,4)
```




    0.74618703



使用 t-SNE 算法降维图顶点嵌入矩阵，由 128 维降至 2 维打印查看顶点的分布情况。从结果来看，代表不同阵营的顶点能够很好的分离，表明了 DeepWalk 图嵌入方法可以将图顶点转化为连续的嵌入向量空间，分析图结构。


```python
Y=usda_manifold.tsne(embeddings_array,2,max_iter=1000,print_interval=200,init='pca',random_state=0,learning_rate='auto')
```

    Preprocessing the data using PCA...
    Computing pairwise distances...
    Mean value of sigma: 2.0342620 of 34...
    Iteration 1000: error is 0.348395


```python
plt.figure(figsize=(2, 2), dpi=100)
plt.scatter(Y[:, 0], Y[:, 1], 20, nodes_attri.club_int,cmap='Dark2')
plt.show()
```


<img src="./imgs/4_10_4/output_28_0.png" height='auto' width='auto' title="caDesign">    


### 4.10.1.2 node2vec<sup>[4]</sup>

#### 1）BFS 和 DFS 

下图<sup>[4]</sup>呈现了网络结构的两个特性，第一种特征是同质性（homophily），如顶点$U$和顶点$S_1,S_2,S_3$之间的关系，这几个顶点属于同一个紧密结合的社区，顶点之间边的数量（路的长度）趋小，而之间边的权值趋大；另一种特征是结构等效性（structural equivalence），如顶点$U$和$S_6$，这两个顶点并不是紧密相连，而是位于不同的社区中，但是表现出相似的结构特征，为各自所在社区中心顶点的角色，其顶点度均为4，与邻接顶点构成围长为3的圈有3~4个。

为了权衡同质性和结构等效性，Grover, A.<sup>[4]</sup>等人将源顶点邻域采样问题看作是一种局部搜索形式，提出了两种采样策略，广度优先采样（ Breadth-ﬁrst Sampling，BFS）和深度优先采样（Depth-ﬁrst Sampling，DFS）。BFS 倾向于采样源顶点邻域邻接的顶点，如$U$邻接顶点$S_1,S_2,S_3$；DFS 倾向于由距离源顶点越来愈远的顶点依次采样组成，如$U$与$S_4,S_5,S_6$。

<img src="./imgs/4_10_4/4_10_4_02.png" height='auto' width='300' title="caDesign"> 

BFS 和 DFS 代表了同质性和结构等效性两种极端搜索的情境，并对学习到的图嵌入向量空间产生影响。而复杂网络的顶点预测任务经常在同质性和结构等效性之间变换。在同质性假设下，高度互连和属于相似簇或社区的顶点，对其估计的嵌入向量距离更近；而在结构等效性假设下，在网络中具有相似结构角色的顶点（不强调连通性，在网络中的顶点可能相距很远），对其估计的嵌入向量距离则更近。

#### 2）node2vec 采样策略

基于 BFS 和 DFS，Grover, A.等人设计了一个灵活的邻域采样策略，开发了一种灵活的有偏随机漫步（biased random walk），以 BFS 和 DFS 方式搜索邻域，可以在 BFS 和 DFS 之间平滑的进行插值。

给定一个源顶点$u$，模拟一个给定长度$l$的随机漫步。用$c_i$表示漫步中的第$i$个顶点，开始的顶点$c_0=u$，即为源顶点。顶点$c_i$由下述分布给出，$P\left(c_i=x \mid c_{i-1}=v\right)= \begin{cases}\frac{\pi_{v x}}{Z} & \text { if }(v, x) \in E \\ 0 & \text { otherwise }\end{cases}$，式中，$\pi_{v x}$为顶点$v$和$x$之间的非归一化转移概率（unnormalized transition probability），$Z$是一个归一化常数。

如下图<sup>[4]</sup>，定义一个有两个参数$p$和$q$的2阶随机漫步，该随机漫步已经经过顶点$t$到达了顶点$v$，现在需要确定如何走下一步，是到$x_1,x_2,x_3$，还是返回$t$，因此需要计算顶点$v$的边$(v,x)$的转移概率$\pi_{v x}$。设非归一化的转移概率$\pi_{v x}=\alpha_{p q}(t, x) \cdot w_{v x}$，有$\alpha_{p q}(t, x)= \begin{cases}\frac{1}{p} & \text { if } d_{t x}=0 \\ 1 & \text { if } d_{t x}=1 \\ \frac{1}{q} & \text { if } d_{t x}=2\end{cases}$，式中，$d_{t x}$表示顶点$t$和$x$之间最短路径距离，且$d_{t x}$属于集合$\{0,1,2\}$。参数$p$和$q$控制了随机漫步探索和离开源顶点$u$邻域的速度，并在探索过程中在 BFS 和 DFS 之间（近似）插值（interpolate）。

<img src="./imgs/4_10_4/4_10_4_03.png" height='auto' width='200' title="caDesign"> 

返回参数（Return parameter），$p$：该参数用于控制随机漫步中，某一顶点即刻重访其上一顶点的概率，即当前顶点$v$重访上一顶点$t$的可能性（上图）。如果将其配置为一个较大的值（$>\max (q, 1)$），则接下来的两步中，不太可能对已经访问过的顶点进行采样（除非随机漫步中的下一个顶点没有邻接顶点）。相反，如果该参数值很小（$< \min (q, 1)$），这将导致随机漫步后退一步，使得漫步更倾向于在源顶点附近。返回参数（Return parameter）。

出入参数（In-out parameter），$q$：该参数可以控制权衡在“内部的”（inward）和“外部的”（outward）顶点中搜索。如果$q>1$，随机漫步倾向于选择顶点$t$附近的顶点，近似 BFS 采样策略的同质性特征。相反，如果$q<1$，随机漫步更倾向于访问离顶点$t$更远的顶点，近似 DFS 采样策略的结构等效性的特征。

如果$p=q=1$，随机漫步则等同于 DeepWalk 中的随机漫步。

下面的试验重构了 node2vec 论文中解释 BFS和 DFS的示例图，其中顶点 0 对应到$U$；顶点 6 对应到$S_6$。定义`node2vec_walk2`方法<sup>[9]</sup>计算 node2vec。计算中多次运行比较获得如下结果，从图中可以观察到，含有红色的圆实现了 DFS 采样策略；而含有绿色的圆则实现了 BFS 采样策略。


```python
G_n2v=nx.Graph()
G_n2v.add_edges_from([(0,1),(0,2),(0,3),(0,4),(1,4),(1,2),(3,2),(3,4),(5,3),(5,4),(6,5),(6,7),(6,8),(6,9),(9,5),(9,8)])
```


```python
pq=[(1,1),(1,10),(10,1)]
walk_lsts=[]
for p,q in pq:
    node2vec_walk=usda_ge.RandomWalker(G_n2v,p=p, q=q, use_rejection_sampling=False)
    node2vec_walk.preprocess_transition_probs()
    walk_lst=node2vec_walk.node2vec_walk2(walk_length=8, start_node=0)
    walk_lsts.append(walk_lst)
print(walk_lsts)    

usda_network.G_drawing(
    G_n2v,
    node_color='#BDBDBD',
    edgecolors='#BDBDBD',
    nodes=walk_lsts[1:],
    nodes_color=['#9CCC65','#F44336'],
    nodes_size=[200,100],
    figsize=(4,4),
    )
```

    [[0, 3, 0, 4, 3, 2, 0, 2], [0, 2, 0, 2, 1, 2, 0, 1], [0, 1, 2, 3, 5, 6, 9, 8]]
    


<img src="./imgs/4_10_4/output_32_1.png" height='auto' width='auto' title="caDesign">    


#### 3）空手道俱乐部的 node2vec 图嵌入

该试验包括两个部分，首先用 node2vec 方法计算图嵌入；然后用顶点的嵌入向量使用`RandomForestClassifier`随机森林分类算法建立分类预测模型，计算预测精度。比较多个$p,q$值对计算结果建立分类预测模型的精度，可以发现当$p=q=1$时，即为 DeepWalk 图嵌入算法所获得的精度并不是最高的，表明配置$p,q$值合理的 node2vec 有偏随机漫步要优于 DeepWalk。


```python
train_mask=[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]
test_mask=[0, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33]
labels=nodes_attri.club_int.to_numpy()

pq_pairs=[(p,q) for p in range(1,8) for q in range(1,8)]

pq_scores={}
for p,q in pq_pairs:
    model_node2vec=usda_ge.Node2Vec(G_karate_club, walk_length=10, num_walks=80,p=p, q=q, workers=1, use_rejection_sampling=1)
    model_node2vec.train(window_size=10, iter=3,embed_size=64);   

    clf=RandomForestClassifier(random_state=0)
    clf.fit(model_node2vec.w2v_model.wv[train_mask], labels[train_mask])
    
    y_pred=clf.predict(model_node2vec.w2v_model.wv[test_mask])
    acc=accuracy_score(y_pred, labels[test_mask])

    pq_scores[(p,q)]=acc
```

    Learning embedding vectors done!


```python
pq_scores_sorted=sorted(pq_scores.items(),key=lambda x:x[1])

fig,ax=plt.subplots(figsize=(10,2))
ax.plot([str(i[0]) for i in pq_scores_sorted], [i[1] for i in pq_scores_sorted], '-')
ax.tick_params(axis='x', labelrotation=90)
```


<img src="./imgs/4_10_4/output_36_0.png" height='auto' width='auto' title="caDesign">    


### 4.10.1.3 植物调查样方物种的图嵌入

[Countryside Survey 1978 vegetation plot data](https://ckan.publishing.service.gov.uk/dataset/countryside-survey-1978-vegetation-plot-data)<sup>②</sup>数据集包括于1978年在英国各地调查的 256 个 $1km \times 1km$ 地块中存在的物种及其丰度（abundance）。该数据是在生态与水文中心（Centre for Ecology & Hydrology）管理的乡村调查（ Countryside Survey）长期监测项目下收集的。下载的数据集包括数据说明文件和两个数据文件，其中一个数据文件为地块的基本信息，其包含的字段如下：

1. YEAR - 调查年份；
2. SQUARE_ID - 方阵标识；
3. PLOT_ID - 地块标识；
4. PLOT_TYPE - 地块类型；
5. COUNTRY	ENV_ZONE_2007 - 环境分区编号（2007版）；
6. EZ_DESC_07 - 环境分区描述（2007版）。

另一个数据文件为调查地块中物种信息，其包含的字段如下：

1. YEAR	- 调查年份；
2. SQUARE_ID - 方阵标识；	 
3. PLOT_ID - 地块标识；	
4. AMALG_PTYPE - 地块类型；	
5. BRC_NUMBER -	物种标识；
6. BRC_NAMES - 种名；	
7. TOTAL_COVER - 占整个调查地块的百分比。	



植物群落是在一个指定的地理单元内植物物种的集合或联合（ association）<sup>[16]</sup>，并形成一个与相邻不同植被类型斑块区分开来相对统一的斑块。每个植物群落的组成受到土壤类型、地形、气候和人为干扰的影响<sup>[17]</sup>。这里假设位于同一个调查样方中的植物物种更倾向于组成相对稳定的植物群落，从而对该数据集中植物调查样方（地块）物种构建图并计算图嵌入。构建图时，如果物种存在于同一个调查样方则建立边，并以占地百分比的差值作为边的一个属性，字段名为`cover_diff`。如果具有边连接的两个物种存在于多个调查样方中，则计算其均值。


```python
from itertools import combinations
from collections import defaultdict
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from statistics import mean 
from node2vec import Node2Vec
import pandas as pd
import networkx as nx
```

读取和查看植物调查数据。为了方便数据分析，使用[Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)<sup>③</sup>库的`LabelEncoder`方法对物种名称进行整数编码。


```python
vegetation_plot_species_list_fn='../data/Countryside_Survey_1978_vegetation_plot_data/data/Vegetation Plot - Species List 1978.csv'
vegetation_plot_information_fn='../data/Countryside_Survey_1978_vegetation_plot_data/data/Vegetation Plot - Plot Information 1978.csv'
```


```python
species_list=pd.read_csv(vegetation_plot_species_list_fn)
le=LabelEncoder()
species_list['name_encoder']=le.fit_transform(species_list.BRC_NAMES)
species_list.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YEAR</th>
      <th>SQUARE_ID</th>
      <th>PLOT_ID</th>
      <th>AMALG_PTYPE</th>
      <th>BRC_NUMBER</th>
      <th>BRC_NAMES</th>
      <th>TOTAL_COVER</th>
      <th>name_encoder</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>44492</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>5505962.0</td>
      <td>Cladonia sp.</td>
      <td>1</td>
      <td>153</td>
    </tr>
    <tr>
      <th>44493</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>9202136.0</td>
      <td>Vaccinium myrtillus</td>
      <td>1</td>
      <td>643</td>
    </tr>
    <tr>
      <th>44494</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>9202138.0</td>
      <td>Vaccinium vitis-idaea</td>
      <td>1</td>
      <td>646</td>
    </tr>
  </tbody>
</table>
</div>




```python
plot_information=pd.read_csv(vegetation_plot_information_fn)
plot_information.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YEAR</th>
      <th>SQUARE_ID</th>
      <th>PLOT_ID</th>
      <th>PLOT_TYPE</th>
      <th>COUNTRY</th>
      <th>ENV_ZONE_2007</th>
      <th>EZ_DESC_07</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2276</th>
      <td>1978</td>
      <td>VJURQL</td>
      <td>PGVBRABLNM</td>
      <td>X</td>
      <td>ENG</td>
      <td>3</td>
      <td>Uplands (England)</td>
    </tr>
    <tr>
      <th>2277</th>
      <td>1978</td>
      <td>VJURQL</td>
      <td>CTDCGFAVUI</td>
      <td>X</td>
      <td>ENG</td>
      <td>3</td>
      <td>Uplands (England)</td>
    </tr>
    <tr>
      <th>2278</th>
      <td>1978</td>
      <td>VJURQL</td>
      <td>QMBXWPAQUD</td>
      <td>X</td>
      <td>ENG</td>
      <td>3</td>
      <td>Uplands (England)</td>
    </tr>
  </tbody>
</table>
</div>



按调查地块（`PLOT_ID`字段）计算两两物种的覆盖占比差值。


```python
plot_species_group=species_list.groupby(by=['PLOT_ID'])
```


```python
plot_species_group_pairs_info={}
species_pairs_percent_cover_diff_dict_list=[]

for group in tqdm(plot_species_group):
    name_encoder=group[1].name_encoder.to_list()
    species_total_cover=group[1].TOTAL_COVER.to_list()
    species_cover_dict=pd.Series(group[1].TOTAL_COVER.values,index=group[1].name_encoder).to_dict()
    species_pairs_percent_cover_diff_dict={tuple(sorted((i,j))):abs(species_cover_dict[i]-species_cover_dict[j]) for i,j in combinations(name_encoder,2)}
    species_pairs_percent_cover_diff_dict_list.append(species_pairs_percent_cover_diff_dict)

species_pairs_percent_cover_diff_dict_merged=defaultdict(list)
for d in species_pairs_percent_cover_diff_dict_list:
    for key, value in d.items():
        species_pairs_percent_cover_diff_dict_merged[key].append(value)
```

    100%|███████████████████████████████████████████| 2279/2279 [00:00<00:00, 2528.74it/s]
    


```python
species_pairs_percent_cover_diff_mean={k:mean(v) for k,v in species_pairs_percent_cover_diff_dict_merged.items()} 
```

构建图，并保存至本地磁盘。


```python
species_encoder2name=pd.Series(species_list.BRC_NAMES.values,index=species_list.name_encoder).to_dict()

G_species=nx.Graph()
G_species.add_edges_from(list(species_pairs_percent_cover_diff_mean.keys()))
nx.set_edge_attributes(G_species, species_pairs_percent_cover_diff_mean,'cover_diff')
nx.set_node_attributes(G_species,species_encoder2name,'name')

nx.write_gml(G_species,'../data/g_species.gml')
```

计算图嵌入。此次试验使用的`node2vec`算法是直接调用[Node2Vec](https://github.com/eliorc/node2vec)<sup>④</sup>库提供的方法。实验中配置参数`p,q`不同值，计算了两次图嵌入，可以发现不同的`p,q`值将会有不同的结果。因此在实际问题分析时，需要根据分析目的权衡同质性和结构等效性，分析群落结构性的特征。


```python
G_species=nx.read_gml('../data/g_species.gml')
node2vec=Node2Vec(G_species, dimensions=64, walk_length=30, num_walks=200, p=.1, q=10, workers=8)
model_pq=node2vec.fit(window=10, min_count=1, batch_words=4)
```

    Computing transition probabilities: 100%|███████████| 675/675 [02:30<00:00,  4.49it/s]
    

用计算获得的图嵌入矩阵（向量），定义`most_similar_species()`函数，给定物种名返回与该物种在网络结构中相似，距离相近的物种列表。


```python
def most_similar_species(species_name,species_encoder2name,model,num=10):
    species_name2encoder={v:k for k,v in species_encoder2name.items()}
    species_similar=model.wv.most_similar(species_name2encoder[species_name])
    species_similar_nameNencoder=[(i[0],species_encoder2name[int(i[0])],i[1]) for i in species_similar]
    
    species_encoder=species_name2encoder[species_name]
    return species_similar_nameNencoder,species_encoder       

species_similar_nameNencoder_pq,species_encoder=most_similar_species('Avena fatua',species_encoder2name,model_pq) 
species_similar_nameNencoder_pq
```




    [('132', 'Centaurea nigra', 0.6480474472045898),
     ('521', 'Rumex acetosa', 0.6247394680976868),
     ('627', 'Trifolium pratense', 0.6161571741104126),
     ('477', 'Prunella vulgaris', 0.5903562307357788),
     ('98', 'Cardamine pratensis', 0.5866711139678955),
     ('470', 'Potentilla erecta', 0.5834638476371765),
     ('136', 'Cerastium fontanum', 0.583010196685791),
     ('628', 'Trifolium repens', 0.5810055732727051),
     ('605', 'Succisa pratensis', 0.57342928647995),
     ('469', 'Potentilla anserina', 0.5671511888504028)]



计算给定物种和其相似物种之间的最短路径，例如对于物种 Avena fatua（60）到嵌入向量空间中距离最近的物种为 Centaurea nigra（132），但是在所有的调查地块中，这两个物种并没有同时出现，而是存在一个中间物种 Achillea millefolium。而对于相似物种 Trifolium pratense（627），则存在边，即存在同时出现的地块。


```python
shortest_path_st_pq={i[0]:[G_species.has_edge(int(species_encoder),int(i[0])),nx.shortest_path(G_species,source=int(species_encoder),target=int(i[0])) ] for i in species_similar_nameNencoder_pq}
shortest_path_st_pq
```




    {'132': [False, [60, 2, 132]],
     '521': [False, [60, 10, 521]],
     '627': [True, [60, 627]],
     '477': [False, [60, 12, 477]],
     '98': [False, [60, 48, 98]],
     '470': [False, [60, 183, 470]],
     '136': [True, [60, 136]],
     '628': [True, [60, 628]],
     '605': [False, [60, 10, 605]],
     '469': [False, [60, 12, 469]]}




```python
species_encoder2name[2]
```




    'Achillea millefolium'



在图中显示给定物种及通过图嵌入计算获得的相似物种。


```python
species_edges=list(G_species.edges(species_encoder))

similar_nodes=[[species_encoder],[int(i[0]) for i in species_similar_nameNencoder_pq]]
usda_network.G_drawing(G_species,
                       figsize=(20,20),
                       edge_widths=[2]*len(species_edges),
                       nodes=similar_nodes,nodes_color=['#42A5F5','#F44336'],
                       routes=species_edges,
                       edge_colors=['#42A5F5']*len(species_edges),
                       edge_color=(117/255,117/255,117/255,.01),
                       font_size=10,
                       node_color=(117/255,117/255,117/255,.5),
                       edgecolors=(117/255,117/255,117/255,.5),
                       )
```


<img src="./imgs/4_10_4/output_58_0.png" height='auto' width='auto' title="caDesign">    



调整`p,q`值，再次计算图嵌入，观察计算结果发现，对于同一给定物种 Avena fatua（60）的相似物种发生的变化。


```python
node2vec=Node2Vec(G_species, dimensions=64, walk_length=30, num_walks=200, p=2, q=1, workers=8)
model_qp=node2vec.fit(window=10, min_count=1, batch_words=4)
```

    Computing transition probabilities: 100%|███████████| 675/675 [02:32<00:00,  4.43it/s]
    


```python
species_similar_nameNencoder_qp,species_encoder=most_similar_species('Avena fatua',species_encoder2name,model_qp) 
shortest_path_st={i[0]:[G_species.has_edge(int(species_encoder),int(i[0])),nx.shortest_path(G_species,source=int(species_encoder),target=int(i[0])) ] for i in species_similar_nameNencoder_qp}
shortest_path_st
```




    {'315': [False, [60, 12, 315]],
     '151': [False, [60, 2, 151]],
     '319': [False, [60, 10, 319]],
     '208': [False, [60, 2, 208]],
     '240': [False, [60, 12, 240]],
     '521': [False, [60, 10, 521]],
     '493': [False, [60, 2, 493]],
     '253': [False, [60, 12, 253]],
     '175': [False, [60, 136, 175]],
     '209': [True, [60, 209]]}



## 4.10.2 从 原始（vanilla） GNN 到 GCN、GAT、GraphSAGE 和 GIN <sup>[18,19]</sup>

阐述多种 GNN 网络模型时，为了便于理解算法，使用`dash`库定义`gnn_algorithms_dash` Web 应用程序<sup>[19]</sup>，通过交互操作更新图顶点表征（嵌入向量），观察值变化来分析算法的机制。


```python
%load_ext autoreload 
%autoreload 2 
import usda.network as usda_nx

import torch
from torch_geometric.datasets import FacebookPagePage,PPI,TUDataset
from torch_geometric.utils import to_dense_adj

from sklearn.metrics import f1_score
from torch_geometric.data import Batch
from torch_geometric.loader import DataLoader, NeighborLoader
from torch_geometric.nn import GraphSAGE
from torch_geometric.data import Data
from torch_geometric.utils import to_dense_batch
from torch.nn import LSTM

import networkx as nx
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    


```python
usda_nx.gnn_algorithms_dash()
```

### 4.10.2.1 vanilla (多层感知机，Multi-Layer Perceptron（MLP）) GNN（vGNN）

一个基本的神经网络层对应一个线性变换（linear transformation），公式表达为$h_A=x_A W^T$，式中，$x_A$为顶点$A$的输入向量（特征向量）；$W$为权重。如果构建 MLP 直接学习特征向量（输出为顶点对应的一个分类），将忽略顶点之间边的联系，使得顶点间完全分离，网络学习不到图中顶点的语境，训练的模型预测精度必然不高。如果考虑顶点邻接顶点的特征，设$\mathcal{N_A}$为顶点$A$的邻接顶点（含自身），则可以将图的线性层（graph linear layer）调整为，$h_A=\sum_{i \in \mathcal{N}_A} x_i W^T$。下图简单示例中，假设图含有5个顶点，并仅包含一个特征（特征向量的维度为1），对于顶点$A$，结果为 -1，经激活函数（ReLU）非线性变换后结果为0。

<img src="./imgs/4_10_4/4_10_4_04.png" height='auto' width='700' title="caDesign"> 

将线性变换转换为矩阵表达有$H=X W^T$，式中$X$为顶点的输入特征向量矩阵。同样将图线性层的上述公式转换为矩阵表达有$H=\tilde{\mathrm{A}}^T X W^T$，式中$\tilde{\mathrm{A}}$为包含自身的顶点邻接矩阵（方阵），为$\tilde{\mathrm{A}}=A+I$，式中$A$为邻接矩阵，$I$为单位矩阵（identity matrix）。用 0 表示两个顶点间不邻接，用 1 表示邻接。矩阵的对角线为顶点自身之间的关系，如果值为 1， 则包含自身。

[PyG （PyTorch Geometric）](https://pytorch-geometric.readthedocs.io/en/latest/index.html)<sup>⑤</sup>是一个基于 [PyTorch](https://pytorch.org/)<sup>⑥</sup>构建的库，可以轻松编写和训练神经网络（Graph Neural Networks，GNNs），广泛用于与结构化数据相关的应用。PyG 的 [datasets](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html)<sup>⑦</sup>模块包含有大量图数据集，其中 Facebook 为经过验证页面-页面（page-page）的图数据集。顶点对应到官方的 Facebook 页面，边对应到互相点赞（likes）的站点。顶点特征为对站点的描述，任务是对站点类别进行多类别分类<sup>[20]</sup>。构建 vGNN 网络，用 Facebook 图数据集训练模型，完成分类任务。 

下载和读取 Facebook 图数据集。


```python
facebookPagePage_fn='../data/pyg_datasets'
dataset=FacebookPagePage(root=facebookPagePage_fn)
```

查看数据集相关信息。


```python
data=dataset[0]
print(f'number of graphs:{len(dataset)}\
        \nnumber of nodes:{data.x.shape[0]}\
        \nnumber of features:{dataset.num_features}\
        \nnumber of classes:{dataset.num_classes}\
        \nedges are directed:{data.is_directed()}\
        \ngraph has isolated nodes:{data.has_isolated_nodes()}\
        \ngraph has loops:{data.has_self_loops()}')
```

    number of graphs:1        
    number of nodes:22470        
    number of features:128        
    number of classes:4        
    edges are directed:False        
    graph has isolated nodes:False        
    graph has loops:True
    

查看顶点属性特征向量，和对应的站点类别。


```python
print(data.x.shape,'\n',data.x,'\n',data.y)
```

    torch.Size([22470, 128]) 
     tensor([[-0.2626, -0.2765, -0.2624,  ..., -0.2151, -0.3759, -0.2238],
            [-0.2626, -0.2765, -0.2624,  ..., -0.2151, -0.3641, -0.1286],
            [-0.2626, -0.2651, -0.2624,  ..., -0.2151, -0.3759, -0.2238],
            ...,
            [-0.2626, -0.2765, -0.2624,  ..., -0.1804, -0.3721, -0.2226],
            [-0.2626, -0.2765, -0.2624,  ..., -0.2151, -0.3759, -0.2181],
            [-0.2323, -0.2765, -0.2624,  ..., -0.1959, -0.3759, -0.2213]]) 
     tensor([0, 2, 1,  ..., 2, 1, 0])
    

采用 `PyG` 库对图数据处理的方法，配置训练、验证和测试数据集区间。


```python
data.train_mask=range(18000)
data.val_mask=range(18001, 20000)
data.test_mask=range(20001, 22470)
```

用`PyG`的`to_dense_adj`方法计算顶点邻接矩阵，并配置对角线值为 1，即包含顶点自身。


```python
adjacency=to_dense_adj(data.edge_index)[0]
adjacency+=torch.eye(len(adjacency))
print(adjacency.shape)
adjacency
```

    torch.Size([22470, 22470])
    




    tensor([[1., 0., 0.,  ..., 0., 0., 0.],
            [0., 1., 0.,  ..., 0., 0., 0.],
            [0., 0., 1.,  ..., 0., 0., 0.],
            ...,
            [0., 0., 0.,  ..., 1., 0., 0.],
            [0., 0., 0.,  ..., 0., 1., 0.],
            [0., 0., 0.,  ..., 0., 0., 1.]])



查看 vGNN 网络层，定义有两个线性层，执行完一个线性层计算后，计算与顶点邻接矩阵的点积（点乘），代码为`x = torch.sparse.mm(adjacency, x)`，然后经激活函数（ReLU）非线性变换后，执行第2个线性层，最后用 SoftMax 函数分类，使用 `PyTorch`库的`torch.nn.functional.log_softmax`方法。


```python
gnn_vanilla=usda_nx.VanillaGNN(dataset.num_features, 16, dataset.num_classes)
gnn_vanilla
```




    VanillaGNN(
      (gnn1): VanillaGNNLayer(
        (linear): Linear(in_features=128, out_features=16, bias=False)
      )
      (gnn2): VanillaGNNLayer(
        (linear): Linear(in_features=16, out_features=4, bias=False)
      )
    )



训练模型。预测精度为预测分类正确数的百分比。


```python
gnn_vanilla.fit(data,adjacency,epochs=1000,verbose=200)
```

    Epoch   0 | Train Loss: 1.309 | Train Acc: 79.72% | Val Loss: 1.25 | Val Acc: 79.24%
    Epoch 200 | Train Loss: 0.324 | Train Acc: 91.18% | Val Loss: 0.36 | Val Acc: 90.80%
    Epoch 400 | Train Loss: 0.294 | Train Acc: 92.40% | Val Loss: 0.34 | Val Acc: 90.70%
    Epoch 600 | Train Loss: 0.241 | Train Acc: 93.25% | Val Loss: 0.32 | Val Acc: 91.10%
    Epoch 800 | Train Loss: 0.204 | Train Acc: 93.88% | Val Loss: 0.31 | Val Acc: 91.30%
    Epoch 1000 | Train Loss: 0.574 | Train Acc: 89.84% | Val Loss: 0.62 | Val Acc: 89.59%
    

用测试数据集查看多类别分类预测精度，结果为 88.62%。


```python
acc=gnn_vanilla.test(data,adjacency)
print(f'\nGNN test accuracy: {acc*100:.2f}%')
```

    
    GNN test accuracy: 88.62%
    

    C:\Users\richie\anaconda3\envs\rl\Lib\site-packages\usda\network\_gnn_interpretation.py:325: FutureWarning:
    
    adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.
    
    C:\Users\richie\anaconda3\envs\rl\Lib\site-packages\scipy\sparse\_index.py:143: SparseEfficiencyWarning:
    
    Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.
    
    

### 4.10.2.2 GCN（Graph Convolutional Networks）

基于卷积神经网络（Convolutional Neural Networks，CNNs），Thomas N. Kipf等人<sup>[21]</sup>提出了用于复杂网络的图卷积网络（Graph Convolutional Networks，GCNs）。不同于vGNN，仅是加权求和顶点与其邻接顶点的特征值，GCN考虑到当前顶点度，有$h_i=\frac{1}{\operatorname{deg}(i)} \sum_{j \in N_i} x_j W^\tau$，式中$\operatorname{deg}(i)$为当前顶点度；对应矩阵的形式表示为$H=\tilde{D}^{-1} \tilde{A} X W^T$，式中，$\tilde{A}=A+I$，$A$为邻接矩阵，$I$为单位矩阵，为包含当前顶点自身。$\tilde{D}^{-1}=(D+I)^{-1} $，为顶点度倒数矩阵。Thomas N. Kipf等人注意到，具有更高顶点度，即具有更多邻接顶点的顶点的特征更容易传播。为了抵消这种影响，提出了$H=\tilde{D}^{-\frac{1}{2}} \tilde{A}^T \tilde{D}^{-\frac{1}{2}} X W^T$，可以使得低顶点度的顶点分配有更高的权重。就单个顶点，GCN 的计算公式为$h_i=\sum_{j \in N_i} \frac{1}{\sqrt{\operatorname{deg}(i)} \sqrt{\operatorname{deg}(j)}} x_j W^T$。

下图简单示例中，配置权重值$W=1$（因此可以省略），对于顶点$A$，其自身顶点度为3（有 2 个邻接顶点，并包含自身），其特征值为 6， 因此根据单个顶点的 GCN 公式有，$6 \times   \frac{1}{ \sqrt{3} \times \sqrt{3}} $；对于$A$的邻接顶点$E$，其顶点度为4，特征值为 3，因此有$3 \times   \frac{1}{ \sqrt{3} \times \sqrt{4}} $；同理，对于邻接顶点$C$有，$-10 \times   \frac{1}{ \sqrt{3} \times \sqrt{2}} $。将上述各邻接顶点（含自身）结果求和后结果为 -1.216，经激活函数（ReLU）非线性变换后结果为0。

<img src="./imgs/4_10_4/4_10_4_05.png" height='auto' width='700' title="caDesign"> 

`PyG`集成有大量[卷积层（Convolutional Layers）](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers)<sup>⑧</sup>，其中`GCNConv`对应到Thomas N. Kipf等人提出的方法。使用`GCNConv`层定义 GCN，如下包含有两层`GCNConv`。同样使用 Facebook 图数据集进行试验。


```python
gcn=usda_nx.GCN(dataset.num_features, 16, dataset.num_classes)
gcn
```




    GCN(
      (gcn1): GCNConv(128, 16)
      (gcn2): GCNConv(16, 4)
    )


可以发现相对于 vGNN 模型，GCN 具有更快的收敛速度和相对较高的预测精度。

```python
gcn.fit(data, epochs=1000,verbose=200)
```

    Epoch   0 | Train Loss: 0.236 | Train Acc: 93.09% | Val Loss: 0.24 | Val Acc: 92.35%
    Epoch 200 | Train Loss: 0.153 | Train Acc: 95.67% | Val Loss: 0.20 | Val Acc: 93.75%
    Epoch 400 | Train Loss: 0.144 | Train Acc: 96.01% | Val Loss: 0.20 | Val Acc: 93.90%
    Epoch 600 | Train Loss: 0.141 | Train Acc: 96.04% | Val Loss: 0.19 | Val Acc: 94.00%
    Epoch 800 | Train Loss: 0.139 | Train Acc: 96.12% | Val Loss: 0.19 | Val Acc: 93.90%
    Epoch 1000 | Train Loss: 0.138 | Train Acc: 96.13% | Val Loss: 0.19 | Val Acc: 93.90%
    

用测试数据集查看多类别分类预测精度，结果为 93.16%。


```python
acc=gcn.test(data)
print(f'\nGCN test accuracy: {acc*100:.2f}%\n')
```

    
    GCN test accuracy: 93.16%
    
    

### 4.10.2.3 GAT（Graph Attention Networks）

在*从 RNN 到 Transformer 和 GPT，从自然语言处理到视觉模型*部分解释了 transformer 网络中的注意力机制，将该机制用于 GNN 建立  GAT（Graph Attention Networks）。相较于 GCN 考虑顶点度以区分邻接顶点少的顶点比其它顶点更重要，GAT 则引入了考虑顶点特征重要性的加权因子，为顶点间的注意力得分（attention score），对于顶点$i,j$间的注意力得分，可记为$a_{ij}$，从而有，$h_i=\sum_{j \in \mathcal{N}_i} \alpha_{i j} \mathbf{W} x_j$。该公式对应到下图顶点$A$示例$h_A$的计算部分，其中，$a_{AA},a_{AC},a_{AE}$分别为顶点$A$到邻接顶点的注意力得分（含自身）。

注意力得分$a_{ij}$的计算包括线性变换（Linear transformation），应用激活函数（Activation function）和 Softmax 标准化（ Softmax normalization）。组合线性变换和激活函数可表示为，$e_{i j}=\operatorname{LeakyReLU}\left(W_{a t t}^\tau\left[\mathbf{W} h_i \| \mathbf{W} h_j\right]\right) $，对应到下图示例中$e_{AA},e_{AC},e_{AE}$的计算部分，式中，$W$为共享的权重矩阵；$W_{att}$对应图中示例的$A_W$权重矩阵。对线性变换结果执行 LeakyReLU 激活函数，对 LeakyReLU 的解释可以查看*判别器（D）的层结构*部分，其公式表述为$\operatorname{LeakyReLU}(x)=\max (0, x)+$ negative_slope $* \min (0, x)$，或$\text { LeakyReLU }(x)= \begin{cases}x, & \text { if } x \geq 0 \\ \text { negative\_slope } \times x, & \text { otherwise }\end{cases}$。LeakyReLU 的计算直接调用`PyTorch`库的`torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)`方法，在下图示例计算时，配置参数`negative_slope=0.2`。

如果要比较不同的注意力得分，则需要将其标准化，使用 Softmax 标准化方法，公式为$\alpha_{i j}=\operatorname{softmax}_j\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_i} \exp \left(e_{i k}\right)}$，对应图中$a_{AA},a_{AC},a_{AE}$部分的计算。实际计算时调用`torch.nn.Softmax(dim=None)`方法。

<img src="./imgs/4_10_4/4_10_4_06.jpeg" height='auto' width='1000' title="caDesign"> 

由于自注意力（self-attention）可能并不稳定，因此 Vaswani, A. 等人<sup>[22]</sup>提出了多头注意力（Multi-head attention ），在 GAT 中则是将线性变换，应用激活函数和 Softmax 标准化过程重复多次（$n$）计算，而后取均值或只是连接（Concatenation），对于取均值可表示为，$ h_i=\frac{1}{n} \sum_{k=1}^n h_i^k=\frac{1}{n} \sum_{k=1}^n \sum_{j \in N_i} \alpha_{i j}^k \mathbf{W}^k x_j$；对于连接可表示为，$h_i=\|_{k=1}^n h_i^k=\|_{k=1}^n \sum_{j \in N_i} \alpha_{i j}^k \mathbf{W}^k x_j $。实践中，为隐藏层时选择连接方式，当位于网络最后一层时选择均值方式。

Shaked Brody 等人<sup>[23]</sup>发现 GAT 计算的是一种非常有限的注意力：注意力得分排名在查询的顶点上是无条件的。为与更具表现力的动态注意力（dynamic attention）区分，将这种受限的注意力定义为静态注意力（static attention）。使用静态注意力机制的 GAT 不能表示简单图问题（ simple graph problems），在受控问题（controlled problem）中甚至会阻碍训练数据拟合。为了消除静态注意力的限制，Shaked Brody 等人通过调整 GAT 的计算顺序提出了 GATv2。对 GAT 中计算$e_{ij}$的公式进行调整，有$e_{i j}=W_{a t t}^\tau \operatorname{LeakyReLU}\left( \mathbf{W} \left[ h_i \|  h_j\right]\right) $。`PyG` 库对则应提供了`GATConv`和`GATv2Conv`方法。

继续使用 Facebook 图数据集进行试验，计算过程和结果如下。


```python
gat=usda_nx.GATv2(dataset.num_features, 32, dataset.num_classes)
gat
```




    GATv2(
      (gat1): GATv2Conv(128, 32, heads=8)
      (gat2): GATv2Conv(256, 4, heads=1)
    )




```python
gat.fit(data,epochs=1000,verbose=200)
```

    Epoch   0 | Train Loss: 2.047 | Train Acc: 22.72% | Val Loss: 2.02 | Val Acc: 22.56%
    Epoch 200 | Train Loss: 0.331 | Train Acc: 89.11% | Val Loss: 0.33 | Val Acc: 89.39%
    Epoch 400 | Train Loss: 0.323 | Train Acc: 88.94% | Val Loss: 0.31 | Val Acc: 89.19%
    Epoch 600 | Train Loss: 0.339 | Train Acc: 88.44% | Val Loss: 0.34 | Val Acc: 88.29%
    Epoch 800 | Train Loss: 0.332 | Train Acc: 88.81% | Val Loss: 0.33 | Val Acc: 89.34%
    Epoch 1000 | Train Loss: 0.330 | Train Acc: 88.50% | Val Loss: 0.32 | Val Acc: 89.29%
    

用测试数据集查看多类别分类预测精度，结果为 91.17%。


```python
acc=gat.test(data)
print(f'GAT test accuracy: {acc*100:.2f}%')
```

    GAT test accuracy: 91.17%
    

### 4.10.2.4 GraphSAGE

大型图中顶点的低维嵌入（low-dimensional embeddings）已经被证明在各种预测任务中非常有用，为了避免训练嵌入时包含图中所有的顶点（称为直推式，（transductive）），Hamilton, W.等人<sup>[24]</sup>提出了 GraphSAGE 算法，一个通用的归纳式（inductive）框架，利用顶点特征信息，从顶点的局部邻域中采样和聚合特征学习一个函数，不是为每个顶点训练一个不同的嵌入向量，而是训练一组聚合器函数（aggregator functions），从而有效的为之前未见过的数据生成顶点嵌入。其具体的过程如下图示<sup>[24]</sup>：

<img src="./imgs/4_10_4/4_10_4_08.png" height='auto' width='1000' title="caDesign"> 

上图中，左图为邻域采样；中图为从邻域采样中聚合特征信息；右图为使用聚合的信息预测图的上下文（context）和类标。

* 邻域采样（Neighbor sampling）

聚合器函数从远离给定顶点不同跳数（hops）或搜索深度聚合信息。从上图左中可以观察 1 跳为顶点的邻接顶点，2 跳为邻接顶点的邻接顶点，以此类推。同时，为了避免对应跳数顶点数的指数级增长，采用邻域采样的方式降低顶点数。

* 聚合器架构（Aggregator Architectures）

聚合器函数作用于没有自然顺序的邻接顶点。理想情况，聚合器函数应是对称（对其输入的排列不变）且是可训练的，保持有较高的表示能力，从而保证神经网络模型可以被训练并应用于任意有序的顶点邻域特征集。论文中作者研究了三种聚合器函数，为均值、LSTM 和池化（Pooling）。

均值算子是计算邻域采样$\left\{\mathbf{h}_u^{k-1}, \forall u \in \mathcal{N}(v)\right\} $中顶点向量的均值，基本等同于 GCN 的卷积传播规则，用公式表示为$ \mathbf{h}_v^k \leftarrow \sigma\left(\mathbf{W} \cdot \operatorname{MEAN}\left(\left\{\mathbf{h}_v^{k-1}\right\} \cup\left\{\mathbf{h}_u^{k-1}, \forall u \in \mathcal{N}(v)\right\}\right)\right.$；LSTM 聚合器基于 LSTM 架构（可以参考*从 RNN 到 Transformer 和 GPT，从自然语言处理到视觉模型*章节对 LSTM 的阐述），与均值聚合器相比，LSTM 聚合器理论上可以区分更多的图结构，从而生成更好的嵌入。但 LSTM 输入为一个序列，而顶点没有任何顺序，因此需要对顶点进行随机排序，例如在 `PyG` 中使用`data.sort(sort_by_row=False)`方法按照边索引的目标顶点排序等；池化聚合器，将邻域采样每个顶点的向量喂入全连接神经网络，而后用最大池化（max-pooling）聚合信息，公式表达为$\quad \operatorname{AGGREGATE}_k^{\text {pool }}=\max \left(\left\{\sigma\left(\mathbf{W}_{\text {pool }} \mathbf{h}_{u_i}^k+\mathbf{b}\right), \forall u_i \in \mathcal{N}(v)\right\}\right)$，式中，$max$表示取最大值，$\sigma$为非线性激活函数。原则上，在最大池化之前应用的函数可以是任意深度的多层感知器。

下图单个顶点的 GraphSAGE 更新演示使用 LSTM 聚合器函数。为了方便演示，配置 LSTM 的所有参数均为值1。通过按照边索引（`edge_index`）的目标顶点排序，得到如下边索引结果`data.edge_index`。按照边索引，使用`PyG`的`to_dense_batch`方法，按照排序后的边索引，可以得到图中每个顶点邻接顶点向量`x_dense`。如果不足最大邻接顶点数，则用值0占位，例如对于顶点$A$，其邻接顶点为$C,E$，有`[[-10.],[2.],[0.]]`。


```python
x=torch.tensor([[6],[2],[-10],[1],[3]]).to(torch.float)
edge_index=torch.tensor([[0, 0, 1, 2, 3, 4, 4, 4],[2, 4, 4, 0, 4, 0, 1, 3]])
data=Data(x=x, edge_index=edge_index)

data=data.sort(sort_by_row=False)
data.edge_index
```




    tensor([[2, 4, 4, 0, 4, 0, 1, 3],
            [0, 0, 1, 2, 3, 4, 4, 4]])




```python
x_=torch.tensor([data.x[i] for i in data.edge_index[0]]).reshape(-1,1)
x_dense,_=to_dense_batch(x_,data.edge_index[1])
x_dense
```




    tensor([[[-10.],
             [  3.],
             [  0.]],
    
            [[  3.],
             [  0.],
             [  0.]],
    
            [[  6.],
             [  0.],
             [  0.]],
    
            [[  3.],
             [  0.],
             [  0.]],
    
            [[  6.],
             [  2.],
             [  1.]]])



用 LSTM 模型计算按边索引目标顶点排序的邻接顶点向量结果如下。


```python
lstm=LSTM(1, 1, batch_first=True)
for para in list(lstm.parameters()):   
    para.data.fill_(1.0)

lstm_out=lstm(x_dense)[0][:,-1] 
lstm_out
```




    tensor([[0.8961],
            [0.9393],
            [0.9395],
            [0.9393],
            [0.9756]], grad_fn=<SelectBackward0>)



完成聚合器函数（LSTM）计算后，对应演示后续计算公式表示为$h_i^{\prime}=\sigma\left(\mathbf{W} h_i+\mathbf{B} \cdot \operatorname{LSTM}_{j \in \mathcal{N}_i}\left(h_j\right)\right)$。

<img src="./imgs/4_10_4/4_10_4_07.png" height='auto' width='700' title="caDesign"> 

直推式只能生成固定图的嵌入，不能泛化到不可见的顶点或图。而基于邻域采样，GraphSAGE 被设计成在局部使用修剪后的计算图进行预测的归纳式架构，从而可用于具有相同特征模式的任何计算图。使用`PyG`提供的蛋白质间相互作用网络图数据集`PPI`<sup>[25]</sup>，包含定位基因（positional gene）集，基序基因（motif gene）集，作为顶点特征的免疫特征（immunological signatures）数据（总共有 50 个），并将基因本体集（gene ontology）作为标签（总共 121 个）。直接迁移 *Hands-On Graph Neural Networks Using Python*<sup>[18]137</sup>示例代码计算过程和结果如下。

查看 GPU。


```python
print(torch.__version__)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device
```

    2.1.0+cu118
    




    device(type='cuda')



下载数据至本地磁盘。


```python
# Load training, evaluation, and test sets
root='../data/pyg_datasets/PPI'
train_dataset= PPI(root=root, split='train')
val_dataset = PPI(root=root, split='val')
test_dataset = PPI(root=root, split='test')

print(len(train_dataset))
train_dataset[0]
```

    20
    




    Data(x=[1767, 50], edge_index=[2, 32318], y=[1767, 121])



训练数据集包括 20 个图，将这些所有图通过`Batch.from_data_list`方法将其描述为一个不连接的大图（统一成一个集合），并建立用于训练的数据加载器。


```python
# Unify the training graphs and apply neighbor sampling
train_data = Batch.from_data_list(train_dataset)
train_loader = NeighborLoader(train_data, batch_size=2048, shuffle=True, num_neighbors=[20, 10], num_workers=2, persistent_workers=True)

# Evaluation loaders (one datapoint corresponds to a graph)
val_loader = DataLoader(val_dataset, batch_size=2)
test_loader = DataLoader(test_dataset, batch_size=2)

train_data
```




    DataBatch(x=[44906, 50], edge_index=[2, 1226368], y=[44906, 121], batch=[44906], ptr=[21])



初始化 GraphSAGE 模型，损失和优化器。


```python
model = GraphSAGE(
    in_channels=train_dataset.num_features,
    hidden_channels=512,
    num_layers=2,
    out_channels=train_dataset.num_classes,
).to(device)

criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

model
```




    GraphSAGE(50, 121, num_layers=2)



定义模型训练函数。


```python
def fit(loader):
    model.train()

    total_loss = 0
    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index)
        loss = criterion(out, data.y)
        total_loss += loss.item() * data.num_graphs
        loss.backward()
        optimizer.step()
    return total_loss / len(loader.data)
```

定义精度计算函数，使用对应于准确率和召回率的调和平均值`f1_score`（f1-分数）。


```python
@torch.no_grad()
def test(loader):
    model.eval()

    data = next(iter(loader))
    out = model(data.x.to(device), data.edge_index.to(device))
    preds = (out > 0).float().cpu()

    y, pred = data.y.numpy(), preds.numpy()
    return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0
```

训练模型。


```python
for epoch in range(1001):
    loss = fit(train_loader)
    val_f1 = test(val_loader)
    if epoch % 200 == 0:
        print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Val F1-score: {val_f1:.4f}')

print(f'Test F1-score: {test(test_loader):.4f}')
```

    Epoch   0 | Train Loss: 12.720 | Val F1-score: 0.4894
    Epoch 200 | Train Loss: 8.501 | Val F1-score: 0.8194
    Epoch 400 | Train Loss: 8.431 | Val F1-score: 0.8319
    Epoch 600 | Train Loss: 8.398 | Val F1-score: 0.8317
    Epoch 800 | Train Loss: 8.362 | Val F1-score: 0.8373
    Epoch 1000 | Train Loss: 8.368 | Val F1-score: 0.8341
    Test F1-score: 0.8570
    

查看已训练模型的预测精度。


```python
print(f'Test F1 score: {test(test_loader):.4f}')
```

    Test F1 score: 0.8570
    

### 4.10.2.5 GIN（Graph Isomorphism Network）

#### 1）同构图的 Weisfeiler-Lehman（WL） 检验<sup>[26]</sup>

基于 Weisfeiler and Lehman, A.A. 等人<sup>[27]</sup>的  Weisfeiler-Lehman（WL）同构图检验的 1-维变体（1-dimensional variant），即朴素顶点求精（naive vertex reﬁnement），Shervashidze, N.等人<sup>[26]</sup>在图中迭代 1-维 WL检验，测试给定的图$G$和$G^{\prime}$是否同构，算法如下：

```algorithm
% WGAN
\begin{algorithm}
\caption{One iteration of the 1-dim. Weisfeiler-Lehman test of graph isomorphism}
\begin{algorithmic}
\STATE \textbf{1: Multiset-label determination} 
\STATE • For $i=0$, set $M_i(v):=l_0(v)=\ell(v) .$
\STATE • For $i>0$, assign a multiset-label $M_i(v)$ to each node $v$ in $G$ and $G^{\prime}$ which consists of the multiset $\left\{l_{i-1}(u) \mid u \in \mathcal{N}(v)\right\}$.
\STATE \textbf{2: Sorting each multiset} 
\STATE • Sort elements in $M_i(v)$ in ascending order and concatenate them into a string $s_i(v)$.
\STATE • Add $l_{i-1}(v)$ as a prefix to $s_i(v)$ and call the resulting string $s_i(v)$.
\STATE \textbf{3: Label compression} 
\STATE • Sort all of the strings $s_i(v)$ for all $v$ from $G$ and $G^{\prime}$ in ascending order.
\STATE • Map each string $s_i(v)$ to a new compressed label, using a function $f: \Sigma^* \rightarrow \Sigma$ such that $f\left(s_i(v)\right)=f\left(s_i(w)\right)$ if and only if $s_i(v)=s_i(w)$.
\STATE \textbf{4: Relabeling} 
\STATE • Set $l_i(v):=f\left(s_i(v)\right)$ for all nodes in $G$ and $G^{\prime}$.
\end{algorithmic}
\end{algorithm}
```

对应上述算法的图解如下<sup>[26]</sup>，

<img src="./imgs/4_10_4/4_10_4_10.png" height='auto' width='700' title="caDesign"> 

该算法的核心思想是将排序的邻接顶点标签增加到原顶点标签上，并将这些扩充的顶点标签压缩为短的标签，重复这个过程直至图$G$和$G^{\prime}$的顶点标签集不同，或者迭代次数达到$n$。例如图中$h=1$的 WL 子树核（subtree kernel）计算中，将$\{1,2, \ldots, 13\} \in \Sigma$视为字母，如果一个顶点具有标签 8，则意味着该顶点有一个高度为1的子树模式（subtree pattern）， 多集标签（Multiset-label）为$2,35$，对应根标签为 2，邻域标签为3和5。

步骤 3（c） 中对多集进行基数排序（radix sort），并定义$f$（如哈希函数（Hash function））把多集映射（压缩）到一组新的标签。多集排序保证了所有相同的字符串都映射到相同的新标签（数字）上。其中$\Sigma$必须足够大，确保$f$是内射的。在多次迭代中（图示例中仅需迭代一次），如果新创建的标签集在图$G$和$G^{\prime}$中不相同，说明二者不同构。如果$n$次迭代后，集合相同，则意味着图$G$和$G^{\prime}$同构或算法无法确定它们不是同构的。

步骤 4（e）中，计数了 WL 子树核的公共原始标签和映射标签。

`NetworkX`库提供了`weisfeiler_lehman_graph_hash(G, edge_attr=None, node_attr=None, iterations=3, digest_size=16)`方法返回 WL 图哈希值。该函数迭代的对每个顶点的邻域进行聚合和散列（哈希），以更新顶点标签。返回值为输入图的哈希值对应的十六进制字符串。例如下述代码构建了上述示例图中的图$G$（`G1`）和$G^{\prime}$（`G2`），并计算了图的 WL 哈希值，结果不同，表明图$G$和$G^{\prime}$不同构。


```python
G1=nx.Graph()
G1.add_edges_from([(4,0),(4,1),(4,5),(4,3),(2,5),(2,3),(5,3)])
nx.set_node_attributes(G1,{0:1,1:1,2:2,3:3,4:4,5:5},name='labels')

G2=nx.Graph()
G2.add_edges_from([(4,2),(4,1),(4,5),(4,3),(2,5),(2,3),(0,3)])
nx.set_node_attributes(G2,{0:2,1:1,2:5,3:3,4:4,5:2},name='labels')

pos={0:[2,0],1:[1,0],2:[2,2],3:[3,1],4:[0,1],5:[1,2]}
```


```python
usda_nx.G_drawing(G1,node_labels='labels',pos=pos)
```


<img src="./imgs/4_10_4/output_118_0.png" height='auto' width='auto' title="caDesign">    



```python
usda_nx.G_drawing(G2,node_labels='labels',pos=pos)
```


<img src="./imgs/4_10_4/output_119_0.png" height='auto' width='auto' title="caDesign">    



```python
WL_G1=nx.weisfeiler_lehman_graph_hash(G1,node_attr='labels',iterations=1)
WL_G2=nx.weisfeiler_lehman_graph_hash(G2,node_attr='labels',iterations=1)
print(WL_G1,WL_G2)
```

    965633870406c8813aa3c2daad107bbe 466a349290fb7ad16aa95c70014ab524
    

`NetworkX`库也提供了`weisfeiler_lehman_subgraph_hashes(G, edge_attr=None, node_attr=None, iterations=3, digest_size=16)`方法返回顶点为键子图哈希值的字典。从计算结果可以发现，当仅迭代1次时，即对应顶点列表的第1个值，图$G$和$G^{\prime}$的顶点3、1对应相同等，而图$G$中的顶点5和图$G^{\prime}$中的顶点2相同。


```python
g1_hashes=nx.weisfeiler_lehman_subgraph_hashes(G1, iterations=2, digest_size=8,node_attr='labels')
g2_hashes=nx.weisfeiler_lehman_subgraph_hashes(G2, iterations=2, digest_size=8,node_attr='labels')
print(g1_hashes)
print(g2_hashes)
```

    {4: ['bb4d352c7c4fcc44', '6274bc44044b5a3f'], 0: ['5110adc459f44b27', 'e5e3a395c0f7e75d'], 1: ['5110adc459f44b27', 'e5e3a395c0f7e75d'], 5: ['6d4d91e01b12ba52', '5cdde0408b77fb12'], 3: ['ff34a88346b6b71f', '1380842ff2943f32'], 2: ['7d5a4600089dcd1b', '6117058e1c02d97f']}
    {4: ['15f9a158b7b4c4da', '01830c815cd29704'], 2: ['6d4d91e01b12ba52', '96603cec7f6af193'], 1: ['5110adc459f44b27', '5594b95736b6436f'], 5: ['48c13d17f6c77427', 'aec9546ac5c31b74'], 3: ['ff34a88346b6b71f', 'fcd5055cf24b328b'], 0: ['26808910ed0da6e0', '8a99dfce7ad1fff5']}
    

#### 2）Graph Isomorphism Network，GIN<sup>[28]</sup>

设图$G=(V, E)$，其顶点特征向量为$X_v \text (v \in V)$。对于图顶点分类，其中每个顶点$v \in V$都有一个相对应的分类标签$y_v$，目标是学习顶点$v$的表征向量（representation vector）$h_v$，使得顶点$v$的分类标签可以由$y_v=f\left(h_v\right)$预测；对于图分类，给定一组图$\left\{G_1, \ldots, G_N\right\} \subseteq \mathcal{G}$和对应的分类标签$\left\{y_1, \ldots, y_N\right\} \subseteq \mathcal{Y}$，目标是学习一个表征向量$h_G$，可以用其预测整个图的分类，有$y_G=g\left(h_G\right) $。

GNNs 使用图结构和顶点特征$X_v$学习顶点或整个图的表征向量$h_v$或$h_G$，遵循邻域聚合策略，通过聚合邻域顶点表征信息来迭代更新顶点的表征。经过$k$次聚合迭代，顶点的表征捕获到了其$k$-hop（$k$-跳）网络邻域的结构信息，第$k$层（迭代）的 GNN 可以表示为，$a_v^{(k)}=\operatorname{AGGREGATE}^{(k)}\left(\left\{h_u^{(k-1)}: u \in \mathcal{N}(v)\right\}\right), \quad h_v^{(k)}=\operatorname{COMBINE}^{(k)}\left(h_v^{(k-1)}, a_v^{(k)}\right)$，式中，$h_v^{(k)}$是第$k$次迭代，顶点$v$的特征向量，并初始化$h_v^{(0)}=X_v$，而$\mathcal{N}^{(v)}$是顶点$v$的邻域顶点集合。$\operatorname{AGGREGATE}^{(k)}(\cdot) \text { and } \operatorname{COMBINE}^{(k)}(\cdot)$的选择是关键，GraphSAGE 就提到均值、LSTM 和池化（Pooling）等聚合器函数。

对于顶点分类，使用最后一次迭代顶点的表征$h_v^{(k)}$进行预测；对于图分类，$\operatorname{READOUT}$函数聚合最后一次迭代的顶点特征，得到整个图的表征$h_G=\operatorname{READOUT}\left(\left\{h_v^{(K)} \mid v \in G\right\}\right) $。$\operatorname{READOUT}$可以是一个简单的置换不变函数（permutation invariant function）（特征之间没有空间位置关系），例如求和函数或者为一个更复杂的图级池化函数（graph-level pooling function ）。

理想情况下，最强大的 GNN 可以将不同的图结构映射到嵌入空间（ embedding space）中的不同表征（ representations）来区分不同的图结构。然而，这种将任意两个不同图映射到不同嵌入的能力，意味着要解决具有挑战性的图同构问题，即希望同构图映射到相同的表征，而非同构图映射到不同的表征。同构图的 Weisfeiler-Lehman（WL） 检验为其提供了一种途径。

引理（Lemma）1，$G_1$和$G_2$为非同构的图，如果一个图神经网络$\mathcal{A}: \mathcal{G} \rightarrow \mathbb{R}^d $映射图$G_1$和$G_2$为不同的嵌入时，WL 图同构检验也判定图$G_1$和$G_2$不同构。

定理（Theorem）2， 设$\mathcal{A}: \mathcal{G} \rightarrow \mathbb{R}^d $为 GNN，迭代足够次数，如果满足如下条件，$\mathcal{A}$将 WL 图同构检验判定为非同构的任意图$G_1$和$G_2$映射到不同的嵌入，

a） $\mathcal{A}$用$h_v^{(k)}=\phi\left(h_v^{(k-1)}, f\left(\left\{h_u^{(k-1)}: u \in \mathcal{N}(v)\right\}\right)\right)$迭代的聚合和更新顶点特征，式中，函数$f$作用于多集，$\phi$为单射；

b）$\mathcal{A}$图级`readout`函数，作于于顶点特征$\left\{h_v^{(k)}\right\}$的多集，为单射。

Keyulu Xu 等人<sup>[28]</sup>开发的 GIN 简单架构的算法模型证明满足定理 2 中的条件，推广了 WL 检验，实现了 GNNs 的最大判别能力。为了对邻域聚合建模单射多集函数（ injective multiset functions），发展了“深度多集”（“deep multisets”）的理论，即用神经网络参数化通用多集函数。下一引理（3）陈述了求和聚合器是单射的，为多集上的通用函数（universal functions）。

引理 3，假设$\mathcal{X}$是可计算的（countable），存在一个函数$f: \mathcal{X} \rightarrow \mathbb{R}^n$，使得$h(X)=\sum_{x \in X} f(x)$对于每一个有界大小的多集$ X \subset \mathcal{X}$是唯一的。对于函数$\phi$，任意多集函数$g$都可以分解为$g(X)=\phi\left(\sum_{x \in X} f(x)\right)$。

推论（4）在诸多的聚合方案中提供了一个简单而具体的公式。

推论（Corollary）4，假设$\mathcal{X}$是可计算的，存在一个函数$f: \mathcal{X} \rightarrow \mathbb{R}^n$，使得对于$\epsilon$无限多个选择，包括所有无理数，$h(c, X)=(1+\epsilon) \cdot f(c)+\sum_{x \in X} f(x)$对每一对$(c, X)$都是唯一的，式中$c \in \mathcal{X}$和$X \subset \mathcal{X}$是一个有界大小的多集。此外对于一些函数$\varphi$，任何函数$g$都可以分解为$g(c, X)=\varphi\left((1+\epsilon) \cdot f(c)+\sum_{x \in X} f(x)\right)$。

可以使用多层感知机（MLPs）学习推论（4）中的$f$和$\varphi$。因为 MLPs 可表示函数的组合，因此用 MLPs 对$f^{(k+1)} \circ \varphi^{(k)}$建模。在第1次迭代中，输入的特征如果为独热编码，它们的和为单射，因此在求和之前不需要 MLPs。$\epsilon$可以作为一个可学习的参数，也可以为固定的标量。定义 GIN 顶点表征的更新公式为，$h_v^{(k)}=\mathrm{MLP}^{(k)}\left(\left(1+\epsilon^{(k)}\right) \cdot h_v^{(k-1)}+\sum_{u \in \mathcal{N}(v)} h_u^{(k-1)}\right)$。

下述简单的演示案例应用了 GIN 顶点更新的上述公式，例如对于顶点$A$，聚合邻接顶点$C$和$E$，求和为$-10+3=-7$，进而与顶点当前表征$h_A$与$(1+\epsilon)$之积求和得到$-7+(1+0)*6=-1$，经过 ReLU 激活函数的非线性变换得到结果值为0。

<img src="./imgs/4_10_4/4_10_4_09.png" height='auto' width='700' title="caDesign"> 

#### 3）GIN 图分类

`PyG`库的`TUDataset`提供了收集于多特蒙德工业大学（TU Dortmund University）多种多样的图核（graph kernel）基准数据集，使用其中的`PROTEINS`（蛋白质）数据集，应用 GIN 网络执行图分类任务。

首先下载数据集并打印相关信息。


```python
root='../data/pyg_datasets/TUDataset'
dataset = TUDataset(root=root, name='PROTEINS').shuffle()
```


```python
# Print information about the dataset
print(f'Dataset: {dataset}')
print('-----------------------')
print(f'Number of graphs: {len(dataset)}')
print(f'Number of nodes: {dataset[0].x.shape[0]}')
print(f'Number of features: {dataset.num_features}')
print(f'Number of classes: {dataset.num_classes}')
```

    Dataset: PROTEINS(1113)
    -----------------------
    Number of graphs: 1113
    Number of nodes: 31
    Number of features: 3
    Number of classes: 2
    

切分数据集为训练、验证和测试数据集。


```python
# Create training, validation, and test sets
train_dataset = dataset[:int(len(dataset)*0.8)]
val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]
test_dataset  = dataset[int(len(dataset)*0.9):]
# Create mini-batches
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=True)
```

初始化 GIN 网络，该网络使用`PyG`库的`GINConv`方法构建。


```python
gin = usda_nx.GIN(dataset.num_node_features,dataset.num_classes,dim_h=32)
gin
```




    GIN(
      (conv1): GINConv(nn=Sequential(
        (0): Linear(in_features=3, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): ReLU()
      ))
      (conv2): GINConv(nn=Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): ReLU()
      ))
      (conv3): GINConv(nn=Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): ReLU()
      ))
      (lin1): Linear(in_features=96, out_features=96, bias=True)
      (lin2): Linear(in_features=96, out_features=2, bias=True)
    )



训练网络模型。


```python
gin = usda_nx.gin_train(gin, train_loader,val_loader,epochs=200,verbose=40)
```

    Epoch   0 | Train Loss: 1.26 | Train Acc: 72.05% | Val Loss: 0.44 | Val Acc: 77.36%
    Epoch  40 | Train Loss: 0.45 | Train Acc: 78.74% | Val Loss: 0.41 | Val Acc: 84.24%
    Epoch  80 | Train Loss: 0.41 | Train Acc: 80.36% | Val Loss: 0.60 | Val Acc: 76.86%
    Epoch 120 | Train Loss: 0.39 | Train Acc: 81.26% | Val Loss: 0.56 | Val Acc: 78.42%
    Epoch 160 | Train Loss: 0.39 | Train Acc: 81.20% | Val Loss: 0.53 | Val Acc: 78.99%
    Epoch 200 | Train Loss: 0.37 | Train Acc: 82.40% | Val Loss: 0.53 | Val Acc: 78.99%
    

在测试数据集上计算精度。


```python
test_loss, test_acc = usda_nx.gin_test(gin, test_loader)
print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')
```

    Test Loss: 0.64 | Test Acc: 77.34%
    

由训练的模型预测分类并打印结果（总共 2 类，红绿颜色区分）。


```python
_=usda_nx.gin_prediction_plot(gin,dataset[-16:],figsize=(4,4))
```


<img src="./imgs/4_10_4/output_137_0.png" height='auto' width='auto' title="caDesign">    


## 4.10.3 VGAE（Variational Graph Auto-Encoder）连接（边）预测（Link prediction） 和植物调查样方物种间的关联

VGAE 和 GAE 均由Kipf, T. N. 和 Welling, M.<sup>[29]</sup>提出。变分图自编码器（ Variational Graph Auto-Encoders​，VGAE）是一种基于变分自编码器（Variational Auto-Encoder ，VAE）的一种用于图结构数据无监督学习框架，可利用潜在变量（latent variables）学习无向图可解释的潜在表征。

### 4.10.3.1 变分自编码器（Variational Auto-Encoder ，VAE）

变分自编码器（Variational Auto-Encoder ，VAE）是由Kingma, D. P. 和 Welling, M. <sup>[30]</sup>提出的一种神经网络结构，为概率生成模型（probabilistic generative models），是概率图模型（ probabilistic graphical models）和变分贝叶斯方法（variational Bayesian methods）家族的一部分。VAE 包括编码器（encoder）和解码器（decoder），编码器将特征（输入）向量映射到潜在空间（latent space），可以产生来自同一分布的多个不同样本。而解码器为编码器的逆过程，从潜在空间映射回输入空间，以生成数据点（data points）。

将神经网络用于概率编码器表示为 $q_\phi(\mathbf{z} \mid \mathbf{x})$，为生成模型$\left.p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}\right)$后验$p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})$的近似。设潜在变量的先验为中心各向同性多元高斯（centered isotropic multivariate Gaussian）分布（多元正态分布），$p_{\boldsymbol{\theta}}(\mathbf{z})=\mathcal{N}(\mathbf{z} ; \mathbf{0}, \mathbf{I})$。注意到先验缺少参数，设$p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z})$为多元高斯，其分布参数用 MLP（具有单个隐藏层的全连接神经网络）从潜在空间$\mathbf{z}$中计算 。假设真实的后验具有近似对角协方差的近似高斯形式，$ \log q_\phi\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)=\log \mathcal{N}\left(\mathbf{z} ; \boldsymbol{\mu}^{(i)}, \boldsymbol{\sigma}^{2(i)} \mathbf{I}\right)$，式中，$\boldsymbol{\mu}^{(i)} , \boldsymbol{\sigma}^{(i)}$为近似后验的均值和标准差，对应到 MLP 的输出。$\mathbf{x}^{(i)}$为数据点的非线性函数。$\phi$为变分参数。

从下述试验的代码中可以观察到试验中的编码器网络结构被设计为，

```python
(img_2hid): Linear(in_features=784, out_features=200, bias=True)
(hid_2mu): Linear(in_features=200, out_features=20, bias=True)
(hid_2sigma): Linear(in_features=200, out_features=20, bias=True)
```

其中`hid_2mu`层输出为均值，而`hid_2sigm`层输出为标准差。

用$\mathbf{z}^{(i, l)}= g_\phi\left(\mathbf{x}^{(i)}, \boldsymbol{\epsilon}^{(l)}\right)=\boldsymbol{\mu}^{(i)}+\boldsymbol{\sigma}^{(i)} \odot \boldsymbol{\epsilon}^{(l)}  \text { where } \boldsymbol{\epsilon}^{(l)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$公式从近似后验$\mathbf{z}^{(i, l)} \sim q_\phi\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)$中采样，式中$\odot$表示元素积（element-wise product）。对应下述代码书写为，

```python
def forward(self, x):
    mu, sigma = self.encode(x)

    # Sample from latent distribution from encoder
    epsilon = torch.randn_like(sigma)
    z_reparametrized = mu + sigma*epsilon

    x = self.decode(z_reparametrized)
    return x, mu, sigma
```

从潜在空间采样后`z_reparametrized`，将其输入到解码器，解码器的网络结构如下：

```python
(z_2hid): Linear(in_features=20, out_features=200, bias=True)
(hid_2img): Linear(in_features=200, out_features=784, bias=True)
```

已知输入的特征向量和从潜在空间采样经解码器生成返回的特征向量，为了学习到较好的均值和标准差，其损失增加 KL 散度（Kullback-Leibler Divergence）一项，有$ \mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) \simeq \frac{1}{2} \sum_{j=1}^J\left(1+\log \left(\left(\sigma_j^{(i)}\right)^2\right)-\left(\mu_j^{(i)}\right)^2-\left(\sigma_j^{(i)}\right)^2\right)+\frac{1}{L} \sum_{l=1}^L \log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} \mid \mathbf{z}^{(i, l)}\right)  \text { where } \quad \mathbf{z}^{(i, l)}=\boldsymbol{\mu}^{(i)}+\boldsymbol{\sigma}^{(i)} \odot \boldsymbol{\epsilon}^{(l)} \quad \text { and } \quad \boldsymbol{\epsilon}^{(l)} \sim \mathcal{N}(0, \mathbf{I})$。对应的代码为，

```python
# loss
loss_fn = nn.BCELoss(reduction="sum")
reconst_loss = loss_fn(x_reconst, x)
kl_div = - torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))

# Backprop and optimize
loss = reconst_loss + kl_div
```

试验时，为了观察学习到的潜在空间，首先配置`Z_DIM = 2`，即学习到的均值和标准差的维度为2，用于在二维中打印观察。而后配置为`Z_DIM = 20`用于实际的计算。


```python
%load_ext autoreload 
%autoreload 2 
import usda.network as usda_nx
import usda.utils as usda_utils

import torchvision.datasets as datasets  
from torch.utils.data import DataLoader  
from torchvision import transforms
import torch.nn as nn
import matplotlib.pyplot as plt
import torch
import numpy as np
import torchvision
```

配置参数。


```python
# Configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
INPUT_DIM = 784
Z_DIM = 2
H_DIM = 200
NUM_EPOCHS = 10
BATCH_SIZE = 32
LR_RATE = 3e-4 
```

下载 MNIST 手写数字数据集。


```python
dataset=datasets.MNIST(root="C:/Users/richie/omen_richiebao/omen_temp/dataset/", train=True, transform=transforms.ToTensor(), download=True)
train_loader=DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)
```

初始化 VAE 模型、优化器和损失。


```python
# Initialize model, optimizer, loss
model = usda_nx.VariationalAutoEncoder(INPUT_DIM, Z_DIM).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)
loss_fn = nn.BCELoss(reduction="sum")
```

查看模型的网络结构，包含编码器和解码器。


```python
model
```




    VariationalAutoEncoder(
      (img_2hid): Linear(in_features=784, out_features=200, bias=True)
      (hid_2mu): Linear(in_features=200, out_features=2, bias=True)
      (hid_2sigma): Linear(in_features=200, out_features=2, bias=True)
      (z_2hid): Linear(in_features=2, out_features=200, bias=True)
      (hid_2img): Linear(in_features=200, out_features=784, bias=True)
    )



训练模型。


```python
# Run training
usda_nx.vae_train(NUM_EPOCHS, model, optimizer, loss_fn,train_loader,INPUT_DIM,device)
```

    1875it [00:18, 98.98it/s, loss=5.79e+3] 
    1875it [00:18, 101.03it/s, loss=5.06e+3]
    1875it [00:18, 101.94it/s, loss=5.28e+3]
    1875it [00:17, 104.55it/s, loss=5.73e+3]
    1875it [00:18, 103.89it/s, loss=5.4e+3] 
    1875it [00:18, 102.00it/s, loss=5.79e+3]
    1875it [00:19, 94.77it/s, loss=5.83e+3] 
    1875it [00:18, 103.85it/s, loss=5.23e+3]
    1875it [00:19, 96.91it/s, loss=5.32e+3] 
    1875it [00:20, 92.01it/s, loss=5.26e+3] 
    

从数据集中分别对应10个数字各提取一个样本用于训练模型编码器的输入以获得均值和标准差（用多元高斯分布（均值和标准差）表征的潜在空间）。


```python
images = []
idx = 0
for x, y in dataset:
    if y == idx:
        images.append(x.to(device))
        idx += 1
    if idx == 10:
        break

encodings_digit = []
for d in range(10):
    with torch.no_grad():
        mu, sigma = model.encode(images[d].view(1, 784))
    encodings_digit.append((mu, sigma))
```

用`np.random.multivariate_normal`方法从多元高斯分布中采样数据点。


```python
means=np.array([i[0][0].detach().cpu().numpy() for i in encodings_digit])
covs=np.array([i[1][0].detach().cpu().numpy() for i in encodings_digit])
covs_diag=[np.diag(i) for i in covs]

pts_lst=[np.random.multivariate_normal(mean, cov, size=80) for mean,cov in zip(means,covs_diag)]
```

    C:\Users\richie\AppData\Local\Temp\ipykernel_28376\3622666592.py:5: RuntimeWarning:
    
    covariance is not symmetric positive-semidefinite.
    
    

打印数据点的分布，可以发现10个数字的分布开始显现出团聚的分离性。因为配置的潜在空间维度为2，而有10个数字，因此将维度配置为大于10的一个值将会提高不同数字的分离。


```python
colors=usda_utils.cmap2hex('tab20',10)
fig, ax = plt.subplots(figsize=(5,5))
for idx,pts in enumerate(pts_lst):
    ax.scatter(pts[:,0], pts[:,1],c=colors[idx],label=f'{idx}')
ax.legend()
plt.show()
```


<img src="./imgs/4_10_4/output_157_0.png" height='auto' width='auto' title="caDesign">    


将潜在空间维度配置为20，训练模型。


```python
Z_DIM = 20

model = usda_nx.VariationalAutoEncoder(INPUT_DIM, Z_DIM).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)
loss_fn = nn.BCELoss(reduction="sum")
usda_nx.vae_train(NUM_EPOCHS, model, optimizer, loss_fn,train_loader,INPUT_DIM,device)
```

    1875it [00:19, 96.93it/s, loss=5.15e+3] 
    1875it [00:18, 99.45it/s, loss=4.78e+3] 
    1875it [00:19, 94.36it/s, loss=4.48e+3] 
    1875it [00:19, 97.07it/s, loss=4.53e+3] 
    1875it [00:20, 93.59it/s, loss=4.03e+3] 
    1875it [00:19, 94.85it/s, loss=4.58e+3] 
    1875it [00:19, 98.16it/s, loss=4.44e+3] 
    1875it [00:19, 94.29it/s, loss=4.41e+3] 
    1875it [00:20, 93.64it/s, loss=4.17e+3] 
    1875it [00:19, 94.44it/s, loss=4.04e+3] 
    

用训练的模型生成数字。


```python
usda_nx.vae_digit_inference(9,model,dataset,device, num_examples=5,figsize=(9,9),fontsize=10)
```


<img src="./imgs/4_10_4/output_161_0.png" height='auto' width='auto' title="caDesign">    



```python
usda_nx.vae_digit_inference(4,model,dataset,device, num_examples=5,figsize=(9,9),fontsize=10)
```


<img src="./imgs/4_10_4/output_162_0.png" height='auto' width='auto' title="caDesign">    


```python
usda_nx.vae_digit_inference(2,model,dataset,device, num_examples=5,figsize=(9,9),fontsize=10)
```


<img src="./imgs/4_10_4/output_163_0.png" height='auto' width='auto' title="caDesign">    

### 4.10.3.2 VGAE<sup>[29]</sup>

用 GCN 作为 VGAE 的编码器，用简单的内积作为其解码器。

定义（Deﬁnitions），给定一个无向无权图$\mathcal{G}=(\mathcal{V}, \mathcal{E})$，有$N=\mid\mathcal{V}\mid $个顶点。图$\mathcal{G}$的邻接矩阵为$A$（并假设对角线元素值为1，即顶点与自身的邻接），和度矩阵为$D$。同时，随机潜在向量（latent variables）为$\mathbf{z}_i$，归纳为$N \times F$的矩阵$Z$。顶点特征归纳为$N \times D$的矩阵$X$。

推理模型（Inference model），构建有两层 GCN 参数化的简单推理模型： $ q(\mathbf{Z} \mid \mathbf{X}, \mathbf{A})=\prod_{i=1}^N q\left(\mathbf{z}_i \mid \mathbf{X}, \mathbf{A}\right), \text { with } q\left(\mathbf{z}_i \mid \mathbf{X}, \mathbf{A}\right)=\mathcal{N}\left(\mathbf{z}_i \mid \boldsymbol{\mu}_i, \operatorname{diag}\left(\boldsymbol{\sigma}_i^2\right)\right) $，式中，均值向量$\boldsymbol{\mu}_i$的矩阵形式为$\boldsymbol{\mu}=\operatorname{GCN}_\mu(\mathbf{X}, \mathbf{A})$；类似有标准差的自然对数，$\log \sigma=\operatorname{GCN}_\sigma(\mathbf{X}, \mathbf{A})$。两层的 GCN 网络定义为$\operatorname{GCN}(\mathbf{X}, \mathbf{A})=\tilde{\mathbf{A}} \operatorname{ReLU}\left(\tilde{\mathbf{A}} \mathbf{X} \mathbf{W}_0\right) \mathbf{W}_1$，其权重矩阵为$\mathbf{W}_i \cdot \operatorname{GCN}_\mu(\mathbf{X}, \mathbf{A})$和$\operatorname{GCN}_{\boldsymbol{\sigma}}(\mathbf{X}, \mathbf{A})$，共享第一层参数$\mathbf{W}_0 \cdot \operatorname{ReLU}(\cdot)=\max (0, \cdot) $和$ \tilde{\mathbf{A}}=\mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}}$，为对称归一化邻接矩阵。

生成模型（Generative model ），由潜在变量的内积给出：$p(\mathbf{A} \mid \mathbf{Z})=\prod_{i=1}^N \prod_{j=1}^N p\left(A_{i j} \mid \mathbf{z}_i, \mathbf{z}_j\right) \text {, with } p\left(A_{i j}=1 \mid \mathbf{z}_i, \mathbf{z}_j\right)=\sigma\left(\mathbf{z}_i^{\top} \mathbf{z}_j\right)$，式中，$A_{i j}$为$A$的元素，$\sigma(\cdot) $为 Logistic Sigmoid 函数。

学习（Learning），就变分参数$\mathbf{W}_i$优化变分下界$\mathcal{L}$：$\mathcal{L}=\mathbb{E}_{q(\mathbf{Z} \mid \mathbf{X}, \mathbf{A})}[\log p(\mathbf{A} \mid \mathbf{Z})]-\operatorname{KL}[q(\mathbf{Z} \mid \mathbf{X}, \mathbf{A}) \| p(\mathbf{Z})] $，式中，$\mathrm{KL}[q(\cdot) \| p(\cdot)]$为$q(\cdot) $和$p(\cdot)$之间的 KL 散度。并进一步取高斯先验$p(\mathbf{Z})=\prod_i p\left(\mathbf{z}_{\mathbf{i}}\right)=\prod_i \mathcal{N}\left(\mathbf{z}_i \mid 0, \mathbf{I}\right)$。对于非常稀疏的邻接矩阵$A$，可以在$\mathcal{L}$中重新加权$A_{i j}=1$的项或者$A_{i j}=0$的子样（ sub-sample）项。训练过程中执行全批梯度下降，并使用重参数化技巧（reparameterization trick）<sup>[30]</sup>进行训练。对于无特征的情况，只需放弃对$X$的依赖，将$X$替换为 GCN 中的单位矩阵。

GAE（Non-probabilistic graph auto-encoder）模型，对于 VGAE 模型的非概率变体，计算嵌入$Z$和重构的邻接矩阵$\hat{\mathbf{A}}$有，$\hat{\mathbf{A}}=\sigma\left(\mathbf{Z Z}^{\top}\right) \text {, with } \mathbf{Z}=\operatorname{GCN}(\mathbf{X}, \mathbf{A})$。

使用前文中植物调查样方物种数据集，不过由植物调查样方物种的图嵌入计算转换为预测物种间具有联系的概率，即物种共存的可能性。顶点特征$X$使用两个因素，一个为覆盖率，另一个为物种名称。覆盖率为连续数值，通过除以100将其缩放至[0,1]区间；而物种名称为分类数据，需要转换为数值后喂入模型，因为分类数据并无顺序关系，因此使用独热编码（One-Hot Encoding），而不是整数编码（Integer Encoding）<sup>[31]250</sup>。

在图构建时，配置阈值为 0.05（5%），只有大于等于该阈值覆盖率的物种才构建调查样方内物种间的边。


```python
%load_ext autoreload 
%autoreload 2 
import usda.network as usda_nx

import networkx as nx
from itertools import combinations
from torch_geometric.utils.convert import from_networkx
import torch_geometric.transforms as T
import torch
from torch_geometric.data import Batch,Data
from torch_geometric.loader import DataLoader
from tqdm import tqdm
import pandas as pd
from sklearn.preprocessing import OneHotEncoder,Normalizer,LabelEncoder
import numpy as np
```

读取数据并构建图，顶点属性`x`为归一化的覆盖率和物种的独热编码。


```python
vegetation_plot_species_list_fn='../data/Countryside_Survey_1978_vegetation_plot_data/data/Vegetation Plot - Species List 1978.csv'
vegetation_plot_information_fn='../data/Countryside_Survey_1978_vegetation_plot_data/data/Vegetation Plot - Plot Information 1978.csv'
```


```python
species_list=pd.read_csv(vegetation_plot_species_list_fn)
le=LabelEncoder()
species_list['name_encoder']=le.fit_transform(species_list.BRC_NAMES)
species_list['total_cover_norm']=species_list.TOTAL_COVER.apply(lambda x:x/100)
species_list.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YEAR</th>
      <th>SQUARE_ID</th>
      <th>PLOT_ID</th>
      <th>AMALG_PTYPE</th>
      <th>BRC_NUMBER</th>
      <th>BRC_NAMES</th>
      <th>TOTAL_COVER</th>
      <th>name_encoder</th>
      <th>total_cover_norm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>44492</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>5505962.0</td>
      <td>Cladonia sp.</td>
      <td>1</td>
      <td>153</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>44493</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>9202136.0</td>
      <td>Vaccinium myrtillus</td>
      <td>1</td>
      <td>643</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>44494</th>
      <td>1978</td>
      <td>WDGZFA</td>
      <td>GKGCGUEPMT</td>
      <td>X</td>
      <td>9202138.0</td>
      <td>Vaccinium vitis-idaea</td>
      <td>1</td>
      <td>646</td>
      <td>0.01</td>
    </tr>
  </tbody>
</table>
</div>



建立独热编码模型，用于后续物种名称到独热编码的计算。


```python
X_names=np.expand_dims(species_list.BRC_NAMES.values,1).astype(str)
onehot_encoder=OneHotEncoder(sparse_output=False)
onehot_encoder.fit(X_names)
```




<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div>



按调查样方地块`PLOT_ID`列分组数据。


```python
plot_species_group=species_list.groupby(by=['PLOT_ID'])
species_encoder2name=pd.Series(species_list.BRC_NAMES.values,index=species_list.name_encoder).to_dict()
```

依次构建各个调查样方内物种的图。


```python
datas=[]

for group in tqdm(plot_species_group):
    species_cover_dict=pd.Series(group[1].total_cover_norm.values,index=group[1].name_encoder).to_dict()
    nodes_attri=[(k,{'x':np.concatenate((np.array([v]),onehot_encoder.transform([[species_encoder2name[k]]])[0])).astype(np.float32),'name':species_encoder2name[k]}) for k,v in species_cover_dict.items()]
    species_cover_dict_threshold={k:v for k,v in species_cover_dict.items() if v >=0.05}
    edges=list(combinations(list(species_cover_dict_threshold.keys()), 2))
    G=nx.Graph()
    G.add_nodes_from(nodes_attri)
    G.add_edges_from(edges)
    G_pyg=from_networkx(G)
    datas.append(G_pyg)   
```

    100%|█████████████████████████████████████████████| 2279/2279 [01:10<00:00, 32.20it/s]
    

使用`PyG`的`Batch`方法将所有调查样方的图描述为一个大的（不连接）图数据对象，并切分为训练、测试和验证数据集。


```python
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform=T.Compose([
    T.ToDevice(device),
    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),
])

batch=Batch.from_data_list(datas)
batch=transform(batch)
train_data, val_data, test_data=batch
```

查看顶点的特征。


```python
train_data.x
```




    tensor([[0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
            [0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
            [0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
            ...,
            [0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
            [0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
            [0.0100, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
           device='cuda:0')



查看 VGAE 网络结构。编码器由多层 GCN （使用`PgG`提供的`GCNConv`层）组成，输出为潜在空间多元高斯分布的均值$\mu$和标准差的自然对数$\log \sigma$；解码器由潜在变量的内积给出，即`InnerProductDecoder()`方法。从潜在空间中采样对应的代码为：

```python
def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:
    if self.training:
        return mu + torch.randn_like(logstd) * torch.exp(logstd)
    else:
        return mu
```

损失部分的代码为：

```python
z = self.model.encode(train_data.x, train_data.edge_index)
loss = self.model.recon_loss(z, train_data.pos_edge_label_index) + (1 / train_data.num_nodes) * self.model.kl_loss()
```

损失包括两部分，一部分为`recon_loss`，一部分为`kl_loss`。其中`recon_loss`部分对应代码如下：

```python
def recon_loss(self, z: Tensor, pos_edge_index: Tensor,
               neg_edge_index: Optional[Tensor] = None) -> Tensor:
    r"""Given latent variables :obj:`z`, computes the binary cross
    entropy loss for positive edges :obj:`pos_edge_index` and negative
    sampled edges.

    Args:
        z (torch.Tensor): The latent space :math:`\mathbf{Z}`.
        pos_edge_index (torch.Tensor): The positive edges to train against.
        neg_edge_index (torch.Tensor, optional): The negative edges to
            train against. If not given, uses negative sampling to
            calculate negative edges. (default: :obj:`None`)
    """
    pos_loss = -torch.log(
        self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()

    if neg_edge_index is None:
        neg_edge_index = negative_sampling(pos_edge_index, z.size(0))
    neg_loss = -torch.log(1 -
                          self.decoder(z, neg_edge_index, sigmoid=True) +
                          EPS).mean()

    return pos_loss + neg_loss
```

`kl_loss`部分对应代码为：

```python
def kl_loss(self, mu: Optional[Tensor] = None,
            logstd: Optional[Tensor] = None) -> Tensor:
    r"""Computes the KL loss, either for the passed arguments :obj:`mu`
    and :obj:`logstd`, or based on latent variables from last encoding.

    Args:
        mu (torch.Tensor, optional): The latent space for :math:`\mu`. If
            set to :obj:`None`, uses the last computation of :math:`\mu`.
            (default: :obj:`None`)
        logstd (torch.Tensor, optional): The latent space for
            :math:`\log\sigma`.  If set to :obj:`None`, uses the last
            computation of :math:`\log\sigma^2`. (default: :obj:`None`)
    """
    mu = self.__mu__ if mu is None else mu
    logstd = self.__logstd__ if logstd is None else logstd.clamp(
        max=MAX_LOGSTD)
    return -0.5 * torch.mean(
        torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))
```


```python
vgae_model=usda_nx.VGAE_gnn(train_data.num_features, 16,lr=0.01,device=device)
vgae_model.model
```




    VGAE(
      (encoder): Encoder(
        (conv1): GCNConv(676, 32)
        (conv_mu): GCNConv(32, 16)
        (conv_logstd): GCNConv(32, 16)
      )
      (decoder): InnerProductDecoder()
    )



训练模型。


```python
vgae_model.fit(train_data, val_data,epochs=301,verbose=50 )
```

    Epoch  0 | Loss: 3.5018 | Val AUC: 0.6436 | Val AP: 0.5539
    Epoch 50 | Loss: 0.8684 | Val AUC: 0.9529 | Val AP: 0.9146
    Epoch 100 | Loss: 0.7979 | Val AUC: 0.9768 | Val AP: 0.9622
    Epoch 150 | Loss: 0.7788 | Val AUC: 0.9836 | Val AP: 0.9764
    Epoch 200 | Loss: 0.7793 | Val AUC: 0.9849 | Val AP: 0.9772
    Epoch 250 | Loss: 0.7628 | Val AUC: 0.9878 | Val AP: 0.9808
    Epoch 300 | Loss: 0.7584 | Val AUC: 0.9893 | Val AP: 0.9836
    

用测试数据集测试结果精度约为 0.98。


```python
test_auc, test_ap = vgae_model.test(test_data) 
print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')
```

    Test AUC: 0.9858 | Test AP 0.9817
    

保存和读取已训练的模型。


```python
vgae_path='../models/vgae.pt'
torch.save(vgae_model.model,vgae_path)
```


```python
model_vgae=torch.load(vgae_path,map_location=torch.device('cpu')) 
model_vgae.eval();
```

从一个调查样方中随机提取三个物种构建两两之间均存在边的图，其中覆盖率随机给出，用已训练的模型预测物种间存在边的可能性如下。


```python
edge_index_1=torch.tensor([[0, 0, 1],
                          [1, 2, 2]], dtype=torch.long)
x_1_coverNID=[[ 20., 175],  [ 10., 394], [  50., 151]]
x_1=torch.tensor([np.concatenate((np.array([i[0]/100]),onehot_encoder.transform([[species_encoder2name[i[1]]]])[0])) for i in x_1_coverNID], dtype=torch.float32)
data_fake_1=Data(x=x_1, edge_index=edge_index_1)

encoder2name4print=lambda  x:{i:species_encoder2name[i] for i in [int(j[1]) for j in x]}
print(encoder2name4print(x_1_coverNID))
```

    {175: 'Cynosurus cristatus', 394: 'Nardus stricta', 151: 'Cirsium palustre'}
    

预测结果表明从一个调查样方中随机提取三个物种两两之间存在边的可能性极大，即可以估计为物种共存。


```python
z=model_vgae.encode(data_fake_1.x,data_fake_1.edge_index) 
Ahat=torch.sigmoid(z @ z.T)
Ahat
```




    tensor([[0.9776, 0.9764, 0.9715],
            [0.9764, 0.9911, 0.9931],
            [0.9715, 0.9931, 0.9959]], grad_fn=<SigmoidBackward0>)



下述则随机给出三个物种和各自假设的覆盖率，可以观察到 Oenanthe crocata 和 Papaver rhoeas 存在边的可能性为 0.7543，而其它物种间则只有约一半的几率存在边。


```python
edge_index_2=torch.tensor([[0, 0, 1],
                          [1, 2, 2]], dtype=torch.long)
x_2_coverNID=[[ 10., 200],  [ 35., 399], [  50., 410]]
x_2=torch.tensor([np.concatenate((np.array([i[0]/100]),onehot_encoder.transform([[species_encoder2name[i[1]]]])[0])) for i in x_2_coverNID], dtype=torch.float32)
data_fake_2=Data(x=x_2, edge_index=edge_index_2)
print(encoder2name4print(x_2_coverNID))

z=model_vgae.encode(data_fake_2.x,data_fake_2.edge_index) 
Ahat=torch.sigmoid(z @ z.T)
Ahat
```

    {200: 'Eleocharis palustris', 399: 'Oenanthe crocata', 410: 'Papaver rhoeas'}
    




    tensor([[0.5781, 0.5348, 0.5069],
            [0.5348, 0.6813, 0.7543],
            [0.5069, 0.7543, 0.8557]], grad_fn=<SigmoidBackward0>)



可以对测试数据集顶点间存在边的可能性进行估计。


```python
z = model_vgae.encode(test_data.x.cpu(), test_data.edge_index.cpu())
Ahat = torch.sigmoid(z @ z.T)
```


```python
print(Ahat.shape)
Ahat
```

    torch.Size([44466, 44466])
    




    tensor([[0.5685, 0.5089, 0.5407,  ..., 0.5687, 0.5447, 0.5137],
            [0.5089, 0.5613, 0.5291,  ..., 0.5539, 0.5306, 0.5130],
            [0.5407, 0.5291, 0.5704,  ..., 0.5681, 0.5449, 0.5162],
            ...,
            [0.5687, 0.5539, 0.5681,  ..., 0.6827, 0.5785, 0.5481],
            [0.5447, 0.5306, 0.5449,  ..., 0.5785, 0.5827, 0.5303],
            [0.5137, 0.5130, 0.5162,  ..., 0.5481, 0.5303, 0.5526]],
           grad_fn=<SigmoidBackward0>)



### 4.10.3.3 生成图

`NetworkX`库提供有[多种类型生成图的函数](https://networkx.org/documentation/latest/reference/generators.html#)<sup>⑨</sup>，例如各种类型随机图生成器，各类小型并有命名的图（如 Krackhardt Kite Social Network、Moebius-Kantor graph等）的生成器，著名社交网络生成器和用于研究社交网络的图形类生成器等。而基于 GNN 的图生成器更具表现力，用于深度图生成的网络架构主要有 GVAEs，GANs 和自回归模型（autoregressive models）等。上文用$\hat{A}=\sigma\left(Z^T Z\right)$预测顶点间的链接，如果给一个概率的阈值，例如下述的 0.9，则可以根据邻接矩阵的概率生成图，大于0.9的顶点赋值为1，预示顶点间存在边；否则赋值为0，预示顶点间不存在边。


```python
adj = torch.where((z @ z.T) > 0.9, 1, 0)
adj[10000:,2000:]
```




    tensor([[0, 0, 0,  ..., 0, 0, 0],
            [1, 1, 1,  ..., 0, 0, 0],
            [0, 0, 0,  ..., 0, 0, 0],
            ...,
            [0, 0, 0,  ..., 0, 0, 0],
            [0, 0, 0,  ..., 0, 0, 0],
            [0, 0, 0,  ..., 0, 0, 0]])



---

注释（Notes）：

①  NetworkX，（<https://networkx.org/documentation/stable/index.html>）。

②  Countryside Survey 1978 vegetation plot data，（<https://ckan.publishing.service.gov.uk/dataset/countryside-survey-1978-vegetation-plot-data>）。

③  Sklearn，（<https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html>）。

④  Node2Vec，（<https://github.com/eliorc/node2vec>）。

⑤  PyG （PyTorch Geometric），（<https://pytorch-geometric.readthedocs.io/en/latest/index.html>）。

⑥  PyTorch，（<https://pytorch.org/>）。

⑦  PyG （PyTorch Geometric） datasets，（<https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html>）。

⑧  卷积层（Convolutional Layers），（<https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers>）。

⑨  NetworkX库多种类型生成图的函数，（<https://networkx.org/documentation/latest/reference/generators.html#>）。

参考文献（References）:

[1] Xu, M. (2021). Understanding Graph Embedding Methods and Their Applications. SIAM Review, 63(4), 825–853. doi:10.1137/20M1386062.

[2] Abdel-Basset, M., Moustafa, N., Hawash, H., & Tari, Z. (2023). Responsible Graph Neural Networks (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781003329701

[3] Perozzi, B., Al-Rfou, R., & Skiena, S. (2014). DeepWalk: Online Learning of Social Representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 701–710). Association for Computing Machinery.

[4] Grover, A. & Leskovec, J. (2016). node2vec: Scalable feature learning for networks. Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining (p./pp. 855--864).

[5] Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J. & Mei, Q. (2015). LINE: Large-scale Information Network Embedding. WWW (p./pp. 1067--1077), New York, NY, USA: ACM. ISBN: 978-1-4503-3469-3

[6] Shen, X. & Chung, F.-L. (2019). Deep Network Embedding for Graph Representation Learning in Signed Networks.. CoRR, abs/1901.01718.

[7] Ribeiro, L. F., Saverese, P. H. & Figueiredo, D. R. (2017). struc2vec: Learning Node Representations from Structural Identity. Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17 (p./pp. 385--394), Halifax, NS, Canada: ACM Press. ISBN: 978-1-4503-4887-4

[8] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. arXiv [Cs.CL]. Retrieved from http://arxiv.org/abs/1301.3781

[9] GraphEmbedding, <https://github.com/shenweichen/GraphEmbedding>

[10] P.Erdős and A. Rényi, On Random Graphs, Publ. Math. 6, 290 (1959).

[11] Huffman, D. (1952). A Method for the Construction of Minimum-Redundancy Codes. Proceedings of the IRE, 40(9), 1098–1101. doi:10.1109/jrproc.1952.273898 

[12] Rong, X. (2014). word2vec parameter learning explained. arXiv preprint arXiv:1411.2738.

[13] Morin, F., & Bengio, Y. (2005). Hierarchical Probabilistic Neural Network Language Model. In Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics (pp. 246–252). PMLR.

[14] Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality. arXiv [Cs.CL]. Retrieved from http://arxiv.org/abs/1310.4546

[15] Zachary, Wayne W. “An Information Flow Model for Conflict and Fission in Small Groups.” Journal of Anthropological Research, 33, 452–473, (1977).

[16] Ornduff, R., Faber, P., & Keeler-Wolf, T. (2003). Introduction to California Plant Life. University of California Press.

[17] Plant community, <https://en.wikipedia.org/wiki/Plant_community>

[18] Labonne, M. (2023). Hands-On Graph Neural Networks Using Python (1st ed.). Packt Publishing. (Original work published 2023)

[19] Understanding Convolutions on Graphs, <https://distill.pub/2021/understanding-gnns/>.

[20] Benedek Rozemberczki, Carl Allen, Rik Sarkar, Multi-Scale attributed node embedding, Journal of Complex Networks, Volume 9, Issue 2, April 2021, cnab014, https://doi.org/10.1093/comnet/cnab014

[21] Thomas N. Kipf, & Max Welling (2017). Semi-Supervised Classification with Graph Convolutional Networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.

[22] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). Attention Is All You Need. arXiv [Cs.CL]. Retrieved from http://arxiv.org/abs/1706.03762

[23] Shaked Brody, Uri Alon, & Eran Yahav (2022). How Attentive are Graph Attention Networks? . In International Conference on Learning Representations.

[24] Hamilton, W., Ying, Z. & Leskovec, J. (2017). Inductive Representation Learning on Large Graphs. Advances in Neural Information Processing Systems, , 1024-1034.

[25] Marinka Zitnik, Jure Leskovec, Predicting multicellular function through multi-layer tissue networks, Bioinformatics, Volume 33, Issue 14, July 2017, Pages i190–i198, https://doi.org/10.1093/bioinformatics/btx252

[26] Shervashidze, N., Schweitzer, P., Leeuwen, E., Mehlhorn, K., & Borgwardt, K. (2011). Weisfeiler-Lehman Graph Kernels. J. Mach. Learn. Res., 12(null), 2539–2561.

[27] Weisfeiler and Lehman, A.A. (1968) A Reduction of a Graph to a Canonical Form and an Algebra Arising during This Reduction. Nauchno-Technicheskaya Informatsia, 9.

[28] Keyulu Xu, Weihua Hu, Jure Leskovec, & Stefanie Jegelka (2019). How Powerful are Graph Neural Networks?. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.

[29] Kipf, T. N. & Welling, M. (2016). Variational Graph Auto-Encoders. arXiv:1611.07308 [cs, stat].

[30] Kingma, D. P. & Welling, M. (2014). Auto-Encoding Variational Bayes. 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.

[31] Brownlee, J, Data Preparation for Machine Learning - Data Cleaning, Feature Selection, and Data. machine learning mastery, 2020.
