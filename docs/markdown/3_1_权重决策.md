Created on Mon Feb 20 15:44:40 2023 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.2 权重决策

## 3.1.1 多准则决策法 

多准则决策法，Multiple Criteria Decision-Making（MCDM）也称之为 Multi-Criteria Decision Analysis（MCDA），Multi-attribute Decision-Making（MADM），或multi-object decision-making（MODM）（多目标决策法），是关于在同时考虑多个准则（criteria）/目标（objectives）下对备选方案（alternatives）进行排名（rank）或选择时做出决策。当准则越复杂， 备选方案增多时，确定哪个为最优方案的难度就越大。MCDM经过几十年的发展，各类算法涌现，已经成为解决现实问题的强大工具，可以帮助寻找最能满足要求众多相互冲突目标的决策<sup>[1]</sup>。MCDM被广泛应用于数学、经济学、管理学和工程领域等众多学科，服务于商业、非营利组织、政府、卫生、教育和个人决策等。MCDM（离散型，discrete）问题可以表述为一个矩阵，$\begin{aligned} & \begin{array}{llll} \hspace{35pt} c_1 & \hspace{8pt} c_2 & \hspace{5pt} \cdots &  \hspace{5pt} c_n\end{array} \\ & A=\begin{array}{c}a_1 \\ a_2 \\ \vdots \\ a_m\end{array}\left(\begin{array}{cccc}p_{11} & p_{12} & \cdots & p_{1 n} \\ p_{21} & p_{22} & \cdots & p_{2 n} \\ \vdots & \vdots & \ddots & \vdots \\ p_{m 1} & p_{m 2} & \cdots & p_{m n}\end{array}\right) \\ & \end{aligned}$，式中$\{ a_{1},a_{2}, \ldots ,a_{m}  \}$为备选方案（feasible alternatives，actions，stimuli）；$\{ c_{1},c_{2}, \ldots ,c_{n}  \}$为决策准则（decision-making criterion）；$p_{ij} $为第$i$个备选方案对应到第$j$个决策准则的得分。其目标是从备选方案中寻找到最好（最可取、最重要的）的选择，即具有最佳整体价值（综合评价指数）的方案。计算第$i$个备选方案综合评价指数$V_{i} $的方法有很多算法，一般形式可以对决策准则赋予权重值$w_{j}(w_{j} \geq 0, \sum w_{j}=1  ) $，则$V_{i} $可以用一个简单的加权值函数得到，这是大多数 MCDM 方法的基础模型，公式为：$V_{i}= \sum_{j=1}^n  w_{j} p_{ij}$。上述流程最为重要的部分是决策准则权重$w=\{ w_{1},w_{1}, \ldots ,w_{n} \}$的确定<sup>[2]</sup>。

从上述对MCDM的描述及公式的表述，可以发现规划中的很多地理空间问题都可以转换为MCDM问题，例如其中的备选方案可以为城市的行政分区、子流域、样方、采样点、乃至栅格单元等；而决策准则为各类评价指标（体系），例如生态敏感性评价指标（压力层面的人口密度指数、建设用地占比、农业用地占比、污水排放率、废弃排放量、粉尘排放量、灾害易发度和地形坡度；状态层面的土地胁迫指数、生境质量指数、土地利用类型、水网密度指数、年降雨量、年总气温、植被覆盖度和经济发达指数；及响应层面的造林面积、生活污水处理率、工业SO<sub>2</sub>去除量和固体废物利用率等），采样熵值权重法和PCA权重法计算<sup>[3]</sup>；生态脆弱性评价指标（生态敏感性层面的景观破碎度、地形指数、土壤侵蚀量；生态恢复力层面的蔓延度、归一化植被指数、生物丰度等；生态压力度层面的人类活动强度和土地利用程度等），应用了熵权法计算<sup>[4]</sup>；景观感知决定因素（环境价值、文化价值、美学价值和个人经历或回忆等）<sup>[5]</sup>；热脆弱性指数（Heat Vulnerability Index，HVI）（涉及人口密度、小于5岁儿童人口比例、大于65，大于85的老人人口比例、大于65独居老人人口比例、小于5岁低于贫困线家庭的儿童人口比例、大于65岁低于贫困线家庭的老人人口比例、树冠覆盖率和早于1980年建成的建筑比例等），使用熵权法和TOPSIS（Technique for Order of Preference by Similarity to Ideal Solution ）算法计算<sup>[6]</sup>；生态系统服务评估和权衡（Integrated Valuation of Ecosystem Services and Tradeoffs，[InVEST](https://naturalcapitalproject.stanford.edu/software/invest)）<sup>①</sup>中的很多模型也可以从MCDM角度思考，例如生物多样指数（涉及到当前土地利用/土地覆盖类型、威胁影响距离、威胁地图、栖息地适宜性和栖息地对威胁的敏感性等）。

就MCMD问题，当前形成有多个[软件工具](https://en.wikipedia.org/wiki/Decision-making_software#Comparison_of_decision-making_software)<sup>②</sup>，Valdecy Pereira则将其集成到了Python库中，构建了[pyDecision](https://github.com/Valdecy/pyDecision)包<sup>③</sup>，包括40余种算法。对MCMD的解释，首先再现Soheil Boroushaki基于熵值权重法和改进的TOPSIS算法的MCDA计算<sup>[6]</sup>；并将其应用于城市环境传感器AoT污染气体浓度数据测量点污染度指数评估中；再引入解释`pyDecision`集成的各类算法。


```python
# IPython extension to reload modules before executing user code.
%load_ext autoreload 
# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.
%autoreload 2 

from usda import datasets as usda_datasets
from usda import weight as usda_weight
from usda import database as usda_database
from usda import utils as usda_utils
from usda import data_visualization as usda_vis
from usda.database import postSQL2gpd,gpd2postSQL

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pyDecision.algorithm as da

np.set_printoptions(linewidth=np.inf)
```

### 3.1.1.1 再现熵值权重法和改进的TOPSIS算法

#### 1)  熵值权重法

对于MCDM问题矩阵$A$，包含一定数量的信息，可以用于探索决策准则之间对备选方案综合评价指数影响的程度，即计算决策准则权重。权重的主观方法是由决策者、规划者、利益相关者根据经验或调查配置权重值，而客观方法则可以根据矩阵$A$决策准则中包含的信息量评估权重值。信息论（information theory）中香农的熵概念（Shannon’s entropy concept）已广泛应用于工程、信息科学和管理领域，用于衡量MCDM问题中包含的信息量，计算决策准则（例如各类指标）的信息量。

将Soheil Boroushaki构建的示范数据矩阵写入到`USDA`库中，可以通过`usda_datasets.load_evaluation_criteria_raw_values()`方法调入，该数据用DataFrame格式表述，列为决策准则（criteria），包括坡度（slope）（度）、到水体距离（distance2water）（英里）、高程（elevation）（尺）和到人口中心的距离（distance2population）（英里）；行为备选方案（alternative），对应地理空间的位置区域，索引值为0、1、2和3。


```python
evaluation_criteria_raw_values_df=usda_datasets.load_evaluation_criteria_raw_values().data
evaluation_criteria_raw_values_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>slope</th>
      <th>distance2water</th>
      <th>elevation</th>
      <th>distance2population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9</td>
      <td>2.2</td>
      <td>5700</td>
      <td>1.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20</td>
      <td>3.2</td>
      <td>3100</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10</td>
      <td>2.0</td>
      <td>4900</td>
      <td>1.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16</td>
      <td>3.5</td>
      <td>3600</td>
      <td>1.4</td>
    </tr>
  </tbody>
</table>
</div>



信息熵的计算公式为：$E_j=\left\{\begin{array}{cc}-\frac{\sum_{i=1}^m p_{i j} \cdot \ln \left(p_{i j}\right)}{\ln (m)} & , p_{i j} \neq 0 \\ 0 & , p_{i j}=0\end{array}\right.$，式中：$p_{i j}=\frac{a_{i j}}{\sum_{i=1}^m a_{i j}}$，$a_{i j}$为原始决策准则值，$p_{i j}$为原始决策准则值$a_{i j}$占各自决策准则列之和的比例，定义`df_Pij()`方法实现计算。由信息熵计算决策准则的权重值，公式为：$w_j=\frac{1-E_j}{\sum_{i=1}^m\left(1-E_j\right)}$，定义`entropy_weight()`方法，实现权重值计算，输入矩阵为原始决策准则值，$p_{i j}$直接在该函数内部实现。


```python
df_Pij=usda_weight.df_Pij(evaluation_criteria_raw_values_df)
df_Pij
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>slope</th>
      <th>distance2water</th>
      <th>elevation</th>
      <th>distance2population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.163636</td>
      <td>0.201835</td>
      <td>0.329480</td>
      <td>0.235294</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.363636</td>
      <td>0.293578</td>
      <td>0.179191</td>
      <td>0.254902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.181818</td>
      <td>0.183486</td>
      <td>0.283237</td>
      <td>0.235294</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.290909</td>
      <td>0.321101</td>
      <td>0.208092</td>
      <td>0.274510</td>
    </tr>
  </tbody>
</table>
</div>



`Ej`列为信息熵，`Wj`列为权重值。其中`slope`具有相对最小的信息熵，表明`slope`决策准则值在备选方案（地理空间区域）中分布相对不均匀，权重值相对较高；而对于`distance2population`决策准则值在备选方案中分布相对均匀，权重值则相对较低。


```python
entropy_weight_df=usda_weight.entropy_weight(evaluation_criteria_raw_values_df)
entropy_weight_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Ej</th>
      <th>1-Ej</th>
      <th>Wj</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>slope</th>
      <td>0.961706</td>
      <td>0.038294</td>
      <td>0.477279</td>
    </tr>
    <tr>
      <th>distance2water</th>
      <td>0.980097</td>
      <td>0.019903</td>
      <td>0.248060</td>
    </tr>
    <tr>
      <th>elevation</th>
      <td>0.979473</td>
      <td>0.020527</td>
      <td>0.255832</td>
    </tr>
    <tr>
      <th>distance2population</th>
      <td>0.998489</td>
      <td>0.001511</td>
      <td>0.018829</td>
    </tr>
  </tbody>
</table>
</div>



#### 2)  TOPSIS（理想解法） 

决策规则（decision rule）可以定义为通过规范化具有权重的决策准则，计算每个备选方案的综合性指标，进行排序，选择最佳方案的过程。MCDM的决策规则包含有加权线性组合（weighted linear combination，WLC）、加权求和/布尔叠加法（weighted summation/Boolean overlay methods）、层次分析法（Analytic Hierarchy Process，AHP），理想/参考点法（ideal/reference point methods）和排序法（outranking methods）等众多算法<sup>[7,8]</sup>。TOPSIS (Technique for Order Performance by Similarity to Ideal Solution)算法的基本原理是折衷的解决方案必须同时靠近正理想解（positive ideal solution，PIS）而远离负理想解（ negative ideal solution，NIS）。正理想解表示一个假设的备选方案，其由每个决策准则的最理想的规范化属性值组成；而负理想解表示的假设备选方案由每个决策准则的最差性能的规范化属性值组成。TOPSIS的基本假设是决策准则（评估标注）值的单调递增或递减，因此识别一组决策准则值的最大值和最小值，可以很容易确定每个准则的正理想和负理想解。TOPSIS 结合到正理想解和负理想解的距离来衡量每个备选位置与正理想解的相对接近程度，然后，备选方案将根据这一综合衡量标准进行排名<sup>[9]</sup>。

首先通过将决策矩阵$A$中的每个决策准则值$a_{i j}$标准化为无量纲的$v_{i j}$来构建归一化决策矩阵，以便比较不同的属性，其公式为： $v_{i j}=\frac{a_{i j}}{\sqrt{\sum_{i=1}^m a_{i j}^2}}$，定义`df_standardized_evaluation()`方法实现。


```python
standardized_evaluation_criteria_df=usda_weight.df_standardized_evaluation(evaluation_criteria_raw_values_df)
standardized_evaluation_criteria_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>slope</th>
      <th>distance2water</th>
      <th>elevation</th>
      <th>distance2population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.311086</td>
      <td>0.393045</td>
      <td>0.641016</td>
      <td>0.469596</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.691301</td>
      <td>0.571702</td>
      <td>0.348623</td>
      <td>0.508729</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.345651</td>
      <td>0.357314</td>
      <td>0.551049</td>
      <td>0.469596</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.553041</td>
      <td>0.625299</td>
      <td>0.404852</td>
      <td>0.547862</td>
    </tr>
  </tbody>
</table>
</div>



然后，确定正理想解（$V^{+}(PIS)$）和负理想解（$ V^{-}(NIS)$），其公式为：$\begin{aligned} & V^{+}=\left\{v_1^{+}, v_2^{+}, \ldots, v_n^{+}\right\}=\left\{\left(\max _i v_{i j} \mid j \in J\right),\left(\min _i v_{i j} \mid j \in J^{\prime}\right), i=1,2, \ldots, m\right\} \\ & V^{-}=\left\{v_1^{-}, v_2^{-}, \ldots, v_n^{-}\right\}=\left\{\left(\min _i v_{i j} \mid j \in J\right),\left(\max _i v_{i j} \mid j \in J^{\prime}\right), i=1,2, \ldots, m\right\}\end{aligned}$，式中，$J$与收益、最大化或正向评估标准化相关；而$J' $与成本、最小化或反向评估标准相关联。定义`PIS_NIS()`方法实现，对于每个决策准则方向的确定（值越大越好，约趋向正理想解，还是正好相反；负理想解同，通常与正理想解相反），通过传入`pis`参数确定，该参数的形式设计为一个字典，以决策准则（列名）为键，值为1或者0，为1时表明正理想解越大越好；为0时表明正理想解越小越好。负理想解与正理想解相反（由程序内部判断）。例如，对于`slope`决策准则为值越低越好，因此正理想解为0.311为最小值，而负理想解为最大值0.691；对于`distance2population`决策准则值则越大越好，因此正理想解为0.547，而负理想解为0.469。


```python
pis_nis=usda_weight.PIS_NIS(standardized_evaluation_criteria_df,pis={'slope':0,'distance2water':0,'elevation':0,'distance2population':1})  
pis_nis
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>slope</th>
      <th>distance2water</th>
      <th>elevation</th>
      <th>distance2population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>V+</th>
      <td>0.311086</td>
      <td>0.357314</td>
      <td>0.348623</td>
      <td>0.547862</td>
    </tr>
    <tr>
      <th>V-</th>
      <td>0.691301</td>
      <td>0.625299</td>
      <td>0.641016</td>
      <td>0.469596</td>
    </tr>
  </tbody>
</table>
</div>



进而，计算各备选方案到正负理想解的距离（$S_i^{+}$和$S_i^{-}$），公式为：$\begin{aligned} & S_i^{+}=\left[\sum_{j=1}^n w_j^p \cdot\left(\left|v_{i j}-v_{i j}^{+}\right|\right)^p\right]^{\frac{1}{p}} \\ & S_i^{-}=\left[\sum_{j=1}^n w_j^p \cdot\left(\left|v_{i j}-v_{i j}^{-}\right|\right)^p\right]^{\frac{1}{p}}\end{aligned}$，式中，$ w_j$为前文计算的决策准则信息熵权重值，$p$本次实验配置值为2，为欧氏距离度量。

最后，计算各备选方案的排序指标值（即综合评价指数）$C_i^{+}$，为到正理想解的相对接近度（ relative closeness），公式为： $C_i^{+}=\frac{S_i^{-}}{S_i^{+}+S_i^{-}}$。

定义`closeness_pis_nis()`方法实现TOPSIS算法，包括决策矩阵标准化、确定正负理想解及距离计算和综合评价指数计算过程。计算结果显示，备选方案2为最优解，是最适合的选择区域。


```python
separation_measure_df=usda_weight.closeness_pis_nis(standardized_evaluation_criteria_df,pis={'slope':0,'distance2water':0,'elevation':0,'distance2population':1},Wj=entropy_weight_df['Wj'])
separation_measure_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Si+</th>
      <th>Si-</th>
      <th>Ci+</th>
      <th>Rank</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.075341</td>
      <td>0.190395</td>
      <td>0.716481</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.189103</td>
      <td>0.075979</td>
      <td>0.286626</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.054371</td>
      <td>0.179345</td>
      <td>0.767362</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.134021</td>
      <td>0.089482</td>
      <td>0.400361</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>



### 3.1.1.2 污染气体浓度数据测量点污染浓度综合指数评估

使用“2.7.1 城市环境传感器AoT（SAGE）数据预处理” 一章中处理后的数据，就污染气体（CO, H2S, NO2, O3, SO2, oxidizing_gases和reducing_gases）浓度值评估不同测量点位污染的综合指数，最优解的测量点位应该是各类污染气体浓度值相对最低的区域。

参数管理使用`AttrDict()方法`（具体查看“Cityscapes数据集——参数管理”一节），将该方法写入到`USDA`库中，方便调用。


```python
__C=usda_utils.AttrDict() 
args=__C

__C.db=usda_utils.AttrDict() 
__C.db.UN='postgres'
__C.db.PW='123456'
__C.db.DB='AoT_20220831'
__C.db.GC='geometry' 
__C.db.db_info=dict(geom_col=args.db.GC,myusername=args.db.UN,mypassword=args.db.PW,mydatabase=args.db.DB)
```


```python
gas_concentration_gdf=postSQL2gpd(table_name="concentration",**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is concentration.
    


```python
gas_concentration_gdf.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp</th>
      <th>node_id</th>
      <th>subsystem</th>
      <th>sensor</th>
      <th>parameter</th>
      <th>value_hrf_sum</th>
      <th>value_hrf_count</th>
      <th>value_hrf_average</th>
      <th>value_hrf_min</th>
      <th>value_hrf_max</th>
      <th>project_id</th>
      <th>vsn</th>
      <th>address</th>
      <th>lat</th>
      <th>lon</th>
      <th>description</th>
      <th>start_timestamp</th>
      <th>end_timestamp</th>
      <th>geometry</th>
      <th>ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020/01/01 00:30:00</td>
      <td>001e0610ee43</td>
      <td>chemsense</td>
      <td>co</td>
      <td>concentration</td>
      <td>6.383</td>
      <td>77</td>
      <td>0.083</td>
      <td>0.001</td>
      <td>0.281</td>
      <td>AoT_Chicago</td>
      <td>08B</td>
      <td>UChicago Chicago IL</td>
      <td>41.788608</td>
      <td>-87.598713</td>
      <td>AoT Chicago (S) [C] {UChicago}</td>
      <td>2018/02/23 00:00:00</td>
      <td>None</td>
      <td>POINT (450252.141 4626479.257)</td>
      <td>2020-01-01 00:30:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020/01/01 00:30:00</td>
      <td>001e061183f5</td>
      <td>chemsense</td>
      <td>co</td>
      <td>concentration</td>
      <td>7.711</td>
      <td>53</td>
      <td>0.145</td>
      <td>0.009</td>
      <td>0.457</td>
      <td>AoT_Chicago</td>
      <td>0BF</td>
      <td>111th &amp; Michigan Ave Chicago IL</td>
      <td>41.692703</td>
      <td>-87.621020</td>
      <td>AoT Chicago (S) [CP]</td>
      <td>2019/06/24 00:00:00</td>
      <td>None</td>
      <td>POINT (448321.777 4615844.593)</td>
      <td>2020-01-01 00:30:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020/01/01 00:30:00</td>
      <td>001e061183f5</td>
      <td>chemsense</td>
      <td>h2s</td>
      <td>concentration</td>
      <td>223.790</td>
      <td>143</td>
      <td>1.565</td>
      <td>1.244</td>
      <td>1.929</td>
      <td>AoT_Chicago</td>
      <td>0BF</td>
      <td>111th &amp; Michigan Ave Chicago IL</td>
      <td>41.692703</td>
      <td>-87.621020</td>
      <td>AoT Chicago (S) [CP]</td>
      <td>2019/06/24 00:00:00</td>
      <td>None</td>
      <td>POINT (448321.777 4615844.593)</td>
      <td>2020-01-01 00:30:00</td>
    </tr>
  </tbody>
</table>
</div>



计算读取的`gas_concentration_gdf`时间序列数据为各个测量点位各类污染气体的年均值，以各类气体污染浓度为决策准则，以测量点位（`node_id`）为备选方案。


```python
gas_grouped=gas_concentration_gdf.groupby(['node_id','sensor']).agg({'value_hrf_average':'mean','geometry':'first'})
gas_grouuped_val=gas_grouped['value_hrf_average'].unstack(level=1)
gas_grouuped_val.dropna(axis=0,how='any',inplace=True)

gas_grouped_geometry=gas_grouped['geometry']
gas_grouped_geometry_series=gas_grouped_geometry[~gas_grouped_geometry.index.get_level_values(0).duplicated(keep='last')].droplevel(level=1)

gas_concentration_grouuped_gdf=gas_grouuped_val.join(gas_grouped_geometry_series).set_geometry('geometry',crs=gas_concentration_gdf.crs)
print(gas_concentration_grouuped_gdf.shape)
gas_concentration_grouuped_gdf.head(3)
```

    (17, 8)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>co</th>
      <th>h2s</th>
      <th>no2</th>
      <th>o3</th>
      <th>oxidizing_gases</th>
      <th>reducing_gases</th>
      <th>so2</th>
      <th>geometry</th>
    </tr>
    <tr>
      <th>node_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>001e0610ee43</th>
      <td>0.100156</td>
      <td>0.016942</td>
      <td>0.005921</td>
      <td>0.002911</td>
      <td>0.100419</td>
      <td>0.023512</td>
      <td>0.155692</td>
      <td>POINT (450252.141 4626479.257)</td>
    </tr>
    <tr>
      <th>001e06113107</th>
      <td>1.381645</td>
      <td>0.042800</td>
      <td>0.005717</td>
      <td>0.002976</td>
      <td>0.715194</td>
      <td>0.088307</td>
      <td>0.304424</td>
      <td>POINT (440722.179 4622392.015)</td>
    </tr>
    <tr>
      <th>001e06117b41</th>
      <td>0.191377</td>
      <td>0.349793</td>
      <td>0.014280</td>
      <td>0.004547</td>
      <td>1.306005</td>
      <td>0.419687</td>
      <td>0.547236</td>
      <td>POINT (448297.079 4626171.925)</td>
    </tr>
  </tbody>
</table>
</div>



读取芝加哥城的行政区划数据，方便测量单位分布位置的查看。


```python
chicago_community_areas=postSQL2gpd(table_name='chicago_community_areas',**args.db.db_info)  
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is chicago_community_areas.
    

应用上述定义的熵值权重法和TOPSIS算法，计算污染气体浓度下的MCDM问题。从计算结果来看，测量点位`001e0611856d`为最优方案，各类气体污染浓度相对较小。


```python
entropy_weight_gas_grouuped_val=usda_weight.entropy_weight(gas_grouuped_val)
standardized_evaluation_criteria_gas_grouuped_val=usda_weight.df_standardized_evaluation(gas_grouuped_val)
pis={col:0 for col in gas_grouuped_val.columns}
separation_measure_gas_grouuped=usda_weight.closeness_pis_nis(standardized_evaluation_criteria_gas_grouuped_val,pis=pis,Wj=entropy_weight_gas_grouuped_val['Wj'])
separation_measure_gas_grouuped['node_id']=gas_grouuped_val.index
separation_measure_gas_grouuped
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Si+</th>
      <th>Si-</th>
      <th>Ci+</th>
      <th>Rank</th>
      <th>node_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.003842</td>
      <td>0.426265</td>
      <td>0.991068</td>
      <td>2.0</td>
      <td>001e0610ee43</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.009027</td>
      <td>0.420979</td>
      <td>0.979008</td>
      <td>4.0</td>
      <td>001e06113107</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.025925</td>
      <td>0.415602</td>
      <td>0.941282</td>
      <td>14.0</td>
      <td>001e06117b41</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.016292</td>
      <td>0.415278</td>
      <td>0.962251</td>
      <td>11.0</td>
      <td>001e06117b44</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.008117</td>
      <td>0.421103</td>
      <td>0.981090</td>
      <td>3.0</td>
      <td>001e0611804d</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.020310</td>
      <td>0.416891</td>
      <td>0.953546</td>
      <td>13.0</td>
      <td>001e06118182</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.012700</td>
      <td>0.424827</td>
      <td>0.970974</td>
      <td>8.0</td>
      <td>001e06118295</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.012010</td>
      <td>0.420971</td>
      <td>0.972261</td>
      <td>7.0</td>
      <td>001e061182a2</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.016872</td>
      <td>0.421351</td>
      <td>0.961500</td>
      <td>12.0</td>
      <td>001e061182a7</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.009138</td>
      <td>0.424579</td>
      <td>0.978931</td>
      <td>5.0</td>
      <td>001e061183bf</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.038781</td>
      <td>0.407858</td>
      <td>0.913172</td>
      <td>15.0</td>
      <td>001e061183f3</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.316724</td>
      <td>0.272641</td>
      <td>0.462601</td>
      <td>17.0</td>
      <td>001e061183f5</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.014791</td>
      <td>0.424615</td>
      <td>0.966340</td>
      <td>9.0</td>
      <td>001e06118433</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.296861</td>
      <td>0.279669</td>
      <td>0.485090</td>
      <td>16.0</td>
      <td>001e061184a3</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.014759</td>
      <td>0.422157</td>
      <td>0.966221</td>
      <td>10.0</td>
      <td>001e06118501</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.011269</td>
      <td>0.422414</td>
      <td>0.974015</td>
      <td>6.0</td>
      <td>001e0611850f</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.002697</td>
      <td>0.425934</td>
      <td>0.993708</td>
      <td>1.0</td>
      <td>001e0611856d</td>
    </tr>
  </tbody>
</table>
</div>



打印测量点位，并标识污染浓度综合指数（距理想解的排序）。


```python
fig, ax=plt.subplots(figsize=(7,15))
chicago_community_areas.plot(ax=ax,color='white', edgecolor='gray')
gas_concentration_grouuped_gdf.plot(ax=ax,markersize=30,legend=True,legend_kwds={'loc': 'lower left'},c='r')

for x, y, label in zip(gas_concentration_grouuped_gdf.geometry.x, gas_concentration_grouuped_gdf.geometry.y,separation_measure_gas_grouuped.Rank.astype(int)):
    ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords="offset points",fontsize=7)

ax.axis('off')
plt.show()
```


<img src="./imgs/3_1/output_26_0.png" height='auto' width='auto' title="caDesign">    
    


为了查看第1排名（最优方案）和最后排名测量点的场地环境情况，可以下载街道全景图（Street View panorama），一种方式是从[Google Developers Console_Street View Static API](https://console.cloud.google.com/apis/dashboard?pli=1&project=gsv-streetscape)<sup>④</sup> 支付下载；或者从[istreetview](https://istreetview.com/)<sup>⑤</sup>通过节点坐标获取全景图索引（PanoID），然后用[Street View Download 360](https://svd360.istreetview.com/)<sup>⑥</sup>辅助工具下载。将下载的等量矩形投影图转换为球面全景图查看，使用[mayavi](https://docs.enthought.com/mayavi/mayavi/)<sup>⑦</sup>库定义`sphere_panorama_label()`方法实现。

在进一步的分析中，可以结合土地利用、土地覆盖数据，全景图语义分割后视域指标（绿视率等）、分析与测量点位污染浓度综合指数的关系。


```python
pano_1_fn='../data/panorama_AoT/001e0611856d.jpg'
# pano_17_fn='../data/panorama_AoT/001e061183f5.jpg'
usda_vis.sphere_panorama_label(pano_17_fn)
```

<img src="./imgs/3_1/3_1_01_s.gif" height='auto' width=500 title="caDesign"><img src="./imgs/3_1/3_1_02_s.gif" height='auto' width=500 title="caDesign">

## 3.1.2 MCDM算法集成

Valdecy Pereira在构建`pyDecision`Python工具包时，对MCDM众多算法均给出了[Colab Demo](https://github.com/Valdecy/pyDecision)<sup>⑧</sup>代码操作案例，方便快速的学习和应用对应算法于实际的实验研究中；同时给出了算法的出处（研究论文），方便查看和理解具体算法的计算过程。下表引入了各类算法的名称，参考论文及输入条件等信息，方便查阅：


| 序号  | 算法名  | 参考论文  | 输入条件 |备注   |
|---|---|---|---|---|
|  1 |AHP（Analytic Hierarchy Process），层次分析法   |How to make a decision: The Analytic Hierarchy Process<sup>[10]</sup>   |  判断矩阵 ||
|  2 |F-AHP （Fuzzy analytic hierarchy process） ，模糊层次分析法  | A fuzzy AHP approach for supplier selection problem: a case study in a gearmotor company  <sup>[11]</sup>  | 判断矩阵（模糊数）  |   |
|  3 | ARAS （Additive Ratio Assessment ）  | A new additive ratio assessment (ARAS) method in multicriteria decision‐making<sup>[12]</sup>  | 1.准则权重</br>2.准则类型</br>3.决策矩阵  | |
|  4 |  Borda | Mémoire sur les élections au scrutin *（投票选举简介）<sup>[13]</sup>  | 1.准则类型</br>2.判断矩阵 |   |
|  5 |  BWM（Best-worst multi-criteria decision-making method），最优最劣法 |  Best-worst multi-criteria decision-making method<sup>[2]</sup> |1.最佳准则比较向量</br>2.最差准则比较向量  |   |
|  6 | CODAS （Combinative distance-based assessment），基于组合距离评估 | A new combinative distance-based assessment (codas) method for multi-criteria decision-making<sup>[14]</sup>| 1.准则权重</br>2.准则类型</br>3.决策矩阵  |   |
|  7 |  COPRAS（COmplex PRoportional ASsessment），复杂比例评估 | A complex proportional assessment method for group decision making in an interval-valued intuitionistic fuzzy environment<sup>[15]</sup>  |   1.准则权重</br>2.准则类型</br>3.决策矩阵 |   |
|  8 | CRITIC（CRiteria Importance Through Intercriteria Correlation），基于准则间相关性权重法  | Determining objective weights in multiple criteria problems: the critic method <sup>[16]</sup> |  1.准则类型</br>2.决策矩阵   |   |
|  9 | DEMATEL（Decision making trial and evaluation laboratory），决策实验室法   | DEMATEL Technique: A Systematic Review of the State-of-the-Art Literature on Methodologies and Applications<sup>[17]</sup>  |  判断（关系）矩阵|   |
|  10 | Fuzzy DEMATEL （Fuzzy-based Decision making trial and evaluation laboratory）, 模糊决策实验室法 |  Developing global managers’ competencies using the fuzzy DEMATEL method<sup>[18]</sup> | 判断（关系）矩阵（模糊数）  |   |
|  11 |  EDAS （Distance from Average Solution） |  Multi-Criteria Inventory Classification Using a New Method of Evaluation Based on Distance from Average Solution (EDAS)<sup>[19]</sup> |  1.准则权重</br>2.准则类型</br>3.决策矩阵   |   |
| 12  |  Fuzzy EDAS（Fuzzy-based distance from average solution ） | Fuzzy-EDAS (Evaluation Based on Distance from Average Solution) for Material Selection Problems<sup>[20]</sup>  | 1.准则权重（模糊数）</br>2.准则类型</br>3.决策矩阵（模糊数）   |   |
| 13  | ELECTRE I  |  Classement et choix en presence de points de vue multiples<sup>[21]</sup> |  1. 满意度（一致）阈值$\hat{c} $</br>2. 不满意度（不一致）阈值$\hat{d}$ </br>3.准则权重</br>4.决策矩阵  |   |
| 14  |  ELECTRE I_s |The Electre Methodology <sup>[22]</sup>  |  1. $Q,P,V$向量系数</br>2.准则权重 </br>3.决策矩阵  |   |
| 15  | ELECTRE I_v   | ''  |  1. 满意度（一致）阈值$\hat{c}$</br>2. 不满意度（不一致）阈值$\hat{d}$</br>3.不满意度比较向量  </br>4.准则权重</br>5.决策矩阵  |   |
| 16  |  ELECTRE II |  '' |  1. 满意度（一致）阈值$c^-,c,c^+ $</br>2. 不满意度（不一致）阈值$d^-,d^+$ </br>3.准则权重</br>4.决策矩阵   |   |
| 17  |  ELECTRE III | Un algorithme de classemeuts fonde sur une representation floue des preferences en presence de cr1teres multiples<sup>[23]</sup>  |  1. $Q,P,V$向量系数</br>2.准则权重 </br>3.决策矩阵   |   |
| 18  | ELECTRE IV  | The Electre Methodology <sup>[22]</sup>  | 1. $Q,P,V$向量系数 </br>2.决策矩阵    |   |
| 19  |  ELECTRE Tri-B | Aide multicritère à la décision dans le cadre de la problématique du tri Concepts, méthodes et applications <sup>[24] </sup>  |   1. $Q,P,V,B$向量系数</br>2.准则权重 </br>3.决策矩阵 |   |
| 20  | GRA （Grey Relation Analysis)），灰色关联度分析 | Control problems of grey systems<sup>[25]</sup>    | 1.准则权重</br>2.准则类型</br>3.决策矩阵|   |
|  21 |  IDOCRIW （Integrated Determination of Objective CRIteria Weights） | New Methods and Applications in Multiple Attribute Decision Making (MADM) <sup>[26]</sup>  |   1.准则类型</br>2.决策矩阵  |   |
|  22 |  MABAC （Multi-Attributive Border Approximation area Comparison）， 多属性边界近似区域比较 |  The selection of transport and handling resources in logistics centers using Multi-Attributive Border Approximation area Comparison (MABAC)<sup>[27]</sup>  |  1.准则类型</br>2.决策矩阵   |   |
| 23  | MAUT （Multi-attribute utility theory），多属性效用理论 |Multi-attribute utility theory: models and assessment procedures<sup>[28]</sup>   |  1.准则权重</br>2.准则类型</br>3. 效用参数</br>4.决策矩阵   |   |
| 24  |  MOORA | The MOORA method and its application to privatization in a transition economy<sup>[29]</sup>   | 1.准则权重</br>2.准则类型</br>3.决策矩阵 |    |
| 25  | MOOSRA （ Multi-objective optimisation on the basis of simple ratio analysis），基于简单比率分析的多目标优化 |  Green cutting fluid selection using moosra method<sup>[30]</sup> |  1.准则权重</br>2.准则类型</br>3.决策矩阵 |   |
| 26  |  MULTIMOORA （Multi (Full Multiplicative Form) Multi-Objective Optimiza- tion by Ratio analysis）| Project management by multimooraas an instrument f or transition economies<sup>[31]</sup>  |  1.准则类型</br>2.决策矩阵   |   |
| 27  |  PROMETHEE I  | Promethee methods<sup>[32]</sup>  |   1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$P$）</br>3.决策矩阵 | |   |
| 28  |  PROMETHEE II | ''  |   1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$F$）</br>3.决策矩阵  |   |
| 29  |  PROMETHEE III | PROMETHEE I-II-III Methods<sup>[33]</sup>  |    1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$F$）</br>3.决策矩阵  |   |
|  30 | PROMETHEE IV   |  Promethee methods<sup>[32]</sup> | 1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$F$）</br>3.决策矩阵    |   |
| 31  | PROMETHEE V   | ''  | 1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$F$）</br>4.约束1（所选条件的最大数量）</br>5.约束2（准则成本（cost）和预算（budget））</br>6.约束3（选定条件的禁止集（forbidden））</br>7.决策矩阵   |   |
|  32 |  PROMETHEE VI | ''  |  1. $Q,S,P$向量系数</br>2.准则权重 (区间： 权重低值，权重高值)</br>3. 计算类型（$F$）</br>3.决策矩阵   |   |
| 33  |  PROMETHEE Gaia | ''  |1. $Q,S,P$向量系数</br>2.准则权重 </br>3. 计算类型（$F$）</br>3.决策矩阵   |   |
| 34  | SAW（Simple Additive Weighting ）   |  Simple Additive Weighting (SAW) method in Determining Beneficiaries of Foundation Benefits<sup>[34]</sup>  |   1.准则权重</br>2.准则类型</br>3.决策矩阵  |   |
| 35  |  SMART（Simple Multi-Attribute Rating Technique） | Decision Aids for Selection Problems<sup>[35]</sup>  |  1.得分（4（最差）-10（最好））</br>2.决策阈值（低值向量和高值向量）</br>3.准则类型</br>4.决策矩阵   |   |
| 36  | TOPSIS（Technique for Order Performance by Similarity to Ideal Solution），理想解法  |  A Reconciliation Among Discrete Compromise Solutions<sup>[36]</sup> | 1.准则权重</br>2.准则类型</br>3.决策矩阵    |   |
| 37  | Fuzzy TOPSIS （Fuzzy-based Technique for Order Performance by Similarity to Ideal Solution）模糊理想解法  |Fuzzy TOPSIS: A General View<sup>[37]</sup>   |   1.准则权重（模糊数）</br>2.准则类型</br>3.决策矩阵（模糊数）  |   |
| 38  | VIKOR （ VIseKriterijumska Optimizacija I Kompromisno Resenje ） |  VIseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR)<sup>[38]</sup>  |  1.准则权重</br>2.准则类型</br>3.决策矩阵   |   |
| 39  | Fuzzy VIKOR | Fuzzy VIKOR with an application to water resources planning<sup>[39]</sup> |  1.准则权重（模糊数）</br>2.准则类型</br>3.决策矩阵（模糊数）  |   |
| 40  | WINGS   | Weighted Inﬂuence Non-linear Gauge System (WINGS) – an analysis method for the systems of interrelated components<sup>[40]</sup>  | 判断矩阵（Scale: 0 (No Influence), 1 (Low Influence), 2 (Medium Influence), 3 (High Influence), 4 (Very High Influence)）  |   |
| 41  | WSM, WPM, WASPAS（Weighted Aggregated Sum Product Assessment）  | Weighted Aggregated Sum Product Assessment (WASPAS)<sup>[41]</sup>  | 1.准则权重</br>2.准则类型</br>3.决策矩阵  |   |

为理解相关算法的具体过程，再现 AHP、F-AHP、 ARAS、 BWM、 DEMATEL、IDOCRIW和ELECTRE-I等7种算法。

### 3.1.2.1   再现 AHP 算法

再现Thomas L. Saaty在论文中给出的第一个案例（购房选择问题），阐释AHP算法。为了方便应用 AHP 算法，定义`AHP`类可以方便构建判断矩阵，计算权重矩阵和一致性指数，及总的得分。

对于这个购房选择问题，包括8个决策准则，由变量`criteria`给出；3个备选方案，由变量`alternatives`给出。首先是要构建两类两两比较矩阵（判断矩阵），一个是决策准则对于分析目标的重要性排序，为决策准则之间的两两比较；另一个是对于每一个决策准则，例如对于`size_of_house`而言，3个备选方案比较这一`size_of_house`这一决策准则，哪个备选方案的房子相对会大一些。为了方便和规范比较方式和比较值，作者给出了度量标度，如表：

|标度（Intensity of importance on an absolute scale）   |  定义（Definition）  | 解释（Explanation）  |
|---|---|---|
| 1  |  Equal importance（同样重要性）   |  Two activities contribute equally to the objective  |
| 3  |  Moderate importance of one over another（一个因素比另一个因素稍微重要）   |  Experience and judgment strongly favor one activity over another  |
| 5  | Essential or strong importance（一个因素比另一个因素明显重要）    | Experience and judgement strongly favor one activity over another  |
| 7  |  Very strong importance（一个因素比另一个因素强烈重要） | An activity is strongly favored and its dominance demonstrated in practice   |
| 9  |  Extreme importance（一个因素比另一个因素极端重要） | The evidence favoring one activity over another is of tile highest possible order of affirmation   |
| 2，4，6，8  |Intermediate values between the two adjacent judgments（上述两相邻判断的中值）    |  When compromise is needed  |
| 倒数（Reciprocals）   |   | If activity i has one of the above numbers assigned to it when compared with activity j, then j has the reciprocal value when compared with i （如果因素 i 与因素 j 相比分配了上述数字之一，则 j 与 i 相比为倒数），例如$a_{ij}=3 $，则$a_{ji}=1/3 $  |
| 有理数（Rationals ）  |  Ratios arising from the scale  |  If consistency were to be forced by obtaining n numerical values to span the matrix  |


为了方便判断矩阵的输入，定义了`criteria_pairs_lst()`和`alternative_pairs()`方法生成`criteria_pairs_lst`和`alternative_pairs_lst`类属性，可以查看对于定义的类`AHP`两两比较输入的顺序。输入时为字符串形式输入，是为了应用`fractions`库提供的`Fraction`方法显示为分数形式，而不是浮点数。因为判断矩阵为正互反矩阵（reciprocal matrix），如$A=(a_{ij}),  a_{ij}= w_{i}/ w_{j};i,j=1, \ldots ,n$，有$a_{ij} \times a_{ji}=1$，因此倒数部分可以书写代码自动生成。


```python
criteria=['size_of_house','location_to_bus_line','neighborhood','age_of_house','yard_space','modern_facilities','general_condition','financing_available']
alternatives=['A','B','C']      

choosing_best_house=usda_weight.AHP(criteria,alternatives)  
```


```python
choosing_best_house.criteria_pairs_lst
```




    [('size_of_house', 'location_to_bus_line'),
     ('size_of_house', 'neighborhood'),
     ('size_of_house', 'age_of_house'),
     ('size_of_house', 'yard_space'),
     ('size_of_house', 'modern_facilities'),
     ('size_of_house', 'general_condition'),
     ('size_of_house', 'financing_available'),
     ('location_to_bus_line', 'neighborhood'),
     ('location_to_bus_line', 'age_of_house'),
     ('location_to_bus_line', 'yard_space'),
     ('location_to_bus_line', 'modern_facilities'),
     ('location_to_bus_line', 'general_condition'),
     ('location_to_bus_line', 'financing_available'),
     ('neighborhood', 'age_of_house'),
     ('neighborhood', 'yard_space'),
     ('neighborhood', 'modern_facilities'),
     ('neighborhood', 'general_condition'),
     ('neighborhood', 'financing_available'),
     ('age_of_house', 'yard_space'),
     ('age_of_house', 'modern_facilities'),
     ('age_of_house', 'general_condition'),
     ('age_of_house', 'financing_available'),
     ('yard_space', 'modern_facilities'),
     ('yard_space', 'general_condition'),
     ('yard_space', 'financing_available'),
     ('modern_facilities', 'general_condition'),
     ('modern_facilities', 'financing_available'),
     ('general_condition', 'financing_available')]



按照上述`criteria_pairs_lst`对顺序确定两两比较的标度，通过`pairwise_comparison_matrix()`方法构建决策准则自身之间的比较矩阵，其中参数`alternatives_criteria`为确定生成两类判断矩阵的哪类。


```python
criteria_pairwise_vals=['5','3','7','6','6','1/3','1/4','1/3','5','3','3','1/5','1/7','6','3','4','6','1/5','1/3','1/4','1/7','1/8','1/2','1/5','1/6','1/5','1/6','1/2']
criteria_global_pairwise_comparison_matrix=choosing_best_house.pairwise_comparison_matrix(criteria_pairwise_vals,alternatives_criteria='A')
criteria_global_pairwise_comparison_matrix
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>size_of_house</th>
      <th>location_to_bus_line</th>
      <th>neighborhood</th>
      <th>age_of_house</th>
      <th>yard_space</th>
      <th>modern_facilities</th>
      <th>general_condition</th>
      <th>financing_available</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>size_of_house</th>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>7</td>
      <td>6</td>
      <td>6</td>
      <td>1/3</td>
      <td>1/4</td>
    </tr>
    <tr>
      <th>location_to_bus_line</th>
      <td>1/5</td>
      <td>1</td>
      <td>1/3</td>
      <td>5</td>
      <td>3</td>
      <td>3</td>
      <td>1/5</td>
      <td>1/7</td>
    </tr>
    <tr>
      <th>neighborhood</th>
      <td>1/3</td>
      <td>3</td>
      <td>1</td>
      <td>6</td>
      <td>3</td>
      <td>4</td>
      <td>6</td>
      <td>1/5</td>
    </tr>
    <tr>
      <th>age_of_house</th>
      <td>1/7</td>
      <td>1/5</td>
      <td>1/6</td>
      <td>1</td>
      <td>1/3</td>
      <td>1/4</td>
      <td>1/7</td>
      <td>1/8</td>
    </tr>
    <tr>
      <th>yard_space</th>
      <td>1/6</td>
      <td>1/3</td>
      <td>1/3</td>
      <td>3</td>
      <td>1</td>
      <td>1/2</td>
      <td>1/5</td>
      <td>1/6</td>
    </tr>
    <tr>
      <th>modern_facilities</th>
      <td>1/6</td>
      <td>1/3</td>
      <td>1/4</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>1/5</td>
      <td>1/6</td>
    </tr>
    <tr>
      <th>general_condition</th>
      <td>3</td>
      <td>5</td>
      <td>1/6</td>
      <td>7</td>
      <td>5</td>
      <td>5</td>
      <td>1</td>
      <td>1/2</td>
    </tr>
    <tr>
      <th>financing_available</th>
      <td>4</td>
      <td>7</td>
      <td>5</td>
      <td>8</td>
      <td>6</td>
      <td>6</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



假设一个判断矩阵为：$\begin{aligned} & \begin{array}{llll} \hspace{18pt} A & \hspace{4pt} B &  \hspace{1pt} C\end{array} \\ & \begin{array}{c}A\\ B \\ C\end{array}\left(\begin{array}{cccc}1 & 2  & 1 \\ 1/2 &1&2 & \\1 & 1/2 &1\end{array}\right)  \end{aligned}$，其中$A>B$，且$A=C$，但$B>C$产生了矛盾，因此提出对于一个正互反矩阵如果没有上述矛盾则称之为一致矩阵（consistent matrix），一致矩阵是正互反矩阵的特例。对于一致矩阵有$a_{ij}  \times a_{jk} =a_{ik}(i,j,k=1, \ldots ,n)$，且矩阵各行（各列）之间成倍数关系，例如对于上述假设矩阵$a_{AB}  \times a_{BC}=a_{AC} $，即$2 \times 2=4$。在构造判断矩阵时，难免会出现类似上述的矛盾，因此需要检验构造的判断矩阵和一致矩阵是否有太大差别，只要该矩阵向一致性矩阵靠拢，这个差距参数一致性比例（Consistency Ratio，CR）不高于10%，则可以接受这个权重估计。对于CR公式为：$CR= \frac{CI}{RI} \\ CI= \frac{  \lambda  _{max} - n}{n-1} $，式中，$CI$为一致性指数（Consistency Index）；$RI$为平均随机一致性指标（Random Index），表示大量随机生成的同阶矩阵平均CI，视为RI的预期，因此CR是矩阵的一致性指标与预期的比率。当CR越大，判断矩阵越偏离一致矩阵；反之，值越小则越趋近于一致矩阵<sup>[42]</sup>。对于$RI$可以查表获得，对于1至16阶矩阵，其$RI$对应值为$[0, 0, 0, 0.58, 0.9, 1.12, 1.24, 1.32, 1.41, 1.45, 1.49, 1.51, 1.48, 1.56, 1.57, 1.59]$，可以用于计算决策准则数最多为16个，应用AHP于MCDM问题。对于$\lambda  _{max}$为矩阵最大特征值（principal eigenvalue ），$n$为矩阵的阶（order）。$n$阶一致矩阵，因为各行成比例且不是零矩阵，其秩$r(A)=1$，并当且仅当 $ \lambda _{max}=n $ ，因此定义CI为$ ( \lambda _{max}-n ) / ( n - 1)$，即判断矩阵越不一致时，最大特征值$\lambda _{max}$与$n$的差距就越大。

权重值的计算包括算术平均法求权重和几何平均法求权重，有`weight()`方法的`wd`参数判断。假设判断矩阵为$A=\left[\begin{array}{cccc}a_{11} & \mathrm{a}_{12} & \cdots & \mathrm{a}_{1 \mathrm{n}} \\ \mathrm{a}_{21} & \mathrm{a}_{22} & \cdots & \mathrm{a}_{2 \mathrm{n}} \\ \vdots & \vdots & \ddots & \vdots \\ \mathrm{a}_{\mathrm{n} 1} & \mathrm{a}_{\mathrm{n} 2} & \cdots & \mathrm{a}_{\mathrm{nn}}\end{array}\right]$，算术平均法求权重的公式为：$\omega_{\mathrm{i}}=\frac{1}{\mathrm{n}} \sum_{\mathrm{j}=1}^{\mathrm{n}} \frac{\mathrm{a}_{\mathrm{ij}}}{\sum_{\mathrm{k}=1}^{\mathrm{n}} \mathrm{a}_{\mathrm{kj}}},(\mathrm{i}=1,2, \cdots, \mathrm{n})$，即判断矩阵按列归一化（每个元素除以其所在列的和）后，按行求和，并除以矩阵的阶$n$；几何平均法求权重公式为：$\omega_{\mathrm{i}}=\frac{\left(\prod_{\mathrm{j}=1}^{\mathrm{n}} \mathrm{a}_{\mathrm{ij}}\right)^{\frac{1}{\mathrm{n}}}}{\sum_{\mathrm{k}=1}^{\mathrm{n}}\left(\prod_{\mathrm{j}=1}^{\mathrm{n}} \mathrm{a}_{\mathrm{kj}}\right)^{\frac{1}{\mathrm{n}}}},(\mathrm{i}=1,2, \cdots, \mathrm{n})$，即将矩阵按行相乘得到一个新的列向量后开$n$次方，并进行归一化得到权重值。

迁移`pyDecision`库中`ahp`方法为`USDA`库类`AHP`中的函数，直接调用该方法计算权重和CI值及CR值，返回值仅包含CR值。计算结果如下，CR值约为0.163，作者给出的结果为0.169，实际超出了0.1的阈值界限。


```python
gp_weight,gp_cr=choosing_best_house.weight(criteria_global_pairwise_comparison_matrix)
print(gp_weight,'\n',gp_cr)
```

    [0.1743749238483884 0.06608449083968755 0.17015215186835408 0.01889929722237991 0.0352504763592837 0.04445701659354435 0.1784887930700104 0.3122928501983515] 
     0.16395000832304404
    

同样的方法批量构建每一决策准则不同备选方案的判断矩阵，并计算权重值和CI值。


```python
choosing_best_house.alternative_pairs_lst
```




    [('A', 'B'), ('A', 'C'), ('B', 'C')]




```python
local_pairwise_vals_dict=dict(size_of_house=['6','8','4'], 
                              location_to_bus_line=['7','1/5','1/8'], 
                              neighborhood=['8','6','1/4'],	
                              age_of_house=['1','1','1'],	
                              yard_space=['5','4','1/3'],	
                              modern_facilities=['8','6','1/5'],	
                              general_condition=['1/2','1/2','1'],	
                              financing_available=['1/7','1/5','3'])
local_pairwise_matrix_dict={}
for k,v in local_pairwise_vals_dict.items():
    local_pairwise_matrix_dict[k]=choosing_best_house.pairwise_comparison_matrix(v,alternatives_criteria='C')
local_pairwise_matrix_dict
```




    {'size_of_house':      A    B  C
     A    1    6  8
     B  1/6    1  4
     C  1/8  1/4  1,
     'location_to_bus_line':      A  B    C
     A    1  7  1/5
     B  1/7  1  1/8
     C    5  8    1,
     'neighborhood':      A  B    C
     A    1  8    6
     B  1/8  1  1/4
     C  1/6  4    1,
     'age_of_house':    A  B  C
     A  1  1  1
     B  1  1  1
     C  1  1  1,
     'yard_space':      A  B    C
     A    1  5    4
     B  1/5  1  1/3
     C  1/4  3    1,
     'modern_facilities':      A  B    C
     A    1  8    6
     B  1/8  1  1/5
     C  1/6  5    1,
     'general_condition':    A    B    C
     A  1  1/2  1/2
     B  2    1    1
     C  2    1    1,
     'financing_available':    A    B    C
     A  1  1/7  1/5
     B  7    1    3
     C  5  1/3    1}




```python
local_weight_rc_dict={}
for k,v in local_pairwise_matrix_dict.items():
    local_weight_rc_dict[k]={k:v for k,v in zip(['weight','rc'],choosing_best_house.weight(v))}
    
local_weight_rc_dict    
```




    {'size_of_house': {'weight': array([0.7390547902227547, 0.19155186674652747, 0.06939334303071788], dtype=object),
      'rc': 0.12062025335167682},
     'location_to_bus_line': {'weight': array([0.25041136463361124, 0.06003181219833261, 0.6895568231680563], dtype=object),
      'rc': 0.2220676402473212},
     'neighborhood': {'weight': array([0.7390547902227547, 0.06939334303071788, 0.19155186674652747], dtype=object),
      'rc': 0.12062025335167682},
     'age_of_house': {'weight': array([0.3333333333333333, 0.3333333333333333, 0.3333333333333333], dtype=object),
      'rc': 0.0},
     'yard_space': {'weight': array([0.6650702426564495, 0.10384738186462324, 0.2310823754789272], dtype=object),
      'rc': 0.07495638655172662},
     'modern_facilities': {'weight': array([0.7263184843830004, 0.0653268475849121, 0.20835466803208738], dtype=object),
      'rc': 0.17731739051985576},
     'general_condition': {'weight': array([0.20000000000000004, 0.4000000000000001, 0.4000000000000001], dtype=object),
      'rc': 0.0},
     'financing_available': {'weight': array([0.07377210603017055, 0.6433888691953209, 0.2828390247745087], dtype=object),
      'rc': 0.056475713035283204}}



最后建立`weight_matrix()`方法汇总决策准则之间和各准则对备选方案之间的权重值，并计算最后基于决策准则的备选方案得分`global_priority`。从计算结果得知，备选方案A得分最高，为购房选择问题的最优答案。


```python
weight_A=choosing_best_house.weight_matrix(gp_weight,local_weight_rc_dict)
weight_A
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>size_of_house</th>
      <th>location_to_bus_line</th>
      <th>neighborhood</th>
      <th>age_of_house</th>
      <th>yard_space</th>
      <th>modern_facilities</th>
      <th>general_condition</th>
      <th>financing_available</th>
      <th>global_priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Wj</th>
      <td>0.174375</td>
      <td>0.066084</td>
      <td>0.170152</td>
      <td>0.018899</td>
      <td>0.03525</td>
      <td>0.044457</td>
      <td>0.178489</td>
      <td>0.312293</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>A</th>
      <td>0.739055</td>
      <td>0.250411</td>
      <td>0.739055</td>
      <td>0.333333</td>
      <td>0.66507</td>
      <td>0.726318</td>
      <td>0.2</td>
      <td>0.073772</td>
      <td>0.391943</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.191552</td>
      <td>0.060032</td>
      <td>0.069393</td>
      <td>0.333333</td>
      <td>0.103847</td>
      <td>0.065327</td>
      <td>0.4</td>
      <td>0.643389</td>
      <td>0.334362</td>
    </tr>
    <tr>
      <th>C</th>
      <td>0.069393</td>
      <td>0.689557</td>
      <td>0.191552</td>
      <td>0.333333</td>
      <td>0.231082</td>
      <td>0.208355</td>
      <td>0.4</td>
      <td>0.282839</td>
      <td>0.273695</td>
    </tr>
  </tbody>
</table>
</div>



### 3.1.2.2   再现 F-AHP 算法

再现Ayhan, M. B.在论文中给出的案例（最佳供应商选择问题），阐释F-AHP算法。为了方便应用 F-AHP 算法，定义`F_AHP`类可以方便构建判断矩阵，计算权重矩阵和一致性指数，及总的得分。

对于这个最佳供应商选择问题，包括5个决策准则，由变量criteria给出；3个备选方案，由变量alternatives给出。F-AHP 方法与 AHP 最大的差异是判断矩阵的构建使用的是三角模糊数（triangular fuzzy number，TFN）。对 TFN 的理解可以从对论域、模糊集、隶属函数等概念的理解引入。论域是论题所包括同类事物的非空总和，是将讨论的对象限制在一定范围内，用$U$表示。模糊集合是用来表达模糊性概念的集合，又称为模糊集（或模糊子集）。对于普通集合$A$，元素$x$ 要么属于集合$A$，要么不属于，表达为：$ \mu _{A}(X)= \begin{cases}1 & x  \in  A\\0 & x  \notin A\end{cases} $；对于模糊集合$ \widetilde{A} $，在论域$U$内，对任意$x \in U$，$x$常以某个程度，例如$\mu ( \mu  \in [0,1])$属于$ \widetilde{A} $，而非$x \in  \widetilde{A} $或$x \notin  \widetilde{A} $。全体模糊集用$F(U)$表示。设论域$U$，如果存在$ \mu _{A} (x):U \rightarrow [0,1]$，则称$ \mu _{A} (x)$为$x(x \in A)$的隶属度，从而一般称$ \mu _{A} (x)$为$ \widetilde{A} $的隶属函数。论域$U$中元素$x$与$ \widetilde{A} $的关系由隶属度$ \mu _{A} (x)$给出，不是简单的二值，属于或不属于的关系，而是多大程度上属于；$U$上所有模糊子集的集合称为模糊幂集，记作$F(U)$。例如对于空气质量指数（Air quality index，AQI），如果值小于50被认为健康，而高于150则为不健康，在好与不好之间包括有一个断点值为100划分为2个分段，如果位于50和100则为适中，位于100和150为对敏感人群不健康，AQI的隶属函数为：$u_A(x)= \begin{cases}0, & x<50 \\ 2\left(\frac{x-50}{100}\right)^2, & 50 \leq x<100\\ 1-2\left(\frac{x-150}{100}\right)^2, & 100 \leq x<150\\ 1, & 150 \leq x\end{cases}$，取AQI值分别为60、100和125，则$ \mu _{A} (x)$分别等于0.02、0.5和0.875，表明对于AQI值为60、100和125分别以0.02、0.5和0.875程度属于不健康空气。该例中的论域$U$是AQI，$A$是不健康空气对应的模糊集。

对于任意一个模糊集，都对应一个隶属函数，确定隶属函数通常参考概率论中的分布函数，称为模糊分布函数，例如正态分布、梯形分布、K次抛物线分布、柯西（Cauchy）分布和S型函数（sigmoid function）分布等。这些函数论域为实数，带有参数，值域为[0,1]。在AHP中，两两比较判断矩阵通常没有考虑人的判断模糊性，仅为隶属于给定的标度，因此引入模糊数，使用TFN形式的三值判断（三角模糊数），最低可能值（smallest possible value，记作$l$）、最可能值（most promising value，记作$m$）和最高可能值（largest possible value ，记作$u$）。当$l=m=u$时，为一个非模糊数。每个 TFN 在其左侧和右侧都有线性表示，因此其隶属函数可以定义为<sup>[43]</sup>：$ \mu (x \mid \tilde{M})= \begin{cases}0, & x<l, \\ (x-l) /(m-l), & l \leqslant x \leqslant m \\ (u-x) /(u-m), & m \leqslant x \leqslant u \\ 0, & x>u .\end{cases}$，一个模糊数总是可以由其对应的每个隶属度的左右表示给出：$\begin{aligned} \tilde{M} & =\left(M^{l(y)}, M^{r(y)}\right) \\ & =(l+(m-l) y, u+(m-u) y), \quad y \in[0,1]\end{aligned}$，式中，$l(y)$和$r(y)$分别表示模糊数的左侧表示和右侧表示。对于TFN的模糊集$\tilde{M} $，如图<sup>[43]</sup>表示：

<img src="./imgs/3_1/3_1_03.png" height='auto' width=500 title="caDesign">

从上图可知，当$x=m$时，$x$完全属于$\tilde{M} $，$l$和$u$分别为下界和上界。在$l$和$u$以外的完全不属于模糊数$\tilde{M} $。

判断矩阵中为了考虑人的模糊性，使用TFN，作者同样给出了度量标度，如表：

| Saaty scale（标度）  | Definition （定义） | Fuzzy Triangular Scale  （TFN） |
|---|---|---|
| 1  |   Equally important (Eq. Imp.) （同等重要） | (1, 1, 1)   |
| 3  | Weakly important (W. Imp.)  （稍微重要） | (2, 3, 4)   |
| 5  |  Fairly important (F. Imp.) （重要）  |   (4, 5, 6)  |
| 7  | Strongly important (S. Imp.) （明显重要）  |   (6, 7, 8)  |
| 9  | Absolutely important (A. Imp.)  （非常重要） |  (9, 9, 9)  |
| 2  | The intermittent values between two adjacent scales  （中间重要性） | (1, 2, 3)   |
| 4  | "  | (3, 4, 5)   |
| 5  | "  | (5, 6, 7)   |
| 6  |  " |  (7, 8, 9)  |

第1步，定义决策准则之间的判断矩阵。基于TFN的判断矩阵可以表达为：$\widetilde{A}^k=\left[\begin{array}{cccc}\widetilde{d}_{11}^k & \tilde{d}_{12}^k & \ldots & \widetilde{d}_{1 n}^k \\ \widetilde{d}_{21}^k & \ldots & \ldots & \widetilde{d}_{2 n}^k \\ \ldots & \ldots &  \ddots  & \ldots \\ \widetilde{d}_{n 1}^k & \tilde{d}_{n 2}^k & \ldots & \tilde{d}_{n n}^k\end{array}\right]$，式中，$\widetilde{ d^{k}_{ij} } $表示为第$k^{th} $决策者对第$i^{th} $对$j^{th} $决策准则的判断，并对各个决策者的判断取均值，为：$\tilde{d}_{i j}=\frac{\sum_{k=1}^K \widetilde{d}_{i j}^k}{K}$，得$\tilde{A}=\left[\begin{array}{ccc}\widetilde{d_{11}} & \cdots & \widetilde{d_{1 n}} \\ \vdots & \ddots & \vdots \\ \widetilde{d_{n 1}} & \cdots & \widetilde{d_{n n}}\end{array}\right]$。

定义`pairwise_comparison_TFN_matrix()`方法实现基于TFN判断矩阵的构建。


```python
criteria=['quality','origin','cost','delivery','after_sales']
alternatives=['A1','A2','A3']      

best_supplier=usda_weight.F_AHP(criteria,alternatives)
```


```python
best_supplier.criteria_pairs_lst
```




    [('quality', 'origin'),
     ('quality', 'cost'),
     ('quality', 'delivery'),
     ('quality', 'after_sales'),
     ('origin', 'cost'),
     ('origin', 'delivery'),
     ('origin', 'after_sales'),
     ('cost', 'delivery'),
     ('cost', 'after_sales'),
     ('delivery', 'after_sales')]




```python
criteria_pairwise_TFN=[('1','1','1'),('4','5','6'),('6','7','8'),('4','5','6'),('4','5','6'),('6','7','8'),('6','7','8'),('1/4','1/3','1/2'),('2','3','4'),('1/6','1/5','1/4')]
criteria_pairwise_comparison_TFN_matrix=best_supplier.pairwise_comparison_TFN_matrix(criteria_pairwise_TFN,alternatives_criteria='C')
criteria_pairwise_comparison_TFN_matrix
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>quality</th>
      <th>origin</th>
      <th>cost</th>
      <th>delivery</th>
      <th>after_sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>quality</th>
      <td>(1, 1, 1)</td>
      <td>(1, 1, 1)</td>
      <td>(4, 5, 6)</td>
      <td>(6, 7, 8)</td>
      <td>(4, 5, 6)</td>
    </tr>
    <tr>
      <th>origin</th>
      <td>(1, 1, 1)</td>
      <td>(1, 1, 1)</td>
      <td>(4, 5, 6)</td>
      <td>(6, 7, 8)</td>
      <td>(6, 7, 8)</td>
    </tr>
    <tr>
      <th>cost</th>
      <td>(1/6, 1/5, 1/4)</td>
      <td>(1/6, 1/5, 1/4)</td>
      <td>(1, 1, 1)</td>
      <td>(1/4, 1/3, 1/2)</td>
      <td>(2, 3, 4)</td>
    </tr>
    <tr>
      <th>delivery</th>
      <td>(1/8, 1/7, 1/6)</td>
      <td>(1/8, 1/7, 1/6)</td>
      <td>(2, 3, 4)</td>
      <td>(1, 1, 1)</td>
      <td>(1/6, 1/5, 1/4)</td>
    </tr>
    <tr>
      <th>after_sales</th>
      <td>(1/6, 1/5, 1/4)</td>
      <td>(1/8, 1/7, 1/6)</td>
      <td>(1/4, 1/3, 1/2)</td>
      <td>(4, 5, 6)</td>
      <td>(1, 1, 1)</td>
    </tr>
  </tbody>
</table>
</div>



第2步，计算决策准则之间的权重和一致性比例CR值。采用几何平均法求权重，首先计算每个决策准则模糊判断矩阵的几何平均值，公式为：$\widetilde{r}_i=\left(\prod_{j=1}^n \widetilde{d}_{i j}\right)^{1 / n}, \quad i=1,2, \ldots, n$；进而计算每个$\widetilde{r}_i$的向量和及其-1次幂，并递增排序（reverse）（TFN形式）；计算第$i$个决策准则的模糊权重$ \widetilde{ W_{i} } $，为各$\widetilde{ r_{i} } $之积，公式为：$\begin{aligned} \widetilde{w}_i & =\widetilde{r}_i \otimes\left(\widetilde{r}_1 \oplus \widetilde{r}_2 \oplus \ldots \oplus \widetilde{r}_n\right)^{-1} \\ & =\left(l w_i, m w_i, u w_i\right)\end{aligned}$；将模糊数转换为常规数值，使用Chou 和 Chang 提出的面积中心法去模糊化<sup>[44]</sup>，公式为：$M_i=\frac{l w_i+m w_i+u w_i}{3}$；最后标准化权重，公式为：$N_i=\frac{M_i}{\sum_{i=1}^n M_i}$。

对于F-AHP算法直接迁移`pyDecision`库中`fuzzy_ahp_method`方法为`USDA`库类`F_AHP中`的函数进行计算。


```python
fuzzy_weights, defuzzified_weights, normalized_weights, cr=best_supplier.weight(criteria_pairwise_comparison_TFN_matrix)
print(f_w,'\n', d_w,'\n', n_w,'\n' ,cr)
```

    [(0.30387157227617195, 0.3849442719555282, 0.4827648944504069), (0.3295401422029697, 0.41174038735956564, 0.5113560858232844), (0.051852455454028286, 0.07197841021214509, 0.10262169573734545), (0.04261628425875972, 0.05680430962243532, 0.07596205129037176), (0.05623252420717982, 0.07453262085032564, 0.10262169573734545)] 
     [0.3905269128940357, 0.4175455384619399, 0.07548418713450628, 0.0584608817238556, 0.07779561359828364] 
     [0.3829396778153188, 0.40943338011437996, 0.07401766522882969, 0.057325092005137, 0.07628418483633463] 
     0.25672257239611473
    

第3步，同样的方式计算每一决策准则不同备选方案的模糊判断矩阵，并计算权重值和CI值。因为作者仅给出了`quality`决策准则模糊矩阵，其它准则不同于该文实验参数，因此算法再现结果不同于原文实验。


```python
best_supplier.alternative_pairs_lst
```




    [('A1', 'A2'), ('A1', 'A3'), ('A2', 'A3')]




```python
alternatives_vals_dict=dict(quality=[('1/6','1/5','1/4'),('1/9','1/9','1/9'),('1/4','1/3','1/2')],
                            origin=[('2','3','4'),('6','7','8'),('4','5','6')],
                            cost=[('4','5','6'),('1/6','1/5','1/4'),('1/4','1/3','1/2')],
                            delivery=[('9','9','9'),('6','7','8'),('1/8','1/7','1/7')],
                            after_sales=[('1/8','1/7','1/6'),('1/4','1/3','1/2'),('2','3','4')])
alternatives_matrix_dict={}
for k,v in alternatives_vals_dict.items():
    alternatives_matrix_dict[k]=best_supplier.pairwise_comparison_TFN_matrix(v,alternatives_criteria='A')
alternatives_matrix_dict
```




    {'quality':            A1               A2               A3
     A1  (1, 1, 1)  (1/6, 1/5, 1/4)  (1/9, 1/9, 1/9)
     A2  (4, 5, 6)        (1, 1, 1)  (1/4, 1/3, 1/2)
     A3  (9, 9, 9)        (2, 3, 4)        (1, 1, 1),
     'origin':                  A1               A2         A3
     A1        (1, 1, 1)        (2, 3, 4)  (6, 7, 8)
     A2  (1/4, 1/3, 1/2)        (1, 1, 1)  (4, 5, 6)
     A3  (1/8, 1/7, 1/6)  (1/6, 1/5, 1/4)  (1, 1, 1),
     'cost':                  A1         A2               A3
     A1        (1, 1, 1)  (4, 5, 6)  (1/6, 1/5, 1/4)
     A2  (1/6, 1/5, 1/4)  (1, 1, 1)  (1/4, 1/3, 1/2)
     A3        (4, 5, 6)  (2, 3, 4)        (1, 1, 1),
     'delivery':                  A1         A2               A3
     A1        (1, 1, 1)  (9, 9, 9)        (6, 7, 8)
     A2  (1/9, 1/9, 1/9)  (1, 1, 1)  (1/8, 1/7, 1/7)
     A3  (1/8, 1/7, 1/6)  (7, 7, 8)        (1, 1, 1),
     'after_sales':            A1               A2               A3
     A1  (1, 1, 1)  (1/8, 1/7, 1/6)  (1/4, 1/3, 1/2)
     A2  (6, 7, 8)        (1, 1, 1)        (2, 3, 4)
     A3  (2, 3, 4)  (1/4, 1/3, 1/2)        (1, 1, 1)}




```python
alternatives_weight_cr_dict={}
for k,v in alternatives_matrix_dict.items():
    alternatives_weight_cr_dict[k]={k:v for k,v in zip(['fuzzy_weights', 'defuzzified_weights', 'normalized_weights', 'cr'],best_supplier.weight(v))}
    
alternatives_weight_cr_dict
```




    {'quality': {'fuzzy_weights': [(0.052420300418135744,
        0.06294120510225566,
        0.07794836695752445),
       (0.1981363198158667, 0.2654333418834977, 0.3712059591227326),
       (0.5192640550376543, 0.6716254530142467, 0.8498494966569238)],
      'defuzzified_weights': [0.06443662415930529,
       0.27825854027403235,
       0.6802463349029416],
      'normalized_weights': [0.06299150459837054,
       0.2720180386215403,
       0.6649904567800892],
      'cr': 0.038802175909399925},
     'origin': {'fuzzy_weights': [(0.46123125532773124,
        0.6491180046313251,
        0.8906502333108046),
       (0.20146130719005298, 0.27895456548641834, 0.4046047199899532),
       (0.05543421498406391, 0.07192742988225646, 0.09725683059164322)],
      'defuzzified_weights': [0.6669998310899535,
       0.2950068642221415,
       0.07487282515265453],
      'normalized_weights': [0.643276116391026,
       0.28451411991425357,
       0.07220976369472036],
      'cr': 0.07101595764337375},
     'cost': {'fuzzy_weights': [(0.19287686201378226,
        0.258284994374495,
        0.355472493169515),
       (0.07654323341525081, 0.10472943388074786, 0.15526691289199787),
       (0.44157778201234055, 0.636985571744757, 0.8957345536057669)],
      'defuzzified_weights': [0.2688781165192641,
       0.11217986006266552,
       0.6580993024542882],
      'normalized_weights': [0.25874631486837024,
       0.10795272508383758,
       0.6333009600477921],
      'cr': 0.4768968318277456},
     'delivery': {'fuzzy_weights': [(0.6857178581616268,
        0.7607597376820608,
        0.8359451389785031),
       (0.04360838881170998, 0.04804930980478052, 0.050499463168466624),
       (0.17352027382598298, 0.19119095251315868, 0.22116336550036308)],
      'defuzzified_weights': [0.7608075782740635,
       0.04738572059498571,
       0.19529153061316826],
      'normalized_weights': [0.7581655007845295,
       0.0472211628943469,
       0.1946133363211237],
      'cr': 0.2922872691708499},
     'after_sales': {'fuzzy_weights': [(0.0646575791757096,
        0.08794620881905604,
        0.1285391955362206),
       (0.4699624744114258, 0.6694168694489877, 0.9342848767797738),
       (0.1629268900774419, 0.24263692173195622, 0.3707711990595482)],
      'defuzzified_weights': [0.09371432784366207,
       0.6912214068800623,
       0.25877833695631547],
      'normalized_weights': [0.08978927312229538,
       0.6622708514099278,
       0.24793987546777696],
      'cr': 0.030424894517038763}}



第4步，计算最后基于决策准则的备选方案得分。


```python
local_w_stack=np.stack([v['normalized_weights'] for v in alternatives_weight_cr_dict.values()],axis=-1)
weight_A=best_supplier.weight_matrix(normalized_weights,local_w_stack)
weight_A
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>quality</th>
      <th>origin</th>
      <th>cost</th>
      <th>delivery</th>
      <th>after_sales</th>
      <th>global_priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Wj</th>
      <td>0.382940</td>
      <td>0.409433</td>
      <td>0.074018</td>
      <td>0.057325</td>
      <td>0.076284</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>A1</th>
      <td>0.062992</td>
      <td>0.643276</td>
      <td>0.258746</td>
      <td>0.758166</td>
      <td>0.089789</td>
      <td>0.356964</td>
    </tr>
    <tr>
      <th>A2</th>
      <td>0.272018</td>
      <td>0.284514</td>
      <td>0.107953</td>
      <td>0.047221</td>
      <td>0.662271</td>
      <td>0.281874</td>
    </tr>
    <tr>
      <th>A3</th>
      <td>0.664990</td>
      <td>0.072210</td>
      <td>0.633301</td>
      <td>0.194613</td>
      <td>0.247940</td>
      <td>0.361162</td>
    </tr>
  </tbody>
</table>
</div>



### 3.1.2.3   再现 ARAS 算法

再现Zavadskas, E. K.等人在论文中给出的案例（办公室微气候评估），阐释 ARAS 算法。直接迁移`pyDecision`库提供的`aras_method`方法。

ARAS 算法基本同于一般基于权重计算得分的方法，其中决策准则权重值文中为专家打分获得；类似TOPSIS算法，考虑到决策准则的优化方向，即测量值是越大越好，还是越小越好；决策矩阵测量值根据决策准则优化方向计算方式有所调整。具体流程如下：

第1步，构建决策矩阵（decision-making matrix，DMM），公式为： $X=\left[\begin{array}{ccccc}x_{01} & \cdots & x_{0 j} & \cdots & x_{0 n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ x_{i 1} & \cdots & x_{i j} & \cdots & x_{i n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ x_{m 1} & \cdots & x_{m j} & \cdots & x_{m n}\end{array}\right] ; \quad i=\overline{0, m} ; j=\overline{1, n}$，式中，$m$为备选方案索引，$n$为决策准则索引，$x_{i j}$为第$j$个决策准则值下第$i$个备选方案的测量值。$x_{0 j}$为第$j$个决策准则的优化值，如果不知优化值，则可以通过下述方式确定，$\begin{aligned} & x_{0 j}=\max _i x_{i j}, \text { if } \max _i x_{i j} \text { is preferable } ; \\ & x_{0 j}=\min _i x_{i j}^* \text {, if } \min _i x_{i j}^* \text { is preferable. }\end{aligned}$。

第2步，为了比较不同单位（unit）、不同尺度(dimentions)的决策准则测量值，需要标准化为无量纲（dimensionless）的决策矩阵。优选值为最大值（maxima）的标准化公式为：$\bar{x}_{i j}=\frac{x_{i j}}{\sum_{i=0}^m x_{i j}}$；优选值为最小值（minima）的标准化公式为：$x_{i j}=\frac{1}{x_{i j}^*} ; \bar{x}_{i j}=\frac{x_{i j}}{\sum_{i=0}^m x_{i j}}$。标准化后的决策矩阵可以表示为：$\bar{X}=\left[\begin{array}{ccccc}\bar{x}_{01} & \ldots & \bar{x}_{0 j} & \ldots & \bar{x}_{0 n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ \bar{x}_{i 1} & \ldots & \bar{x}_{i j} & \ldots & \bar{x}_{i n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ \bar{x}_{m 1} & \ldots & \bar{x}_{m j} & \ldots & \bar{x}_{m n}\end{array}\right] ; i=\overline{0, m} ; j=\overline{1, n}$。

第3步，定义归一化加权决策矩阵。决策准则的权重满足$0< w_{j} <1$，且$ \sum_{j=1}^n w_j=1 $。归一化加权矩阵计算公式为：$\hat{x}_{i j}=\bar{x}_{i j} w_j ; i=\overline{0, m}$，式中，$ w_j$为第$j$个决策准则的权重值；归一化加权矩阵表示为：$\begin{aligned}  \hat{X}=\left[\begin{array}{ccccc}\hat{x}_{01} & \cdots & \hat{x}_{0 j} & \cdots & \hat{x}_{0 n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ \hat{x}_{i 1} & \cdots & \hat{x}_{i j} & \cdots & \hat{x}_{i n} \\ \vdots & \ddots & \vdots & \ddots & \vdots \\ \hat{x}_{m 1} & \cdots & \hat{x}_{m j} & \cdots & \hat{x}_{m n}\end{array}\right] ; i=\overline{0, m} ; j=\overline{1, n} \text {. } \\ & \end{aligned}$。

第4步，确定最优解。对每一备选方案对应的决策准则归一化加权值求和，即$S_i=\sum_{j=1}^n \hat{x}_{i j} ; i=\overline{0, m}$，$S_i$为备选方案得分。备选方案的效用度（degree of the alternative utility），可以通过$K_i=\frac{S_i}{S_0} ; i=\overline{0, m}$计算，式中，$S_0$为理想情况下得分值最高备选方案的值，通过与最高值比较确定效用度。

将办公室微气候评估数据写入到`USDA`数据集模块`datasets`下方便调用。读取该数据，包括分析所用的测量值决策矩阵、决策准则权重值和优化方向列表。


```python
microclimate_in_office_rooms=usda_datasets.load_microclimate_in_office_rooms()
microclimate_in_office_rooms
```




    {'data':     amount _of_air_per_head  relative_air_humidity  air_temperature  \
     1                       7.6                   46.0             18.0   
     2                       5.5                   32.0             21.0   
     3                       5.3                   32.0             21.0   
     4                       5.7                   37.0             19.0   
     5                       4.2                   38.0             19.0   
     6                       4.4                   38.0             19.0   
     7                       3.9                   42.0             16.0   
     8                       7.9                   44.0             20.0   
     9                       8.1                   44.0             20.0   
     10                      4.5                   46.0             18.0   
     11                      5.7                   48.0             20.0   
     12                      5.2                   48.0             20.0   
     13                      7.1                   49.0             19.0   
     14                      6.9                   50.0             16.0   
     
         illumination_during_work_hours  rate_of_air_flow  dew_point  
     1                            390.0              0.10       11.0  
     2                            360.0              0.05       11.0  
     3                            290.0              0.05       11.0  
     4                            270.0              0.05        9.0  
     5                            240.0              0.10        8.0  
     6                            260.0              0.10        8.0  
     7                            270.0              0.10        5.0  
     8                            400.0              0.05        6.0  
     9                            380.0              0.05        6.0  
     10                           320.0              0.10        7.0  
     11                           320.0              0.05       11.0  
     12                           310.0              0.05       11.0  
     13                           280.0              0.10       12.0  
     14                           250.0              0.05       10.0  ,
     'name': 'microclimate_in_office_rooms.pickle',
     'measurement_units': ['m3/h', '%', '°C', 'lx', 'm/s', '°C'],
     'optimisation_direction': ['max', 'max', 'max', 'max', 'min', 'min'],
     'weight_of_criteria': [0.21, 0.16, 0.26, 0.17, 0.12, 0.08],
     'optimal_value': [15, 50, 24.5, 400, 0.05, 5]}



从计算结果可以得知索引值为8的备选方案为最高得分，并可以配置`graph`参数打印排序图表。


```python
rank=usda_weight.aras_method(microclimate_in_office_rooms.data, microclimate_in_office_rooms.weight_of_criteria, microclimate_in_office_rooms.optimisation_direction, graph=True)
```

    a1: 0.821
    a2: 0.8
    a3: 0.764
    a4: 0.771
    a5: 0.666
    a6: 0.68
    a7: 0.688
    a8: 0.949
    a9: 0.945
    a10: 0.731
    a11: 0.825
    a12: 0.807
    a13: 0.776
    a14: 0.796
    


<img src="./imgs/3_1/output_59_1.png" height='auto' width='auto' title="caDesign">   



```python
rank
```




    array([[ 8.        ,  0.94850216],
           [ 9.        ,  0.94548367],
           [11.        ,  0.82549096],
           [ 1.        ,  0.82104672],
           [12.        ,  0.80717434],
           [ 2.        ,  0.80024248],
           [14.        ,  0.79601395],
           [13.        ,  0.77558685],
           [ 4.        ,  0.77056324],
           [ 3.        ,  0.76446671],
           [10.        ,  0.73067136],
           [ 7.        ,  0.68789147],
           [ 6.        ,  0.67985115],
           [ 5.        ,  0.66562774]])



### 3.1.2.4 再现 BWM 算法（基于 GWO 元启发式算法）

AHP和F-AHP需要给出判断矩阵，并通过参考CR值，不断调整修正判断矩阵的标度使其趋于一致矩阵，即在一致性检验过程中一致性比率CR值应满足要求。这个调整过程相对繁琐，也不容易使得每项决策准则之间和对于各个准则备选方案之间的判断矩阵修正到满足要求。而 BWM 方法并不需要对决策准则两两比较构建判断矩阵，而类似TOPSIS算法考虑最佳（Best）（正理想值） 和最差（Worst）（负理想值），将各个决策准则与最佳和最差的准则比较作为输入值。以作者给出的第1个案例解释 BWM 算法，该案例表述为公司要选择一种将其产品运输到市场的一种运输方式，涉及3个决策准则，为负载的灵活性$C_{1} $、可达性$C_{2} $和成本$C_{3} $。最佳和最差成对比较向量的值选择1-9之间的数，确定成本（$C_{3} $）为最佳准则，与最佳决策准则的成对比较（判断）向量为：$A_{B}=( a_{B1},a_{B2}, \ldots ,a_{Bn} ) =(8,2,1)$，式中，$a_{Bj}$为最佳决策准则对准则$j$的比较偏好（preference）；确定负载的灵活性（$C_{1} $）为最差准则，与最差决策准则的成对比较（判断）向量为：$A_{W}=( a_{1W},a_{2W}, \ldots ,a_{nW} ) =(1,5,8)$，式中$a_{jW}$为决策准则$j$对最差准则的比较偏好。如果决策准则的实际权重表示为$w_{j} $，那么理论上会有$\frac{w_{B} }{w_{j} }=a_{Bj}  ; \frac{w_{j} }{w_{W} }=a_{jW}$。但是在实际构建判断向量时，会产生误差，因此有：$\begin{aligned} & \left|\frac{\omega_B}{\omega_j}-a_{B j}\right| \leq \xi \quad ,\forall j \\ & \left|\frac{\omega_j}{\omega_W}-a_{j W}\right| \leq \xi, \forall j \\ & \sum_j \omega_j=1;\omega_j \geq 0 ,  \forall j \end{aligned}$，式中，$\xi$表示为误差。对应到案例，则有$\begin{aligned} & \left|\frac{w_3}{w_1}-8\right| \leq \xi \\ & \left|\frac{w_3}{w_2}-2\right| \leq \xi \\ & \left|\frac{w_2}{w_1}-5\right| \leq \xi \\ & w_1+w_2+w_3=1 \\ & w_1, w_2, w_3 \geq 0\end{aligned}$。对上述公式求解即可得到最优的决策准则权重$( w^{*}_{1},w^{*}_{2}, \ldots ,w^{*}_{n} )$和误差$\xi^{*} $。求解的方法使用 GWO（Grey Wolf Optimizer） 优化算法，为一种元启发式算法（meta-heuristic）<sup>[45]</sup>。

GWO 优化算法求解 BWM时，依据上述求解公式， 对于给定的c，可得$  \triangle w=  |  w_{B}- w_{j} a_{Bj}  | $，即求解$w_{j}$使得$ \triangle w$趋近于0；同样，对于给定的$A_{W}$，有$ \triangle w=  |  w_{j}- w_{W} a_{jW}  | $，即求解$w_{j}$使得$ \triangle w$趋近于0。将上述两种情况合并，权重更新时，选择$ \triangle w$为最小值对应的权重值更新，即为最优解。对应的代码为：

```python
def target_function(variables):
    eps       = [float('+inf')]
    for pair in pairs_b:
        i, j = pair
        diff = abs(variables[i] - variables[j]*mic[j])
        if ( i != j):
            eps.append(diff)
    for pair in pairs_w:
        i, j = pair
        diff = abs(variables[i] - variables[j]*lic[j])
        if ( i != j):
            eps.append(diff)
    if ( np.sum(variables) == 0):
        eps = float('+inf')
    else:
        eps = max(eps[1:])
    return eps
```

对于$A_{B}$，对应`diff = abs(variables[i] - variables[j]*mic[j])`；对于$A_{W}$，对应`diff = abs(variables[i] - variables[j]*lic[j])`。


依据 GWO 的等级制度思想，从每行为一组权重向量，初始化数量由参数`size`确定的权重集群（矩阵）（灰狼群）中，依据$ \triangle w$值（值越小越好），提取前三等级的权重组（行），并依次用alpha（$\alpha$）、beta（$\beta$）和delta（$\delta$） 表示，剩下未提取的权重行则为omega（$\omega$）。每一次迭代时都会根据最新的$ \triangle w$值更新$\alpha$、$\beta$和$\delta$，对应代码行为：

```python
def update_pack(position, alpha, beta, delta):
    updated_position = np.copy(position)
    for i in range(0, position.shape[0]):
        if (updated_position[i,-1] < alpha[0,-1]):
            alpha[0,:] = np.copy(updated_position[i,:])
        if (updated_position[i,-1] > alpha[0,-1] and updated_position[i,-1] < beta[0,-1]):
            beta[0,:] = np.copy(updated_position[i,:])
        if (updated_position[i,-1] > alpha[0,-1] and updated_position[i,-1] > beta[0,-1]  and updated_position[i,-1] < delta[0,-1]):
            delta[0,:] = np.copy(updated_position[i,:])
    return alpha, beta, delta
```

逐行逐列（各行各个决策准则权重值）更新权重集群时，是同时考虑$\alpha$、$\beta$和$\delta$3个等级，根据 GWO 模拟包围和狩猎行为变化更新权重集群（灰狼），使之趋于最优解（猎物）。对于包围猎物的行为，论文中定义公式为：$\begin{aligned} & \vec{D}=\left|\vec{C} \cdot \vec{X}_p(t)-\vec{X}(t)\right| \\ & \vec{X}(t+1)=\vec{X}_p(t)-\vec{A} \cdot \vec{D}\end{aligned}$，式中，$t$为当前的迭代次数，$\vec{C}$和$\vec{A}$是向量（权重值）系数，$\vec{X}_p$为$\alpha$、$\beta$和$\delta$当前迭代次数下的权重值，$\vec{X}$为更新后的权重值。对于$\vec{C}$和$\vec{A}$，计算公式为：$\begin{aligned} & \vec{A}=2 \vec{a} \cdot \vec{r}_1-\vec{a} \\ & \vec{C}=2 \cdot \vec{r}_2\end{aligned}$，式中，$\vec{a}$为收敛因子，随着迭代次数的增加从2线性的减少至0，$\vec{r}_1$和$\vec{r}_2$为[0,1]的随机数。对于狩猎行为，论文中定义的公式为： $\begin{aligned} & \vec{D}_\alpha=\left|\vec{C}_1 \cdot \vec{X}_\alpha-\vec{X}\right|, \vec{D}_\beta=\left|\vec{C}_2 \cdot \vec{X}_\beta-\vec{X}\right|, \vec{D}_\delta=\left|\vec{C}_3 \cdot \vec{X}_\delta-\vec{X}\right| \\ & \vec{X}_1=\vec{X}_\alpha-\vec{A}_1 \cdot\left(\vec{D}_\alpha\right), \vec{X}_2=\vec{X}_\beta-\vec{A}_2 \cdot\left(\vec{D}_\beta\right), \vec{X}_3=\vec{X}_\delta-\vec{A}_3 \cdot\left(\vec{D}_\delta\right) \\ & \vec{X}(t+1)=\frac{\vec{X}_1+\vec{X}_2+\vec{X}_3}{3}\end{aligned}$，是分别计算$\alpha$、$\beta$和$\delta$3个等级包围猎物的行为，求其均值为更新的权重值。进而可以根据更新的权重值计算当前的$ \triangle w$值。对应的代码行为：

```python
def update_position(position, alpha, beta, delta, a_linear_component = 2, min_values = [-5,-5], max_values = [5,5], target_function = target_function):
    updated_position = np.copy(position)
    for i in range(0, updated_position.shape[0]):
        for j in range (0, len(min_values)):   
            r1_alpha              = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            r2_alpha              = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            a_alpha               = 2*a_linear_component*r1_alpha - a_linear_component
            c_alpha               = 2*r2_alpha      
            distance_alpha        = abs(c_alpha*alpha[0,j] - position[i,j]) 
            x1                    = alpha[0,j] - a_alpha*distance_alpha   
            r1_beta               = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            r2_beta               = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            a_beta                = 2*a_linear_component*r1_beta - a_linear_component
            c_beta                = 2*r2_beta            
            distance_beta         = abs(c_beta*beta[0,j] - position[i,j]) 
            x2                    = beta[0,j] - a_beta*distance_beta                          
            r1_delta              = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            r2_delta              = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            a_delta               = 2*a_linear_component*r1_delta - a_linear_component
            c_delta               = 2*r2_delta            
            distance_delta        = abs(c_delta*delta[0,j] - position[i,j]) 
            x3                    = delta[0,j] - a_delta*distance_delta                                 
            updated_position[i,j] = np.clip(((x1 + x2 + x3)/3),min_values[j],max_values[j])     
        updated_position[i,-1] = target_function(updated_position[i,0:updated_position.shape[1]-1])
    return updated_position
```

BWM 给出了一致性比例计算的方法。对于一致矩阵有$a_{ik} \times  a_{kj}=a_{ij}, \forall i,j$，实际给出的判断向量往往产生非一致性问题，即$a_{Bj} \times  a_{jW} \neq a_{BW}$，当且仅当$a_{Bj} =a_{jW} = a_{BW}$时，误差达到最大，由$(w _{B}/w _{j})  \times (w _{j}/w _{W})=(w _{B}/w _{W})$，考虑最大误差发生时有：$\left(a_{B j}-\xi\right) \times\left(a_{j W}-\xi\right)=\left(a_{B W}+\xi\right)$，即，$\left(a_{B W}-\xi\right) \times\left(a_{BW}-\xi\right)=\left(a_{B W}+\xi\right) \Rightarrow \xi^2-\left(1+2 a_{B W}\right) \xi+\left(a_{B W}{ }^2-a_{B W}\right)=0$。求解不同的$a_{BW} \in \{1,2, \ldots ,9\} $，可以找到最大可能的$\xi$（max $\xi$），其表为：

| $a_{BW}$  | 1  | 2  | 3  | 4  | 5  | 6  | 7  |  8 | 9  |
|---|---|---|---|---|---|---|---|---|---|
| Consistency index（CI） （max $\xi$） | 0.00  |  0.44  |  1.00   | 1.63   |  2.30   |   3.00  |   3.73  |  4.47   | 5.23  |

一致性比率（CR）则为：$CR= \frac{ \xi^{*} }{CI} $

应用基于 GWO 优化算法求解 BWM的方法，再现论文案例1，其计算结果为0.100、0.250和0.649，对应论文中的结果0.0714、0.3387和0.5899，重要性排序保持一致。


```python
mic=np.array([8,2,1]) # Most Important Criteria
lic=np.array([1,5,8]) # Least Important Criteria

weights=usda_weight.bw_method(mic, lic, size=50, iterations=200,verbose=50)
print(weights)
```

    Iteration =  0  f(x) =  inf
    Iteration =  50  f(x) =  0.015477062414798246
    Iteration =  100  f(x) =  0.015112102494579303
    Iteration =  150  f(x) =  0.015112102494579303
    Iteration =  200  f(x) =  0.015020926002282144
    [0.10000609 0.24996459 0.65002932]
    

### 3.1.2.5 再现 DEMATEL 算法

Dematel 是一种运用图论和矩阵工具解释问题的系统分析方法，通过评估系统中各个因子（factors）（决策准则）之间的相互依赖关系，可以计算每个因子对其它因子的影响度和被影响度，从而计算每个因子的原因度和中心度，确定因子间的因果关系和每个因子在系统中的地位。Dematel 有许多不同的变体，例如根据使用方法可归为有5类： 经典型（classical-dematel），模糊性（fuzzy-dematel）， grey-dematel, ANP-dematel（analytical network process，ANP）和其它类型。`pyDecision`库提供的`dematel_method` 方法为经典型，将其迁移至`USDA`库中调用。

第1步，该方法首先需要构建因子关系（影响，判断）矩阵（direct-influence matrix）$Z$，评估系统中因子$F=\{ F_{1},F_{2}, \ldots ,F_{n} \}$之间的关系。假设决策组中有个$l$名专家$E=\{ E_{1},E_{2}, \ldots ,E_{l} \}$参与构建关系矩阵，通过标度（0，无影响（no influence）；1，低影响（low influence）；2，中等影响（medium influence）；3，高等影响（high influence）；4，极度影响（very high influence）），指出因子$F_{i}$对$F_{j}$的影响程度。第$k$位专家构建的关系矩阵表示为：$Z_{k}= [ z_{ij}^k ]_{n \times n}  $，关系矩阵的对角线应为0，即自身对自身没有影响，$ z_{ij}^k $代表第$ E_{k}$决策者评估因子$F_{i}$对因子$F_{j}$的影响程度，按对角线右上和左下为直接影响（direct effects）和间接影响（indirect effects）。整合所有决策者的关系矩阵为$Z= [ z_{ij} ]_{n \times n}$，式中，$z_{i j}=\frac{1}{l} \sum_{k=1}^l z_{i j}^k, \quad i, j=1,2, \ldots, n$。例如`pyDecision`库案例提供的关系矩阵为：$ \begin{bmatrix}0 & 1&2&0 \\3 & 0&4&4\\3&2&0&1\\4&1&2&0 \end{bmatrix} $，对应因子g1、g2、g3和g4。

第2步，（最大值）归一化关系矩阵$Z$为$X= [ x_{ij} ]_{n \times n} $，公式为，$\begin{aligned} & X=\frac{Z}{s}, \\ & s=\max \left(\max _{1 \leq i \leq n} \sum_{j=1}^n z_{i j}, \max _{1 \leq i \leq n} \sum_{i=1}^n z_{i j}\right) \end{aligned}$，式中，$\sum_{j=1}^n z_{i j}$（$\sum_{i=1}^n z_{i j}$）为对关系矩阵$Z$所有行（或列）求和，并取其最大值为$s$，案例的最大值为11，归一化结果为：$\begin{bmatrix}
   0.000 &   0.091 &   0.182 &   0.000\\
   0.273 &   0.000 &   0.364 &   0.364\\
   0.273 &   0.182 &   0.000 &   0.091\\
   0.364 &   0.091 &   0.182 &   0.000
\end{bmatrix}$。

第3步，计算综合关系矩阵$T= [t_{ij}]_{n \times n} $，公式为：$T=X+ X^{2} +X^{3}+ \ldots +X^{h}=X (1-X)^{-1}, h  \longrightarrow  \infty $，即直接影响和所有间接影响之和，式中，$I$为单位矩阵（identity matrix）。实验数据的计算结果为：$\begin{bmatrix}
   0.154 &   0.165 &   0.285 &   0.086\\
   0.703 &   0.232 &   0.668 &   0.509\\
   0.495 &   0.289 &   0.235 &   0.217\\
   0.573 &   0.224 &   0.389 &   0.117
\end{bmatrix}$。

第4步，生成影响力关系图（influential relation map，IRM）。综合关系矩阵$T$的行之和为$R$，列之和为$C$，对应公式为：$\begin{aligned} & R=\left[r_i\right]_{n \times 1}=\left[\sum_{j=1}^n t_{i j}\right]_{n \times 1}, \\ & C=\left[c_j\right]_{1 \times n}=\left[\sum_{i=1}^n t_{i j}\right]_{1 \times n}^T,\end{aligned}$，式中，$r_i$为矩阵$T$第$i$行之和，表示因子$F_{i}$对其它因子的直接和间接影响的总和，为影响度（D）值，对应实验数据结果为$\begin{bmatrix}   0.689 &   2.112 &   1.236 &   1.304\end{bmatrix}$，可知因子g2对其它因子直接和间接影响总和最大，而因子g1对其它因子影响最小；$c_j$为矩阵$T$第$j$列之和，表示因子$F_j$受其它因子直接和间接影响的总和，为被影响度（C）值，对应实验数据结果为$\begin{bmatrix} 1.925 &   0.910 &   1.577 &   0.929 \end{bmatrix}$，可知因子g1受到其它因子的影响最大，而g2受到其它因子的影响最小。

另$i=j, i,j  \in \{1,2, \ldots ,n\}$，影响度和被影响度之和为$R+C$，代表该因子在系统中的核心作用程度，为中心度（Prominence）；同样，$R-C$代表该因子对系统贡献的净效应，为原因度（Relation）。如果$(r_j-c_j)$为正，则因子$F_j$对其它因子有净影响，可以归为原因组（cause group）；如果$(r_j-c_j)$为负，则因子$F_j$整体上受到其它因素的影响，应归入效应组（effect group）。实验数据对应的中心度和原因度分别为，$\begin{bmatrix}  2.614 &   3.021 &   2.813 &   2.232 \end{bmatrix}$和\begin{bmatrix} -1.236 &   1.202 & -0.341 &   0.375 \end{bmatrix}。可以通过映射$(R+C,R-C)$的数据集创建IRM（如下图），为决策指定提供有价值的见解。四象限图中：

第1象限，（Prominence：高，Relation：高），具有最重要的因子；

第2象限，（Prominence：低，Relation：高），具有可以通过其它因子改进的重要因子；

第3象限，（Prominence：低，Relation：低），具有不重要的因子；

第4象限，（Prominence：高，Relation：低），具有无法通过其它因子改进的重要因子。


```python
dataset = np.array([
    #  g1  g2  g3  g4
    [  0,  1,  2,  0  ],   #g1
    [  3,  0,  4,  4  ],   #g2
    [  3,  2,  0,  1  ],   #g3
    [  4,  1,  2,  0  ]    #g4
    ])

D_plus_R, D_minus_R, weights=usda_weight.dematel_method(dataset, size_x=7, size_y=5)
print(D_plus_R, D_minus_R, weights)
```

    QUADRANT I has the Most Important Criteria (Prominence: High, Relation: High)
    QUADRANT II has Important Criteira that can be Improved by Other Criteria (Prominence: Low, Relation: High)
    QUADRANT III has Criteria that are not Important (Prominence: Low, Relation: Low)
    QUADRANT IV has Important Criteria that cannot be Improved by Other Criteria (Prominence: High, Relation: Low)
    
    g1: Quadrant III
    g2: Quadrant I
    g3: Quadrant IV
    g4: Quadrant II
    

<img src="./imgs/3_1/output_65_1.png" height='auto' width='auto' title="caDesign">
    



    [2.61441523 3.02130553 2.81287398 2.23245694] [-1.2356301   1.20172257 -0.34106981  0.37497733] [0.24477133 0.28286592 0.26335178 0.20901097]
    

### 3.1.2.6 再现 IDOCRIW 算法（基于 GA 元启发式算法）

Zavadskas 和 Podvezko 提出的 IDOCRIW 算法受益于信息熵（Entropy）和 准则影响损失（Criterion Impact LOSs，CILOS）方法。通过结合这两种方法确定相对影响损失及属性权重。IDOCRIW 算法的输入条件为决策矩阵和决策准则方向（越大越好还是越小越好）。作者给出的案例数据为：$\begin{aligned} & \begin{array}{lllll}\hspace{25pt}  - & \hspace{7pt} + & \hspace{7pt} - & \hspace{7pt} +\end{array} \\ & \begin{array}{llll} \hspace{25pt}  \mathrm{C}_1 & \hspace{7pt} \mathrm{C}_2 & \mathrm{C}_3 & \mathrm{C}_4\end{array} \\ & \begin{array}{l}\mathrm{A}_1 \\ \mathrm{~A}_2 \\ \mathrm{~A}_3 \\ \mathrm{~A}_4\end{array}\left[\begin{array}{cccc}3 & 100 & 10 & 7 \\ 2.500 & 80 & 8 & 5 \\ 1.800 & 50 & 20 & 11 \\ 2.200 & 70 & 12 & 9\end{array}\right] \\ & \end{aligned}$，为一个组织打算在$\mathrm{A}_1$、$\mathrm{A}_2$、$\mathrm{A}_3$和$\mathrm{A}_4$等4个地块中选择一个建造一座行政大楼。公司主管部分拟根据专家意见，对成本（$\mathrm{C}_1 $）、建筑面积（$\mathrm{C}_2 $）、与组织所在地的距离（$\mathrm{C}_3 $）和建筑质量（$\mathrm{C}_4 $）等属性进行审查和优先排序。

第1步，标准化决策矩阵，公式为：$\bar{r}_{i j}=\frac{r_{i j}}{\sum_{i=1}^n r_{i j}} ; \quad j=1, \ldots, n$，式中，$\bar{r}_{i j}$表示第$j$个决策准则下第$i$个备选方案的标准化值。实验数据结果为：$\begin{bmatrix}
   0.316 &   0.333 &   0.200 &   0.219\\
   0.263 &   0.267 &   0.160 &   0.156\\
   0.189 &   0.167 &   0.400 &   0.344\\
   0.232 &   0.233 &   0.240 &   0.281
\end{bmatrix}$。

第2步，熵值权重法，公式为：$\begin{aligned} & E_j=-\frac{1}{\ln n} \sum_{i=1}^n \bar{r}_{i j} . \ln \bar{r}_{i j} ; \quad j=1, \ldots, n, \quad 0 \leq E_j \leq 1 \\ & d_j=1-E_j ; \quad j=1, \ldots, n \\ & w_j=\frac{d_j}{\sum_{j=1}^n d_j}\end{aligned}$，实验数据决策准则的信息熵权重结果为，$\begin{bmatrix} 0.115 &   0.198 &   0.418 &   0.269 \end{bmatrix}$。

第3步，统一决策准则方向为最大方向（maximized）并再次标准化（该公式同前），公式为：$\begin{aligned} \hat{r}_{i j} & =\frac{\min _i r_{i j}}{r_{i i}} ; \quad i, j \in\{1, \ldots, n\} \end{aligned} $，将决策矩阵列为负方向的决策准则转换为正方向（值越大越好），并再次标准化。实验数据对应的结果为：$\begin{bmatrix}
   0.191 &   0.333 &   0.279 &   0.219\\
   0.229 &   0.267 &   0.349 &   0.156\\
   0.319 &   0.167 &   0.140 &   0.344\\
   0.261 &   0.233 &   0.233 &   0.281
\end{bmatrix}$。

第4步，构建方阵（Square Matrix），是依次提取决策矩阵每一决策准则列最大值所在的行形成一个新的矩阵，即对原决策矩阵的行按列的最大值排序，从而新的矩阵对角线为各列的最大值，其公式为：$\begin{aligned}  a_j & =\max _i \bar{r}_{i j}=a_{k_i j} ; \quad i, j \in\{1, \ldots, n\}\end{aligned}$，式中，$a_{k_i j} $对应着第$j$个决策准则列最大值行$k_i$，且$a_{ij}=a_{k_i j}$，及$a_{jj}=a_{j}$。实验数据对应的结果为：$\begin{bmatrix}
   0.319 &   0.167 &   0.140 &   0.344\\
   0.191 &   0.333 &   0.279 &   0.219\\
   0.229 &   0.267 &   0.349 &   0.156\\
   0.319 &   0.167 &   0.140 &   0.344
\end{bmatrix}$。

第5步，计算相对影响损失矩阵（Relative Impact Loss Matrix），公式为：$p_{ij}= \frac{a_{jj}-a_{ij}}{a_{jj}};i,j \in \{1, \ldots ,n\},p_{jj}=0 $，$p_{ij}$表示第$j$个决策准则如果作为最佳值的相对影响损失。实验数据对应结果为：$\begin{bmatrix}
   0.000 &   0.500 &   0.600 &   0.000\\
   0.400 &   0.000 &   0.200 &   0.364\\
   0.280 &   0.200 &   0.000 &   0.545\\
   0.000 &   0.500 &   0.600 &   0.000
\end{bmatrix}$。

第6步，权重系统矩阵（ Weight System Matrix），将相对损失矩阵对角线的值替换为各列值和取反，公式为：$\mathrm{F}=\left(\begin{array}{cccc}-\sum_{i=1}^n P_{i 1} & P_{12} & \cdots & P_{1 \mathrm{n}} \\ P_{21} & -\sum_{i=1}^n P_{i 2} & \cdots & P_{2 \mathrm{n}} \\ \vdots & \vdots & \ddots & \vdots \\ P_{\mathrm{n} 1} & P_{\mathrm{n} 2} & \cdots & -\sum_{i=1}^n P_{i \mathrm{n}}\end{array}\right)_{n \times n}$。实验数据计算结果为： $\begin{bmatrix}
 -0.680 &   0.500 &   0.600 &   0.000\\
   0.400 & -1.200 &   0.200 &   0.364\\
   0.280 &   0.200 & -1.400 &   0.545\\
   0.000 &   0.500 &   0.600 & -0.909
\end{bmatrix}$。

第7步，计算决策准则影响损失权重（Criterion Impact Loss Weight，$Q$），根据公式$Fq^T=0$，计算权重值，实验数据对应的方程为：$\left\{\begin{array}{l}-0.680 q_1+0.500 q_2+0.600 q_3=0 \\ 0.400 q_1-1.200 q_2+0.200 q_3+0.364 q_4=0 \\ 0.280 q_1+0.200 q_2-1.400 q_3+0.545 q_4=0 \\ 0.500 q_2+0.600 q_3-0.909 q_4=0\end{array}\right.$，求解上述方程即可获得权重。

第8步，使用遗传算法（Genetic Algorithm， GA）求解第7步的方程。

由第7步方程构建目标函数，对应的代码为：

```python
def target_function(variable = [0]*WP.shape[1]):
    variable = [variable[i]/sum(variable) for i in range(0, len(variable))]
    WP_s     = np.copy(WP)
    for i in range(0, WP.shape[0]):
        for j in range(0, WP.shape[1]):
            WP_s[i, j] = WP_s[i, j]*variable[j]
    total = abs(WP_s.sum(axis = 1)) 
    total = sum(total) 
    return total
```

其中，`WP`变量为权重系统矩阵，`variable`为每次迭代的决策准则权重向量，代入第7步公式，满足各行值总和趋于0，即`total`（$S$值越小越好。

遗传算法为元启发式算法，受启发于自然进化理论，通过模拟自然选择的过程，从种群（population）选择最适合的个体（individuals）进行繁殖产生后代（offspring ）。产生的后代继承了父代的特征，并遗传至下一代。如果父代有较好的适应度（fitness score），后代就会比父代有更好的生存机会。上述过程不断迭代，直至进化到最适合的一代。整个过程可以分为5步，初始化种群（对应`initial_population`函数），适应函数（对应`fitness_function`函数），选择和交叉（对应`breeding`函数），变异（对应`mutation`函数）。

第8-1步，初始化种群（Initial Population）

种群是包含多个个体的集合，本例中个体即为决策准则权重值，为一个包含4个值的向量，那么初始化种群则是随机产生了多个权重向量的集合。个体的特征是一组称为基因（Genes）的参数，对应着各个决策准则，而个体组成的向量就形成了一个染色体（Chromosome），即决策准则权重值。初始化种群对应的代码为：

```python
# Function: Initialize Variables
def initial_population(population_size = 5, min_values = [-5,-5], max_values = [5,5], target_function = target_function):
    population = np.zeros((population_size, len(min_values) + 1))
    for i in range(0, population_size):
        for j in range(0, len(min_values)):
             population[i,j] = random.uniform(min_values[j], max_values[j]) 
        population[i,-1] = target_function(population[i,0:population.shape[1]-1])
    return population
```

代码初始化的种群`population`个人均增加了一位，用于存储目标函数`target_function`的返回值`total`（$S$）。初始化的权重值位于给定的区间[0,1]内。

第8-2步，定义适应度函数（Fitness Function）

适应度函数通过给每一个体适应度值，确定个体与其它个体竞争的能力，从而更容易被选择进行繁殖。本例个体适应度为包含两个值的向量，公式为：$\begin{aligned}&  F_i^0= \frac{1}{1+S_i+S_{min}} \\& F_i^1= \frac{F_i^0+F_{i-1}^1}{ \sum_{i=1}^n F_i^0 }  \end{aligned}$，式中，c为适应度第1个值（索引为0），$ F_i^1$为适应度第2个值（索引为1），$S$为目标函数的返回值，$S_{min}$为种群$S$的最小值，$F_{i-1}^1$为当前个体前一个体（父代）适应度值的第2个值（索引为1）。$F_i^0$随$S$值的减小而增大，且考虑到了$S$种群水平上的最小值，即种群水平$S$最小值越小，$F_i^0$越大；$ F_i^1$受$F_i^0$的影响，当适应度第1个值越大，第2个值也越大，且如果其父代第2个值越大，其自身（子代）第2个值也越大。 对应的代码行为：

```python
# Function: Fitness
def fitness_function(population): 
    fitness = np.zeros((population.shape[0], 2))
    for i in range(0, fitness.shape[0]):
        fitness[i,0] = 1/(1+ population[i,-1] + abs(population[:,-1].min()))
    fit_sum = fitness[:,0].sum()
    fitness[0,1] = fitness[0,0]
    for i in range(1, fitness.shape[0]):
        fitness[i,1] = (fitness[i,0] + fitness[i-1,1])
    for i in range(0, fitness.shape[0]):
        fitness[i,1] = fitness[i,1]/fit_sum
    return fitness
```

第8-3步，繁殖（选择（Selection）与交叉（Crossover））

* 选择，是选择最适合的个体传递基因给下一代，需要选择两个个体（父母）为$p_1$和$p_2$，选择前可以将前一迭代适应度$F^1$最大的前$n$行替换对应种群的前$n$行。选择的过程是产生随机数$r$，循环适应度矩阵，只要满足$r \leq F_i^1$，即为选择的适合的父代。代码为：

```python
# Function: Selection
def roulette_wheel(fitness): 
    ix = 0
    random = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
    for i in range(0, fitness.shape[0]):
        if (random <= fitness[i, 1]):
          ix = i
          break
    return ix
```

* 交叉，为遗传算法中最重要的部分，子代是通过父代$p_1$和$p_2$交换基因产生的， 公式为：$\begin{aligned}& P_{ij}= \frac{(1+b)P_{p_1j}+(1-b)P_{p_2j}}{2};\\& P_{(i+1)j}= \frac{(1-b)P_{p_1j}+(1+b)P_{p_2j}}{2}, i<|P| ;  \\& b=(2r_b)^{ \frac{1}{ \mu +1} }, r \leq 0.5; \\& b= \left( \frac{1}{2(1-r_b)}\right )^{\frac {1}{\mu+1}} , r>0.5  \end{aligned}$，式中，$P_{ij}$为相对父代个体基因，为第$i$个个体的第$j$个基因，$ P_{(i+1)j}$相对子代个体基因，$|P|$为种群的数量，$r$和$r_b$均为[0,1]区间的随机数，$\mu$为交叉系数。代码为：

```python
# Function: Offspring
def breeding(population, fitness, min_values = [-5,-5], max_values = [5,5], m u = 1, elite = 0, target_function = target_function):
    offspring = np.copy(population)
    b_offspring = 0
    if (elite > 0):
        preserve = np.copy(population[population[:,-1].argsort()])
        for i in range(0, elite):
            for j in range(0, offspring.shape[1]):
                offspring[i,j] = preserve[i,j]
    for i in range (elite, offspring.shape[0]):
        parent_1, parent_2 = roulette_wheel(fitness), roulette_wheel(fitness)
        while parent_1 == parent_2:
            parent_2 = random.sample(range(0, len(population) - 1), 1)[0]
        for j in range(0, offspring.shape[1] - 1):
            rand = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            rand_b = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)                                
            if (rand <= 0.5):
                b_offspring = 2*(rand_b)
                b_offspring = b_offspring**(1/(mu + 1))
            elif (rand > 0.5):  
                b_offspring = 1/(2*(1 - rand_b))
                b_offspring = b_offspring**(1/(mu + 1))       
            offspring[i,j] = np.clip(((1 + b_offspring)*population[parent_1, j] + (1 - b_offspring)*population[parent_2, j])/2, min_values[j], max_values[j])           
            if(i < population.shape[0] - 1):   
                offspring[i+1,j] = np.clip(((1 - b_offspring)*population[parent_1, j] + (1 + b_offspring)*population[parent_2, j])/2, min_values[j], max_values[j]) 
        offspring[i,-1] = target_function(offspring[i,0:offspring.shape[1]-1]) 
    return offspring
```

第8-4步，变异（Mutation）

某些新生成的后代，基因可以发生随机概率较低的突变，以维持种群的多样性防止过早收敛。公式为：$\begin{aligned}& P_{ij}=P_{ij}+dm \\& dm=(2r_d)^{\frac{1}{ \eta +1}}-1, r \leq 0.5; \\& dm=1-(2(1-r_d))^\frac{1}{\eta+1},r>0.5 \end{aligned}$，式中，$ P_{ij}$为种群个体基因，即第$i$个个体的第$j$个基因，为实验数据权重向量中对应的第$j$个决策权重值。$r$和$r_d$为[0,1]随机数，$\eta$为变异因子，$dm$为变异值。对应代码为：

```python
# Function: Mutation
def mutation(offspring, mutation_rate = 0.1, eta = 1, min_values = [-5,-5], max_values = [5,5], target_function = target_function):
    d_mutation = 0            
    for i in range (0, offspring.shape[0]):
        for j in range(0, offspring.shape[1] - 1):
            probability = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
            if (probability < mutation_rate):
                rand = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)
                rand_d = int.from_bytes(os.urandom(8), byteorder = "big") / ((1 << 64) - 1)                                     
                if (rand <= 0.5):
                    d_mutation = 2*(rand_d)
                    d_mutation = d_mutation**(1/(eta + 1)) - 1
                elif (rand > 0.5):  
                    d_mutation = 2*(1 - rand_d)
                    d_mutation = 1 - d_mutation**(1/(eta + 1))                
                offspring[i,j] = np.clip((offspring[i,j] + d_mutation), min_values[j], max_values[j])
        offspring[i,-1] = target_function(offspring[i,0:offspring.shape[1]-1])                        
    return offspring
```

第8-5步，迭代

遗传算法通过迭代选择、交叉、变异，更新适应度，使种群个体（决策准则权重）趋于最优解，对应代码为：

```python
# GA Function
def genetic_algorithm(population_size = 5, mutation_rate = 0.1, elite = 0, min_values = [-5,-5], max_values = [5,5], eta = 1, mu = 1, generations = 50, target_function = target_function, verbose = True):    
    count = 0
    population = initial_population(population_size = population_size, min_values = min_values, max_values = max_values, target_function = target_function)
    fitness = fitness_function(population)    
    elite_ind = np.copy(population[population[:,-1].argsort()][0,:])
    while (count <= generations):  
        if (verbose == True):
            print('Generation = ', count, ' f(x) = ', elite_ind[-1])  
        offspring = breeding(population, fitness, min_values = min_values, max_values = max_values, mu = mu, elite = elite, target_function = target_function) 
        population = mutation(offspring, mutation_rate = mutation_rate, eta = eta, min_values = min_values, max_values = max_values, target_function = target_function)
        fitness = fitness_function(population)
        value = np.copy(population[population[:,-1].argsort()][0,:])
        if(elite_ind[-1] > value[-1]):
            elite_ind = np.copy(value) 
        count = count + 1       
    return elite_ind 
```

由遗传算法求得第7步方程解为$\begin{bmatrix} 0.33330718 & 0.21991215 & 0.19594158 & 0.25083909 \end{bmatrix}$。

第9步，聚合权重（Aggregate Weight）

将熵值权重（$q$）和CILOS权重（$W$）聚合得决策准则权重向量，其公式为：$\omega_j=\frac{q_j \cdot w_j}{\sum_{j=1}^n q_j \cdot w_j}$。

最终求得权重值为： $\begin{bmatrix} 0.1652 &  0.1884 & 0.3547 & 0.2917 \end{bmatrix}$。


```python
criterion_type=['min','max','min','max']
dataset=np.array([[3,100,10,7],
                  [2.5,80,8,5],
                  [1.8,50,20,11],
                  [2.2,70,12,9]])

rank=usda_weight.idocriw_method(dataset, criterion_type, size = 20, gen = 12000, graph = True,verbose=1000)
```

    Generation =  0  f(x) =  0.25174145471050513
    Generation =  1000  f(x) =  0.005088300343106242
    Generation =  2000  f(x) =  0.005088300343106242
    Generation =  3000  f(x) =  0.002048160299766136
    Generation =  4000  f(x) =  0.002048160299766136
    Generation =  5000  f(x) =  0.0017442771772882698
    Generation =  6000  f(x) =  0.0017442771772882698
    Generation =  7000  f(x) =  0.0017442771772882698
    Generation =  8000  f(x) =  0.0017442771772882698
    Generation =  9000  f(x) =  0.0017442771772882698
    Generation =  10000  f(x) =  0.0017442771772882698
    Generation =  11000  f(x) =  0.0017442771772882698
    Generation =  12000  f(x) =  0.0017442771772882698
    solution:[0.33330718 0.21991215 0.19594158 0.25083909]
    a1: 0.1652
    a2: 0.1884
    a3: 0.3547
    a4: 0.2917
    

<img src="./imgs/3_1/output_69_1.png" height='auto' width='auto' title="caDesign">
    


### 3.1.2.7 再现 ELECTRE-I 算法

1966年 Bernard Roy 在罗马发表了一篇论文，开发了一个实用的决策系统，现在称之为 ELECTRE。该方法根据备选方案在一组通用决策准则上的得分，对所有备选方案可能配对之间的决策准则关系进行系统分析。结果是衡量每个备选方案优于所有其它备选方案的程度。即若某一备选方案具有多数的决策准则优于其它备选方案且没有任何准则低于不可接受的阈值程度，则该方案优于其它备选方案。该方法需要构建排名靠前的关系，生成满意度/一致性（concordance）和不满意度/不一致（discordance）矩阵（指数）（包含对每个决策准则的相对重要性，即权重的考虑）。 ELECTRE 有6个主要版本，为I、II、III、IV、Tri 和 IS。这里以 ELECTRE-I 为例，再现该算法。

再现 ELECTRE-I 算法的实验数据选择*ELECTRE AND DECISION SUPPORT*<sup>[22]</sup>提供的案例数据，该案例拟议的高速公路项目有6个备选方案$P_i$，包含5个环境相关的决策准则$Cr_j$，为噪音污染影响（$Cr_1$）、社区和土地隔离影响（$Cr_2$）、空气污染影响（$Cr_3$）、土地利用影响（$Cr_4$）和休闲影响（$Cr_5$）。决策准则的权重为：$\begin{aligned} & \begin{array}{llllll}\text { Criterion } & \mathrm{Cr} 1 & \mathrm{Cr} 2 & \mathrm{Cr} 3 & \mathrm{Cr} 4 & \mathrm{Cr} 4\end{array} \\ & \begin{array}{llllll}\text { Weighting } & 3 & \hspace{5pt} 2 & \hspace{8pt} 3 & \hspace{8pt}1 & \hspace{8pt} 1\end{array} \\ & \end{aligned}$；定性等级评估决策矩阵：

$\begin{array}{|c|ccccc|}
\hline & \text { Cr1 } & \text { Cr2 } & \text { Cr3 } & \text { Cr4 } & \text { Cr5 } \\
\hline \text { P1 } & \text { N } & \text { VB } & \text { A } & \text { N } & \text { VB } \\
\text { P2 } & \text { SA } & \text { A } & \text { A } & \text { VB } & \text { N } \\
\text { P3 } & \text { SA } & \text { N } & \text { SA } & \text { VB } & \text { A } \\
\text { P4 } & \text { VB } & \text { A } & \text { N } & \text { N } & \text { N } \\
\text { P5 } & \text { VB } & \text { N } & \text { B } & \text { N } & \text { B } \\
\text { P6 } & \text { VB } & \text { N } & \text { VB } & \text { B } & \text { B } \\
\text { Weighting } & 3 & 2 & 3 & 1 & 1 \\
\hline
\end{array}$，

其中，评估等级解释为VB（Very Beneficial，非常有益）、B（Beneficial，有益）、N（Neutral，中性）、A（Adverse，不利）和SA（Severely Adverse，严重不利）。将定性等级评估转换为数值，按照如下评分系统：对于$Cr_1,Cr_2,Cr_3$，$VB=20,B=15,N=10,A=5,SA=0$；对于$Cr_4,Cr_5$，$VB=16,B=13,N=10,A=7,SA=4$，因此决策矩阵为：$\begin{array}{|l|rrrrr|}
\hline & \text { Cr1 } & \text { Cr2 } & \text { Cr3 } & \text { Cr4 } & \text { Cr5 } \\
\hline \text { P1 } & 10 & 20 & 5 & 10 & 16 \\
\text { P2 } & 0 & 5 & 5 & 16 & 10 \\
\text { P3 } & 0 & 10 & 0 & 16 & 7 \\
\text { P4 } & 20 & 5 & 10 & 10 & 13 \\
\text { P5 } & 20 & 10 & 15 & 10 & 13 \\
\text { P6 } & 20 & 10 & 20 & 13 & 13 \\
\hline
\end{array}$。

第1步，计算满意度矩阵，公式为：$\begin{aligned} & \mathrm{C}(\mathrm{a}, \mathrm{b})=\frac{1}{\mathrm{~W}} \sum_{\forall \mathrm{j}: \mathrm{g}_{\mathrm{j}}(\mathrm{a}) \geq \mathrm{g}_{\mathrm{j}}(\mathrm{b})} \mathrm{w}_{\mathrm{j}} \\ & \mathrm{W}=\sum_{\mathrm{j}=1}^{\mathrm{n}} \mathrm{w}_{\mathrm{j}} \\ & \end{aligned}$，$W_j$为决策准则的权重，$\mathrm{a}, \mathrm{b}$为两两备选方案，$\mathrm{g}_{\mathrm{j}}(\mathrm{a})$和$\mathrm{g}_{\mathrm{j}}(\mathrm{b}) $为第$j$个决策准则列两两备选方案准则值，如果当前备选方案的决策准则值大于与其比较的备选方案准则值，则将第$j$个决策准则权重相加，并除以权重和。实验数据的满意度矩阵结果为：$\begin{bmatrix}
   1.000 &   0.900 &   0.900 &   0.400 &   0.400 &   0.300\\
   0.400 &   1.000 &   0.800 &   0.300 &   0.100 &   0.100\\
   0.100 &   0.600 &   1.000 &   0.300 &   0.300 &   0.300\\
   0.700 &   0.900 &   0.700 &   1.000 &   0.500 &   0.400\\
   0.700 &   0.900 &   0.900 &   1.000 &   1.000 &   0.600\\
   0.700 &   0.900 &   0.900 &   1.000 &   1.000 &   1.000
\end{bmatrix}$。

第2步，计算不满意度矩阵。对于$\mathrm{C}(\mathrm{a}, \mathrm{b})$的值位于[0.1]区间，测量备选方案$\mathrm{a}$优于备选方案$\mathrm{b}$的强度，然而，$\mathrm{a}$对$\mathrm{b}$的任何优势强度都可以被不满意度矩阵$D(a,b)$消弱或抵消，其公式为：$\begin{gathered}\mathrm{D}(\mathrm{a}, \mathrm{b})=0 \text { if } g_j(a) \geq g_j(b) \forall j \\ D(a, b)=\frac{1}{\delta} \max _{\mathrm{j}}\left[g_j(b)-g_j(a)\right] \\ \quad \delta=\max _{\mathrm{c}, \mathrm{d}, \mathrm{j}}\left[\mathrm{g}_{\mathrm{j}}(\mathrm{c})-\mathrm{g}_{\mathrm{j}}(\mathrm{d})\right]\end{gathered}$，为计算两两备选方案（$\mathrm{a}, \mathrm{b}$）比较下，各个对应决策准则值的差值（为比较项减当前项）的最大值除以$ \delta$；$ \delta$为所有两两备选方案的所有决策准则列对应的差值的最大值。实验数据的不满意度矩阵结果为：$\begin{bmatrix}
   0.000 &   0.300 &   0.300 &   0.500 &   0.500 &   0.750\\
   0.750 &   0.000 &   0.250 &   1.000 &   1.000 &   1.000\\
   0.500 &   0.250 &   0.000 &   1.000 &   1.000 &   1.000\\
   0.750 &   0.300 &   0.300 &   0.000 &   0.250 &   0.500\\
   0.500 &   0.300 &   0.300 &   0.000 &   0.000 &   0.250\\
   0.500 &   0.150 &   0.150 &   0.000 &   0.000 &   0.000
\end{bmatrix}$。

第3步，阈值（threshold），ELECTRE-I 的排名优势关系（outranking relationship）是通过比较具有指定限制（阈值）的满意度矩阵和不满意度矩阵来建立的。$\hat{\mathrm{c}}$为满意度阈值，最大值为1；$\hat{\mathrm{d}}$为不满意度阈值，最小值为0，因此有：$\mathrm{aSb} \text { iff } C(a, b) \geq \hat{\mathrm{c}} \text { and } \mathrm{D}(\mathrm{a}, \mathrm{b}) \leq \hat{\mathrm{d}}$，式中，$\mathrm{aSb}$表示备选方案$a$排名高于备选方案$b$，当满意度指数（矩阵）$C(a, b)$大于等于阈值$\hat{\mathrm{c}}$，且不满意度指数$D(a,b)$小于等于阈值$\hat{\mathrm{d}}$。

对于排名优势关系（结构）的比较有如下表述公式：

$\begin{aligned} &  \mathrm{aSb}\hspace{5pt} iff \hspace{5pt} \mathrm{aPb} \hspace{5pt} or \hspace{5pt} \mathrm{aIb} \\&
a P b \Leftrightarrow g(a)>g(b) \\&
\mathrm{aIb} \Leftrightarrow \mathrm{g}(\mathrm{a})=\mathrm{g}(\mathrm{b}) \\&
\forall \mathrm{a}, \mathrm{b} \in \mathrm{A} \\&
since \hspace{5pt} S=P \cup I, a S b \Leftrightarrow g(a) \geq g(b) \\&
aIb \hspace{5pt} and \hspace{5pt} bIc \Leftrightarrow aIc \end{aligned}$

配置不同的阈值，当$\hat{\mathrm{c}}=1.0$，$\hat{\mathrm{d}}=0.0$时，排名靠前的核心（kernel）备选方案由1、2、3和6组成（绿色标识），核心之外的为4和5备选方案。且可知$G(\hat{\mathrm{c}},\hat{\mathrm{d}})$排名图中，$P6>P4,P6>P5,P5>P4$，但$P1,P2,P3$之间及与其它方案之间则不可比较；

当$\hat{\mathrm{c}}=0.9$，$\hat{\mathrm{d}}=0.15$时，排名靠前的核心备选方案由1和6组成，除了$P6$和$P1$不可比之外，$P6$均高于其它备选方案；

当$\hat{\mathrm{c}}=0.7$，$\hat{\mathrm{d}}=0.5$时，排名靠前的核心备选方案仅有$P6$。


```python
W_proposed_motorway=[3,2,3,1,1]
proposed_motorway=np.array([
    [ 10, 20, 5, 10, 16],
    [ 0, 5, 5, 16, 10 ],
    [ 0, 10, 0, 16, 7 ],
    [ 20, 5, 10, 10, 13 ],
    [20, 10, 15, 10, 13 ],
    [ 20, 10, 20, 13, 13 ]
    ])

c_hat=1
d_hat=0 
concordance, discordance, dominance, kernel, dominated=usda_weight.electre_i(proposed_motorway, W = W_proposed_motorway, remove_cycles = True, c_hat = c_hat, d_hat = d_hat, graph = True)
```

<img src="./imgs/3_1/output_71_0.png" height='auto' width='auto' title="caDesign">
    



```python
c_hat=0.9
d_hat=0.15 
concordance, discordance, dominance, kernel, dominated=usda_weight.electre_i(proposed_motorway, W = W_proposed_motorway, remove_cycles = True, c_hat = c_hat, d_hat = d_hat, graph = True)
```

<img src="./imgs/3_1/output_72_0.png" height='auto' width='auto' title="caDesign">
    


```python
c_hat=0.7
d_hat=0.5 
concordance, discordance, dominance, kernel, dominated=usda_weight.electre_i(proposed_motorway, W = W_proposed_motorway, remove_cycles = True, c_hat = c_hat, d_hat = d_hat, graph = True)
```

<img src="./imgs/3_1/output_73_0.png" height='auto' width='auto' title="caDesign">
    



## 3.1.3 LST（降温）与绿地和建设用地矛盾的匹配评估

LST 地表温度数据和 NLCD 美国土地覆盖类型数据集，及对上述数据的处理参看“3.5 标记距离”一节，下述实验直接读取已经处理的数据。城市是人类聚居地，需要满足住房、交通、卫生、公用事业、经济活动和娱乐休闲等需求，又需要改善城市居住的环境，拥有更多的绿地、水体，同时平衡城市热岛效应，那么上述的需求就存在了矛盾，好的城市环境需要更多的绿地，而居住和经济活动等需要建设开发土地，那么对建成区的评估则是基于具有矛盾的多因子（决策准则）的权衡。该实验选择的因子包括 LST 地表温度（`temp`）、绿地栅格频数(`green_freq`)、水体栅格频数(`water_freq`)(含开放水体和湿地)、开发用地栅格频数(`developed_freq`)和耕地栅格频数(`cultivated_freq`)等5个决策准则。评估的对象（备选方案）为基于 LST 栅格精度提取的样方组，总共 2785 个样方。样方单元的大小为1000m。决策准则类型对应`temp`、`green_freq`、`water_freq`、`developed_freq`和`cultivated_freq`，为'min'、'max'、'max'、'max'和'min'。对应决策准则的权重值为0.2、0.3、0.1、0.3和0.1（权重和为1）。权重的配置上将绿地和建设用地全部配置为0.3，二者部分轻重，同时减小水体和耕地的权重比例，LST 保持在一个平均的值上。MCDM 选择 WASPAS 算法。


```python
# IPython extension to reload modules before executing user code.
%load_ext autoreload 
# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.
%autoreload 2 

from usda import geodata_process as usda_geodataProcess
from usda import weight as usda_weight

import rasterio as rio
import matplotlib.pyplot as plt
from rasterio.plot import show
import matplotlib
import geopandas as gpd
import pandas as pd
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    

### 3.1.3.1 数据预处理

土地覆盖合并类型由`LU_merge_dict`变量确定，在栅格单元统计分类频数时，按照提取的4大类，绿地、水体、开发用地和耕地计算。


```python
pt_leftBottom=[-88.41018,41.45427]
pt_rightTop=[-87.15433,41.69524] 

nlcd_class_idNcolor={
    '0':[0,"#64b3d5"],
    'Open_Water':[11,"#5475a8"],
    'Perennial_IceSnow':[12,"#ffffff"],
    'Developed_Open_Space':[21,"#e8d1d1"],
    'Developed_Low_Intensity':[22,"#e29e8c"],
    'Developed_Medium_Intensity':[23,"#ff0000"],
    'Developed_High_Intensity':[24,"#b50000"],
    'Barren_Land_RockSandClay) ':[31,"#d2cdc0"],
    'Deciduous_Forest':[41,'#85c77e'],
    'Evergreen_Forest':[42,"#38814e"],
    'Mixed Fores':[43,"#d4e7b0"],
    'Dwarf_Scrub':[51,"#af963c"],
    'Shrub_Scrub':[52,"#dcca8f"],
    'Grassland_Herbaceous':[71,"#fde9aa"],
    'Sedge_Herbaceous':[72,"#d1d182"],
    'Lichens':[73,"#a3cc51"],
    'Moss':[74,"#82ba9e"],
    'Pasture_Hay':[81,"#fbf65d"],
    'Cultivated_Crops':[82,"#ca9146"],
    'Woody_Wetlands':[90,"#c8e6f8"],
    'Emergent_Herbaceous_Wetlands':[95,"#64b3d5"],    
    }

nlcd_class_color={v[0]:v[1] for v in nlcd_class_idNcolor.values()}
cmap_LC, norm=matplotlib.colors.from_levels_and_colors(list(nlcd_class_color.keys()),list(nlcd_class_color.values()),extend='max')
cmap_LC

chicago_nlcd_2019_lc_reproj_fn=r'E:\data\NLCD_landcover_2019_release_all_files_20210604\clipped\chicago_nlcd_2019_lc_4326.tif'
with rio.open(chicago_nlcd_2019_lc_reproj_fn) as src:    
    epsg_chicago=src.crs
    transform_chicago=src.transform
    
chicago_pt_leftBottom_pj=usda_geodataProcess.pt_coordi_transform(4326,epsg_chicago,pt_leftBottom)
chicago_pt_rightTop_pj=usda_geodataProcess.pt_coordi_transform(4326,epsg_chicago,pt_rightTop)      

Chicago_LC_reproj,Chicago_reproj_transform,Chicago_reproj_ras_meta=usda_geodataProcess.rio_read_subset(chicago_nlcd_2019_lc_reproj_fn,[chicago_pt_leftBottom_pj,chicago_pt_rightTop_pj])  

LST_shp_fn=r'E:\data\LST\LST_Chicago\LST_Chicago.shp'   
LST_gdf=gpd.read_file(LST_shp_fn)

f, ax=plt.subplots(figsize=(20,20))
show(Chicago_LC_reproj,ax=ax,transform=Chicago_reproj_transform,cmap=cmap_LC,norm=norm)
LST_gdf.plot(color='none',edgecolor='k',linewidth=1,ax=ax,linestyle='--')
plt.show()    
```

<img src="./imgs/3_1/output_77_0.png" height='auto' width='auto' title="caDesign">
    


```python
lc_stats=usda_geodataProcess.zonal_stats_raster(chicago_nlcd_2019_lc_reproj_fn,LST_gdf,band=1,stats=['majority'],add_stats=['frequency'])
```


```python
lc_stats.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>temp</th>
      <th>geometry</th>
      <th>majority</th>
      <th>index</th>
      <th>frequency_21</th>
      <th>frequency_22</th>
      <th>frequency_23</th>
      <th>frequency_81</th>
      <th>frequency_24</th>
      <th>frequency_41</th>
      <th>frequency_82</th>
      <th>frequency_71</th>
      <th>frequency_42</th>
      <th>frequency_43</th>
      <th>frequency_90</th>
      <th>frequency_11</th>
      <th>frequency_31</th>
      <th>frequency_95</th>
      <th>frequency_52</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15166</td>
      <td>POLYGON ((-88.40252 41.69121, -88.39287 41.691...</td>
      <td>21.0</td>
      <td>0</td>
      <td>318.0</td>
      <td>303.0</td>
      <td>122.0</td>
      <td>21.0</td>
      <td>19.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15191</td>
      <td>POLYGON ((-88.39287 41.69121, -88.38322 41.691...</td>
      <td>22.0</td>
      <td>0</td>
      <td>162.0</td>
      <td>163.0</td>
      <td>54.0</td>
      <td>159.0</td>
      <td>11.0</td>
      <td>135.0</td>
      <td>44.0</td>
      <td>30.0</td>
      <td>15.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15245</td>
      <td>POLYGON ((-88.38322 41.69121, -88.37356 41.691...</td>
      <td>22.0</td>
      <td>0</td>
      <td>117.0</td>
      <td>218.0</td>
      <td>208.0</td>
      <td>1.0</td>
      <td>70.0</td>
      <td>52.0</td>
      <td>24.0</td>
      <td>79.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>9.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
import warnings
warnings.filterwarnings('ignore')

LU_merge_dict=dict(green_lst=[21,41,42,43,51,52,71,72,73,74],
                   water_lst=[11,12,90,95],
                   developed_lst=[22,23,24],
                   cultivated_lst=[81,82])

def LC_fre_merge_func(row,args):
    cols=[i for i in  row.index if i.split('_')[0]=='frequency']
    LU_merged_cols={}
    for k,v in args.items():
        lu_cols=[i for i in cols if int(i.split('_')[1]) in v]
        freq_sum=row[lu_cols].sum()
        LU_merged_cols[k]=freq_sum
    return pd.Series(LU_merged_cols.values())    
    
lc_stats_copy=lc_stats.copy(deep=True)
reclassify=['green_freq','water_freq','developed_freq','cultivated_freq']
lc_stats_copy[reclassify]=lc_stats_copy.apply(LC_fre_merge_func,args=(LU_merge_dict,),axis=1)
criteria_df=lc_stats_copy[['temp']+reclassify]+1
criteria_df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>temp</th>
      <th>green_freq</th>
      <th>wet_lands_freq</th>
      <th>developed_freq</th>
      <th>cultivated_freq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15167</td>
      <td>320.0</td>
      <td>1.0</td>
      <td>445.0</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15192</td>
      <td>349.0</td>
      <td>5.0</td>
      <td>229.0</td>
      <td>204.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15246</td>
      <td>249.0</td>
      <td>15.0</td>
      <td>497.0</td>
      <td>26.0</td>
    </tr>
  </tbody>
</table>
</div>



### 3.1.3.2  WASPAS 算法评估样方单元综合评价指数

WASPAS 为聚合加权的和积估计（ Weighted aggregated sum product assessment），具体的方法为：

第1步，构建决策矩阵，为上述数据预处理后`criteria_df`变量结果；

第2步，标准化决策矩阵，对于决策类型为`max`的决策准则使用公式： $x^{\prime}(i, j)= 1+\frac{x(i, j)-min(x_j)}{max(x_j)-min(x_j)} $；对于决策类型为`min`的使用公式： $x^{\prime}(i, j)= \frac{max(x_j)-x(i, j)}{max(x_j)-min(x_j)}$ ；

第3步，第$i$个备选方案的第1个相对权重（重要性）类似 WSM 技术，有公式：$Q^{(1)}_i= \sum_{j=1}^n  X_{i,j} W_{j}    $，为第$j$个决策准则权重值与第$i$个备选方案测量值之积的和。另一方面，第$i$个备选方案的第2个相对权重类似 WPM 技术，有公式：$Q^{(2)}_i= \prod_{j=1}^n   X_{i,j}^{W_{j} }$，为第$i$个备选方案测量值的第$j$个决策准则权重值幂的乘积；

第4步，计算第$i$个备选方案综合相对权重，公式为：$Q_i= \lambda Q^{(1)}_i+(1- \lambda )Q^{(2)}_i$，式中$\lambda$ 为组合参数，位于[0,1]之间，如果值为0，则为WPM方法；如果值为1，则为WSM方法。$\lambda$ 用于弥补 MCDM 在排名精度上的问题。

迁移`pyDecision`库的`waspas_method`方法至`USDA`库，计算结果如下。


```python
weights=[0.2,0.3,0.1,0.3,0.1]
criterion_type=['min','max','max','max','min']
lambda_value=0.5
wsm, wpm, waspas=usda_weight.waspas_method(criteria_df.to_numpy(), criterion_type, weights, lambda_value)
```


```python
LST_gdf['waspas']=waspas
```


```python
from mpl_toolkits.axes_grid1 import make_axes_locatable
fig, ax=plt.subplots(1, 1,figsize=(20,10),)
divider=make_axes_locatable(ax)
cax=divider.append_axes("right", size="5%", pad=0.1)
LST_gdf.plot(column='waspas',legend=True,cax=cax, cmap='hot',ax=ax);
```

<img src="./imgs/3_1/output_84_0.png" height='auto' width='auto' title="caDesign">
    
    


---

注释（Notes）：

① InVEST，（<https://naturalcapitalproject.stanford.edu/software/invest>）。

② 多准则决策法相关软件，（<https://en.wikipedia.org/wiki/Decision-making_software#Comparison_of_decision-making_software>）。

③ pyDecision（Python包），用于多准则决策法计算，（<https://github.com/Valdecy/pyDecision>）。

④ Google Developers Console_Street View Static API，（<https://console.cloud.google.com/apis/dashboard?pli=1&project=gsv-streetscape>）。

⑤ istreetview，（<https://istreetview.com>）。

⑥ Street View Download 360，（<https://svd360.istreetview.com>）。

⑦ mayavi，（<https://docs.enthought.com/mayavi/mayavi>）。

⑧ pyDecision工具包的示例文件，（<https://github.com/Valdecy/pyDecision>）。 

参考文献（References）:

[1] Gal, T., Stewart, T.J. and Hanne, T. (1999) Multicriteria decision making: Advances in MCDM models, algorithms, theory, and applications. Boston, MA: Kluwer academic.

[2] Rezaei, J. Best-worst multi-criteria decision-making method. Omega (United Kingdom) 53, 49–57 (2015).

[3] 黎家琦,武雪玲,唐诗怡.压力-状态-响应模型下的生态敏感性分析算法[J].测绘科学,2020,45(11):75-83+106.DOI:10.16251/j.cnki.1009-2307.2020.11.012.

[4] 张金茜,李红瑛,曹二佳,巩杰.多尺度流域生态脆弱性评价及其空间关联性——以甘肃白龙江流域为例[J].应用生态学报,2018,29(09):2897-2906.DOI:10.13287/j.1001-9332.201809.008.

[5] Solecka, I., Rinne, T., Caracciolo Martins, R., Kytta, M. & Albert, C. Important places in landscape – investigating the determinants of perceived landscape value in the suburban area of Wrocław, Poland. Landsc Urban Plan 218, 104289 (2022).

[6] Boroushaki, S. Entropy-Based Weights for MultiCriteria Spatial Decision-Making. Yearbook of the Association of Pacific Coast Geographers 79, 168–187 (2017).

[7] Malczewski, J. GIS-based multicriteria decision analysis: A survey of the literature. International Journal of Geographical Information Science 20, 703–726 (2006).

[8] Malczewski, J. & Rinner, C. Advances in Geographic Information Science Multicriteria Decision Analysis in Geographic Information Science. http://www.springer.com/series/7712.

[9] Hwang, C.-L., and K. Yoon. 1981. Multiple Attribute Decision Making. Methods and Applications A State-of-the-Art Survey. Berlin: Springer-Verlag.

[10] Saaty, T. L. & Katz, J. M. How to make a decision: The Analytic Hierarchy Process. European Journal of Operational Research vol. 48 (1990).

[11] Ayhan, M. B. A Fuzzy Ahp Approach For Supplier Selection Problem: A Case Study In A Gearmotor Company. International Journal of Managing Value and Supply Chains 4, 11–23 (2013).

[12] Zavadskas, E. K. & Turskis, Z. A new additive ratio assessment (ARAS) method in multicriteria decision-making. Technological and Economic Development of Economy 16, 159–172 (2010).

[13] Par M. SUR LES ÉLECTIONS AU SCRUTIN *. Des sciences (1781).

[14] Keshavarz-Ghorabaee, M., Zavadskas, E., Turskis, Z., & Antucheviciene, J. (2016). A new combinative distance-based assessment (CODAS) method for multi-criteria decision-making. Economic Computation and Economic Cybernetics Studies and Research / Academy of Economic Studies, 50, 25–44.

[15] Razavi Hajiagha, S. H., Hashemi, S. S. & Zavadskas, E. K. A complex proportional assessment method for group decision making in an interval-valued intuitionistic fuzzy environment. Technological and Economic Development of Economy 19, 22–37 (2013).

[16] Diakoulaki,~’~:, D., Mavrotas, G. & Papayannakis, L. DETERMINING OBJECTIVE WEIGHTS IN MULTIPLE CRITERIA PROBLEMS: THE CRITIC METHOD. Computers Ops Res vol. 22 (1995).

[17] Si, S. L., You, X. Y., Liu, H. C. & Zhang, P. DEMATEL Technique: A Systematic Review of the State-of-the-Art Literature on Methodologies and Applications. Mathematical Problems in Engineering vol. 2018 Preprint at https://doi.org/10.1155/2018/3696457 (2018).

[18] Wu, W.-W., & Lee, Y.-T. (2007). Developing global managers’ competencies using the fuzzy DEMATEL method. Expert Systems with Applications, 32(2), 499–507. doi:10.1016/j.eswa.2005.12.005

[19] Mehdi Keshavarz Ghorabaee, Edmundas Kazimieras Zavadskas, Laya Olfat, Zenonas Turskis, Multi-Criteria Inventory Classification Using a New Method of Evaluation Based on Distance from Average Solution (EDAS), Informatica 26(2015), no. 3, 435-451, DOI 10.15388/Informatica.2015.57

[20] Zindani, D., Maity, S. R., & Bhowmik, S. (2019). Fuzzy-EDAS (Evaluation Based on Distance from Average Solution) for Material Selection Problems. In R. G. Narayanan, S. N. Joshi, & U. S. Dixit (Eds.), Advances in Computational Methods in Manufacturing (pp. 755–771). Singapore: Springer Singapore.

[21] par B. ROY.Classement et choix en presence de points de vue multiples. 8, 57-75 (1968) 

[22] Rogers, M., Bruen, M., & Maystre, L.-Y. (2000). The Electre Methodology. In ELECTRE and Decision Support: Methods and Applications in Engineering and Infrastructure Investment (pp. 45–85). doi:10.1007/978-1-4757-5057-7_3

[23] B.BOY. Un algorithme de classemeuts fonde sur une representation floue des preferences en presence de cr1teres multiples.1978. 

[24] Wei Yu. Aide multicritère à la décision dans le cadre de la problématique du tri Concepts, méthodes et applications.Thèse pour ('obtention du titre de Docteur en Méthodes Scientifiques de Gestion). 1992.

[25] Ju-Long, D. (1982). Control problems of grey systems. Systems & Control Letters, 1(5), 288–294. doi:10.1016/S0167-6911(82)80025-X

[26] Alinezhad, A., & Khalili, J. (2019). IDOCRIW Method. In New Methods and Applications in Multiple Attribute Decision Making (MADM) (pp. 133–141). doi:10.1007/978-3-030-15009-9_19

[27] Pamučar, D. & Ćirović, G. The selection of transport and handling resources in logistics centers using Multi-Attributive Border Approximation area Comparison (MABAC). Expert Syst Appl 42, 3016–3028 (2015).

[28] Detlof V. Winterfeldt, Gregory W.Fischer. Multi-attribute utility theory: models and assessment procedures. Office of Naval Research Advanced Research Projects Agency, 1973.11.

[29] Karel, W., Brauers, W., & Zavadskas, E. (01 2006). The MOORA method and its application to privatization in a transition economy. Control and Cybernetics, 35.

[30] Ray, A. GREEN CUTTING FLUID SELECTION USING MOOSRA METHOD. IJRET: International Journal of Research in Engineering and Technology http://www.ijret.org.

[31] Brauers, W. K. M. & Zavadskas, E. K. Project management by multimoora as an instrument for transition economies. Technological and Economic Development of Economy 16, 5–24 (2010).

[32] Brans, J.-P., & Mareschal, B. (2005). Promethee Methods. In Multiple Criteria Decision Analysis: State of the Art Surveys (pp. 163–186). doi:10.1007/0-387-23081-5_5

[33] Alinezhad, A., & Khalili, J. (2019). PROMETHEE I-II-III Methods. In New Methods and Applications in Multiple Attribute Decision Making (MADM) (pp. 29–39). doi:10.1007/978-3-030-15009-9_5

[34] Panjaitan, M. I. Login : Jurnal Teknologi Komputer Simple Additive Weighting (SAW) method in Determining Beneficiaries of Foundation Benefits. Jl. Kol. Yos Sudarso No.45 AB 13, 19–25 (2019).

[35] Olson, D. L. (1996). Smart. In Decision Aids for Selection Problems (pp. 34–48). doi:10.1007/978-1-4612-3982-6_4

[36] Yoon, K. (1987). A Reconciliation Among Discrete Compromise Solutions. Journal of the Operational Research Society, 38(3), 277–286. doi:10.1057/jors.1987.44

[36] Nădăban, S., Dzitac, S., & Dzitac, I. (2016). Fuzzy TOPSIS: A General View. Procedia Computer Science, 91, 823–831. doi:10.1016/j.procs.2016.07.088

[38] Thakkar, J. J. (2021). VIseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR). In Multi-Criteria Decision Making (pp. 129–138). doi:10.1007/978-981-33-4745-8_8

[39] Opricovic, S. (2011). Fuzzy VIKOR with an application to water resources planning. Expert Systems with Applications, 38(10), 12983–12990. doi:10.1016/j.eswa.2011.04.097

[40] Michnik, J. (2013). Weighted Influence Non-linear Gauge System (WINGS) – An analysis method for the systems of interrelated components. European Journal of Operational Research, 228(3), 536–544. doi:10.1016/j.ejor.2013.02.007

[41] Thakkar, J. J. (2021). Weighted Aggregated Sum Product Assessment (WASPAS). In Multi-Criteria Decision Making (pp. 253–279). doi:10.1007/978-981-33-4745-8_15

[42] Donegan, H. A. & Dodd, F. J. A NOTE ON SAATY’S RANDOM INDEXES. Mathl. Comput. Modelling vol. 15 (1991).

[43] Kahraman, C., Cebeci, U. & Ruan, D. Multi-attribute comparison of catering service companies using fuzzy AHP: The case of Turkey. Int J Prod Econ 87, 171–184 (2004).

[44] Chou, S. W. & Chang, Y. C. The implementation factors that influence the ERP (enterprise resource planning) benefits. Decis Support Syst 46, 149–157 (2008).

[45] Mirjalili, S., Mirjalili, S. M. & Lewis, A. Grey Wolf Optimizer. Advances in Engineering Software 69, 46–61 (2014).
