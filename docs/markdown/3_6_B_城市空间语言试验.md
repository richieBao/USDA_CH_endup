> Created on Sun Jul  2 21:35:07 2023 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.6-B 城市空间“语言”试验

## 3.6.1 基于 LULC 嵌入向量空间 Transformers 视觉模型的地表温度预测可行性试验

### 3.6.1.1 数据准备

#### 1) ESA WorldCover（LULC） 数据下载

欧空局（European Space Agency，ESA）基于 Sentinel-1 和 2 发布了 10 m高空分辨率 [2020年](https://worldcover2020.esa.int/)<sup>①</sup>和[2021年](https://worldcover2021.esa.int/)<sup>②</sup>的全球土地覆盖产品（WorldCover），该产品包含10个分类类别，为林地（Tree Cover）、灌木丛（Shrubland）、草地（Grassland）、农田（Cropland）、建成区（Built-up）、裸地/稀疏植被（Bare / sparse vegetation）、冰雪（Snow and Ice）、永久水体（Permanent water bodies）、草本湿地（Herbaceous Wetland）、苔藓和地衣（Moss and lichen）等10类，并增加有红树林（Mangrove）类，计有11类，其总体精度为77%（独立验证），使用投影 EPSG 编号为4326，即 WGS1984（World Geodetic System of 1984） 的地理坐标系统。

此次试验的研究范围为伦敦区域，为了能够下载指定区域的 WorldCover 数据，需要先下载 WorldCover 的瓦片网格，由指定区域提取对应的瓦片信息后，确定下载文件路径进行下载。 WorldCover数据的详细说明和下载代码示例可以从其[产品使用手册（Product User Manual）](https://github.com/microsoft/PlanetaryComputerExamples/blob/main/datasets/esa-worldcover/esa-worldcover-example.ipynb)<sup>③</sup>中获取。


```python
%load_ext autoreload 
%autoreload 2 
%reload_ext autoreload
import usda.models as usda_models
import usda.geodata_process as usda_geodataProcess # conda install gdal; pip install geopandas;
import usda.datasets as usda_datasets
import usda.data_visual as usda_datavisual

import matplotlib.pyplot as plt
import pystac_client
import planetary_computer
import rich.table
import rioxarray as rxr
import os
import rasterio as rio
import matplotlib as mpl
from rasterio.plot import show
import copy
from IPython.display import Image,display

import geopandas as gpd
import mapclassify
import pickle

from torchvision import transforms
import torch
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
import torchvision
import numpy as np

import pytorch_lightning as pl
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
```

    

* 从欧空局下载 WorldCover 数据

下载 WorldCover 瓦片网格，并转换为 GeoDataFrame 数据格式。为了直观查看瓦片网格的全球分布情况，定义一个随机的颜色映射打印显示地图。定义`esa_worldcover_2020_grid_downloading()`函数实现。


```python
wc_grid,ranodm_cmap=usda_datasets.esa_worldcover_2020_grid_downloading(show=True)
```


<img src="./imgs/3_6_b/output_4_0.png" height='auto' width='auto' title="caDesign">   


查看 WorldCover 瓦片网格，其字段包含一个几何对象和一个 ID 索引。


```python
wc_grid.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>ll_tile</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2628</th>
      <td>POLYGON ((-144.00000 -27.66528, -144.00530 -27...</td>
      <td>S30W147</td>
    </tr>
    <tr>
      <th>2629</th>
      <td>POLYGON ((-177.00000 -44.08407, -177.02234 -44...</td>
      <td>S45W180</td>
    </tr>
    <tr>
      <th>2630</th>
      <td>POLYGON ((-177.00000 -43.54951, -176.99759 -43...</td>
      <td>S45W177</td>
    </tr>
  </tbody>
</table>
</div>



定义`esa_worldcover_downloading()`函数实现根据指定区域`(左下角经度，左下角纬度，右上角经度，右上角纬度)`下载 WorldCover 数据。


```python
london_bounds=(-1,51.15,1,52)
save_root=r'I:\data\ESA_London'

url_lst,fns,tiles=usda_datasets.esa_worldcover_downloading(london_bounds,save_root,y='2020')
print(url_lst)
```

    100%|█████████████████████████████████████████████████████████████████████████| 2/2 [03:26<00:00, 103.19s/it]

    ['https://esa-worldcover.s3.eu-central-1.amazonaws.com/v100/2020/map/ESA_WorldCover_10m_2020_v100_N51E000_Map.tif', 'https://esa-worldcover.s3.eu-central-1.amazonaws.com/v100/2020/map/ESA_WorldCover_10m_2020_v100_N51W003_Map.tif']
    

    
    

查看返回的 WorldCover 瓦片区域。


```python
fig, ax=plt.subplots(figsize=(5,5))
tiles.plot(column='ll_tile',cmap=ranodm_cmap,ax=ax)
fig.patch.set_visible(False)
ax.axis('off')
plt.show()
```


<img src="./imgs/3_6_b/output_10_0.png" height='auto' width='auto' title="caDesign">    


* 从[Planetary Computer Hub（PcHub）](https://github.com/microsoft/PlanetaryComputerExamples/blob/main/datasets/esa-worldcover/esa-worldcover-example.ipynb)<sup>④</sup>下载 WorldCover 数据或查看信息<sup>[1]</sup>

根据指定的范围搜索 WorldCover 数据，返回对应瓦片的 ID。

> 也可以从提供的数据手册中获得信息。


```python
catalog=pystac_client.Client.open("https://planetarycomputer.microsoft.com/api/stac/v1",modifier=planetary_computer.sign_inplace,)
search=catalog.search(collections=["esa-worldcover"],bbox=london_bounds)
items=list(search.get_items())
items
```




    [<Item id=ESA_WorldCover_10m_2021_v200_N51W003>,
     <Item id=ESA_WorldCover_10m_2021_v200_N51E000>,
     <Item id=ESA_WorldCover_10m_2020_v100_N51W003>,
     <Item id=ESA_WorldCover_10m_2020_v100_N51E000>]



查看数据属性相关信息。


```python
# Metadata
t_metadata = rich.table.Table("Key", "Value")
for k, v in sorted(items[0].properties.items()):
    t_metadata.add_row(k, str(v))
t_metadata
```




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Key                            </span>┃<span style="font-weight: bold"> Value                                              </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ created                        │ 2023-04-06T16:31:45.847838Z                        │
│ datetime                       │ None                                               │
│ description                    │ ESA WorldCover product at 10m resolution           │
│ end_datetime                   │ 2021-12-31T23:59:59Z                               │
│ esa_worldcover:product_tile    │ N51W003                                            │
│ esa_worldcover:product_version │ 2.0.0                                              │
│ grid:code                      │ ESAWORLDCOVER-N51W003                              │
│ instruments                    │ ['c-sar', 'msi']                                   │
│ mission                        │ sentinel-1, sentinel-2                             │
│ platform                       │ sentinel-1a, sentinel-1b, sentinel-2a, sentinel-2b │
│ proj:epsg                      │ 4326                                               │
│ start_datetime                 │ 2021-01-01T00:00:00Z                               │
└────────────────────────────────┴────────────────────────────────────────────────────┘
</pre>




从数据集中获取分类信息和类别颜色配置值。


```python
class_list=items[0].assets["map"].extra_fields["classification:classes"]
classmap={c["value"]: {"description": c["description"], "hex": c["color-hint"]} for c in class_list}
t=rich.table.Table("Value", "Description", "Hex Color")
for k, v in classmap.items():
    t.add_row(str(k), v["description"], v["hex"])
t
```




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Value </span>┃<span style="font-weight: bold"> Description              </span>┃<span style="font-weight: bold"> Hex Color </span>┃
┡━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 10    │ Tree cover               │ 006400    │
│ 20    │ Shrubland                │ FFBB22    │
│ 30    │ Grassland                │ FFFF4C    │
│ 40    │ Cropland                 │ F096FF    │
│ 50    │ Built-up                 │ FA0000    │
│ 60    │ Bare / sparse vegetation │ B4B4B4    │
│ 70    │ Snow and ice             │ F0F0F0    │
│ 80    │ Permanent water bodies   │ 0064C8    │
│ 90    │ Herbaceous wetland       │ 0096A0    │
│ 95    │ Mangroves                │ 00CF75    │
│ 100   │ Moss and lichen          │ FAE6A0    │
└───────┴──────────────────────────┴───────────┘
</pre>




建立用于土地覆盖地图打印的相关信息，包括分类颜色的映射`cmap`、用于图例的分类值`values`、边界`boundaries`、刻度`ticks`和标签`tick_labels`等。定义`worldcover_cmap4plot()`函数完成计算。


```python
cmap,values,boundaries,ticks,tick_labels=usda_datavisual.worldcover_cmap4plot()
cmap
```


<img src="./imgs/3_6_b/3_6_b_06.png" height='auto' width='auto' title="caDesign">



打开从欧空局下载的 WorldCover 数据，示例中仅打开了一个瓦片。


```python
fns
```




    ['I:\\data\\ESA_London\\ESA_WorldCover_10m_2020_v100_N51E000_Map.tif',
     'I:\\data\\ESA_London\\ESA_WorldCover_10m_2020_v100_N51W003_Map.tif']




```python
london_esa=rxr.open_rasterio(fns[1],masked=True).squeeze()
london_esa
```

    <xarray.DataArray (y: 36000, x: 36000)>
    [1296000000 values with dtype=float32]
    Coordinates:
        band         int32 1
      * x            (x) float64 -3.0 -3.0 -3.0 ... -0.0002083 -0.000125 -4.167e-05
      * y            (y) float64 54.0 54.0 54.0 54.0 54.0 ... 51.0 51.0 51.0 51.0
        spatial_ref  int32 0
    Attributes: (12/18)
        algorithm_version:   V1.0.0
        AREA_OR_POINT:       Area
        copyright:           ESA WorldCover project 2020 / Contains modified Cope...
        creation_time:       2021-10-12 16:51:26.705020
        legend:              10  Tree cover\n    20  Shrubland\n    30  Grassland...
        license:             CC-BY 4.0 - https://creativecommons.org/licenses/by/...
        ...                  ...
        reference:           https://esa-worldcover.org
        time_end:            2020-12-31T23:59:59Z
        time_start:          2020-01-01T00:00:00Z
        title:               ESA WorldCover product at 10m resolution for year 2020
        scale_factor:        1.0
        add_offset:          0.0




```python
london_esa.rio.crs
```




    CRS.from_epsg(4326)



由返回的打印相关信息打印 WorldCover 土地覆盖分类地图。


```python
fig, ax = plt.subplots(figsize=(16, 14))
normalizer = matplotlib.colors.Normalize(vmin=0, vmax=255)

xy_0=14000
delta=3000
london_esa.isel(y=slice(xy_0, xy_0+delta), x=slice(xy_0,xy_0+delta)).plot(ax=ax, cmap=cmap, norm=normalizer)

colorbar=fig.colorbar(
    cm.ScalarMappable(norm=normalizer, cmap=cmap),
    boundaries=boundaries,
    values=values,
    cax=fig.axes[1].axes,
)
colorbar.set_ticks(ticks, labels=tick_labels)

ax.set_axis_off()
ax.set_title("ESA WorldCover at London");
```


<img src="./imgs/3_6_b/output_24_0.png" height='auto' width='auto' title="caDesign">    
    


#### 2) 地表温度（Land Surface Temperature，LST）数据

关于地表温度（LST）数据信息可以查看*标记距离*一章，这里从 Planetary Computer Hub 处下载。下载前，通过搜索给定下载区域和数据时段获得满足要求的数据 ID 等相关信息。因为 WorldCover 数据使用的为2020年，因此 LST 选择了同一年份，但仅使用了8月份的数据。


```python
time_range = "2020-08-07/2020-08-08"

catalog=pystac_client.Client.open("https://planetarycomputer.microsoft.com/api/stac/v1",modifier=planetary_computer.sign_inplace,)
search=catalog.search(collections=["modis-11A2-061"],bbox=london_bounds,datetime=time_range)

items=search.get_all_items()
list(items)
```




    [<Item id=MYD11A2.A2020217.h18v03.061.2021013233159>,
     <Item id=MYD11A2.A2020217.h17v03.061.2021013233157>,
     <Item id=MOD11A2.A2020217.h18v03.061.2021013224226>,
     <Item id=MOD11A2.A2020217.h17v03.061.2021013223600>]



查看 LST 数据属性信息，如下。


```python
items[0].properties
```




    {'created': '2021-01-13T23:31:59Z',
     'updated': '2021-01-13T17:38:42.615000Z',
     'datetime': None,
     'platform': 'aqua',
     'proj:epsg': None,
     'proj:wkt2': 'PROJCS["unnamed",GEOGCS["Unknown datum based upon the custom spheroid",DATUM["Not specified (based on custom spheroid)",SPHEROID["Custom spheroid",6371007.181,0]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]]],PROJECTION["Sinusoidal"],PARAMETER["longitude_of_center",0],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["Meter",1],AXIS["Easting",EAST],AXIS["Northing",NORTH]]',
     'proj:shape': [1200, 1200],
     'instruments': ['modis'],
     'end_datetime': '2020-08-11T23:59:59Z',
     'modis:tile-id': '51018003',
     'proj:geometry': {'type': 'Polygon',
      'coordinates': [[[1111950.519767, 5559752.598833],
        [1111950.519767, 6671703.118599],
        [0.0, 6671703.118599],
        [0.0, 5559752.598833],
        [1111950.519767, 5559752.598833]]]},
     'proj:transform': [926.6254331391667,
      0.0,
      0.0,
      0.0,
      -926.6254331383334,
      6671703.118599],
     'start_datetime': '2020-08-04T00:00:00Z',
     'modis:vertical-tile': 3,
     'modis:horizontal-tile': 18}



查看 LST 数据层信息，如下。其中，`LST_Day_1km`为地表温度数据层。


```python
table = rich.table.Table("Asset Key", "Description")
for asset_key, asset in items[0].assets.items():
    table.add_row(asset_key, asset.title)

table
```




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Asset Key        </span>┃<span style="font-weight: bold"> Description                                                     </span>┃
┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ hdf              │ Source data containing all bands                                │
│ QC_Day           │ Quality control for daytime LST and emissivity                  │
│ Emis_31          │ Band 31 emissivity                                              │
│ Emis_32          │ Band 32 emissivity                                              │
│ QC_Night         │ Quality control for nighttime LST and emissivity                │
│ metadata         │ Federal Geographic Data Committee (FGDC) Metadata               │
│ LST_Day_1km      │ 8-day daytime 1km grid Landsurface Temperature                  │
│ Day_view_angl    │ Average view zenith angle of daytime Land-surface Temperature   │
│ Day_view_time    │ Average time of daytime Landsurface Temperature observation     │
│ LST_Night_1km    │ 8-day nighttime 1km grid Landsurface Temperature                │
│ Clear_sky_days   │ the days in clear-sky conditions and with validate LSTs         │
│ Night_view_angl  │ View zenith angle of nighttime Land-surface Temperature         │
│ Night_view_time  │ Average view zenith angle of nighttime Land-surface Temperature │
│ Clear_sky_nights │ the nights in clear-sky conditions and with validate LSTs       │
│ tilejson         │ TileJSON with default rendering                                 │
│ rendered_preview │ Rendered preview                                                │
└──────────────────┴─────────────────────────────────────────────────────────────────┘
</pre>




打印 LST 数据，确定为所选区域的数据。


```python
print(items[1].assets.keys())
im_01=Image(url=items[1].assets["rendered_preview"].href,width=500)
im_02=Image(url=items[0].assets["rendered_preview"].href,width=500)

display(im_01, im_02)
```

    dict_keys(['hdf', 'QC_Day', 'Emis_31', 'Emis_32', 'QC_Night', 'metadata', 'LST_Day_1km', 'Day_view_angl', 'Day_view_time', 'LST_Night_1km', 'Clear_sky_days', 'Night_view_angl', 'Night_view_time', 'Clear_sky_nights', 'tilejson', 'rendered_preview'])
    

<img src="./imgs/3_6_b/3_6_b_02.png" height='auto' width=500 title="caDesign"> <img src="./imgs/3_6_b/3_6_b_01.png" height='auto' width=500 title="caDesign">

通过查看`LST_Day_1km`层数据，可以发现字段`href`提供了下载地址，根据该地址下载数据。


```python
items[0].assets['LST_Day_1km']
```

      href "https://modiseuwest.blob.core.windows.net/modis-061-cogs/MYD11A2/18/03/2020217/MYD11A2.A2020217.h18v03.061.2021013233159_LST_Day_1km.tif?st=2023-07-06T04%3A10%3A39Z&se=2023-07-07T04%3A55%3A39Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-07-07T00%3A49%3A38Z&ske=2023-07-14T00%3A49%3A38Z&sks=b&skv=2021-06-08&sig=AReev5kZKP4CyN3Jj0oQsCU3lvNp%2B8puqGbTreSdDVA%3D"
      type "image/tiff; application=geotiff; profile=cloud-optimized"
      title "8-day daytime 1km grid Landsurface Temperature"
      raster:bands [] 1 items
      0
      unit "Kelvin"
      scale 0.02
      data_type "uint16"
      spatial_resolution 1000
      roles [] 2 items
      0 "data"
      1 "temperature"


```python
url_lst=[]
for item in items:
    url_lst.append(item.assets['LST_Day_1km'].href)
save_root=r'E:\data\LST\LST_London'
fns=[]
i=0
for url in tqdm(url_lst):    
    r = requests.get(url, allow_redirects=True)
    out_fn = os.path.join(save_root,f"LST_{i}.tif")
    fns.append(out_fn)
    with open(out_fn, 'wb') as f:
        f.write(r.content)
    i+=1
```

    100%|██████████████████████████████████████████████████████████████████████████| 4/4 [02:15<00:00, 33.92s/it]
    

使用`USDA`库的`raster_mosaic()`函数合并下载的 LST 数据。


```python
fns=['E:\\data\\LST\\LST_London\\LST_0.tif',
     'E:\\data\\LST\\LST_London\\LST_1.tif',
     'E:\\data\\LST\\LST_London\\LST_2.tif',
     'E:\\data\\LST\\LST_London\\LST_3.tif']

lst_mosaic_fn=os.path.join(save_root,'lst_london.tif')
usda_geodataProcess.raster_mosaic(r'E:\data\LST\LST_London\LST_london',lst_mosaic_fn)
```




    Affine(926.6254331391667, 0.0, -1111950.519767,
           0.0, -926.6254331383334, 6671703.118599)



根据 WorldCover 一个瓦片的边界读取合并的 LST 数据。因为 WorldCover 和 LST 的投影不同，因此使用`pt_coordi_transform`方法转换统一边界坐标。


```python
london_esa_crs=london_esa.rio.crs
london_esa_bounds=london_esa.rio.bounds()
print(london_esa_crs,london_esa_bounds)

with rio.open(lst_mosaic_fn) as src:    
    epsg_LST=src.crs    

LST_pt_leftBottom_pj=usda_geodataProcess.pt_coordi_transform(london_esa_crs,epsg_LST,london_esa_bounds[:2])
LST_pt_rightTop_pj=usda_geodataProcess.pt_coordi_transform(london_esa_crs,epsg_LST,london_esa_bounds[2:])

LST_temp,LST_transform,LST_ras_meta=usda_geodataProcess.rio_read_subset(lst_mosaic_fn,[LST_pt_leftBottom_pj,LST_pt_rightTop_pj])  
```

    EPSG:4326 (-3.0, 51.0, -5.0923620788928536e-17, 54.0)
    

查看 LST 数据。


```python
lst_cmap=mpl.cm.twilight_shifted
f, ax=plt.subplots(figsize=(16,14))
show(LST_temp,ax=ax,transform=LST_transform,cmap=lst_cmap) 
plt.show()
```


<img src="./imgs/3_6_b/output_42_0.png" height='auto' width='auto' title="caDesign">    


将按照边界提取的 LST 数据单独保存为一个栅格文件。


```python
LST_London_fn=r'I:\data\london\LST_London.tif'
LST_ras_meta_=copy.deepcopy(LST_ras_meta)
LST_ras_meta_.update(   
        compress='lzw',
        )  
with rio.open(LST_London_fn,'w',**LST_ras_meta_) as dst:
    dst.write(LST_temp)
```

将 LST 栅格数据转化为以各个栅格单元为多边形对象的矢量文件，定义`rastercells2shp()`函数实现。


```python
rasterfn =r'I:\data\london\LST_London.tif'
aa=rxr.open_rasterio(rasterfn)
aa.rio.crs
```




    CRS.from_wkt('PROJCS["unnamed",GEOGCS["Unknown datum based upon the custom spheroid",DATUM["Not specified (based on custom spheroid)",SPHEROID["Custom spheroid",6371007.181,0]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]]],PROJECTION["Sinusoidal"],PARAMETER["longitude_of_center",0],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Easting",EAST],AXIS["Northing",NORTH]]')




```python
rasterfn =r'I:\data\london\LST_London.tif'
outSHPfn = r'I:\data\london\LST_London.shp'  

LST_gpd=usda_geodataProcess.rastercells2shp(rasterfn,outSHPfn)
```


```python
LST_gpd
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>vals</th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>POLYGON ((-209417.348 6004532.807, -209417.348...</td>
      <td>0</td>
      <td>-209880.660606</td>
      <td>6.004069e+06</td>
    </tr>
    <tr>
      <th>1</th>
      <td>POLYGON ((-208490.722 6004532.807, -208490.722...</td>
      <td>0</td>
      <td>-208954.035173</td>
      <td>6.004069e+06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>POLYGON ((-207564.097 6004532.807, -207564.097...</td>
      <td>0</td>
      <td>-208027.409740</td>
      <td>6.004069e+06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>POLYGON ((-206637.472 6004532.807, -206637.472...</td>
      <td>0</td>
      <td>-207100.784307</td>
      <td>6.004069e+06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>POLYGON ((-205710.846 6004532.807, -205710.846...</td>
      <td>0</td>
      <td>-206174.158873</td>
      <td>6.004069e+06</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>81715</th>
      <td>POLYGON ((-3706.502 5671874.276, -3706.502 567...</td>
      <td>15367</td>
      <td>-4169.814449</td>
      <td>5.671411e+06</td>
    </tr>
    <tr>
      <th>81716</th>
      <td>POLYGON ((-2779.876 5671874.276, -2779.876 567...</td>
      <td>15365</td>
      <td>-3243.189016</td>
      <td>5.671411e+06</td>
    </tr>
    <tr>
      <th>81717</th>
      <td>POLYGON ((-1853.251 5671874.276, -1853.251 567...</td>
      <td>15381</td>
      <td>-2316.563583</td>
      <td>5.671411e+06</td>
    </tr>
    <tr>
      <th>81718</th>
      <td>POLYGON ((-926.625 5671874.276, -926.625 56709...</td>
      <td>15388</td>
      <td>-1389.938150</td>
      <td>5.671411e+06</td>
    </tr>
    <tr>
      <th>81719</th>
      <td>POLYGON ((-0.000 5671874.276, -0.000 5670947.6...</td>
      <td>15358</td>
      <td>-463.312717</td>
      <td>5.671411e+06</td>
    </tr>
  </tbody>
</table>
<p>81720 rows × 4 columns</p>
</div>



### 3.6.1.2 构建数据集和训练模型

#### 1) 构建数据集

数据集的构建包括两个大部分，一个是建立地表温度分类标签；另一个是根据 LST 栅格单元将 WorldCover 切分为一个个样方，每个样方为一个土地覆盖类别矩阵，且对应一个 LST 标签。

* 建立地表温度分类标签

LST 为一个连续型数据，将其离散为分类数据，分类的多种方式可以参看*标记距离*一章。下述分别查看了`BoxPlot`、`JenksCaspall`和`EqualInterval`等三种方法，并写入到 LST （gdf）数据中。

`BoxPlot`分类方法。


```python
outSHPfn = r'I:\data\london\LST_London.shp'
LST_gdf=gpd.read_file(outSHPfn)
LST_gdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vals</th>
      <th>x</th>
      <th>y</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>-209880.660606</td>
      <td>6.004069e+06</td>
      <td>POLYGON ((-209417.348 6004532.807, -209417.348...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>-208954.035173</td>
      <td>6.004069e+06</td>
      <td>POLYGON ((-208490.722 6004532.807, -208490.722...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>-208027.409740</td>
      <td>6.004069e+06</td>
      <td>POLYGON ((-207564.097 6004532.807, -207564.097...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>-207100.784307</td>
      <td>6.004069e+06</td>
      <td>POLYGON ((-206637.472 6004532.807, -206637.472...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>-206174.158873</td>
      <td>6.004069e+06</td>
      <td>POLYGON ((-205710.846 6004532.807, -205710.846...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>81715</th>
      <td>15367</td>
      <td>-4169.814449</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-3706.502 5671874.276, -3706.502 567...</td>
    </tr>
    <tr>
      <th>81716</th>
      <td>15365</td>
      <td>-3243.189016</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-2779.876 5671874.276, -2779.876 567...</td>
    </tr>
    <tr>
      <th>81717</th>
      <td>15381</td>
      <td>-2316.563583</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-1853.251 5671874.276, -1853.251 567...</td>
    </tr>
    <tr>
      <th>81718</th>
      <td>15388</td>
      <td>-1389.938150</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-926.625 5671874.276, -926.625 56709...</td>
    </tr>
    <tr>
      <th>81719</th>
      <td>15358</td>
      <td>-463.312717</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-0.000 5671874.276, -0.000 5670947.6...</td>
    </tr>
  </tbody>
</table>
<p>81720 rows × 4 columns</p>
</div>




```python
LST_gdf.drop(LST_gdf[LST_gdf['vals']==0].index,inplace=True)

LST_BoxPlot=mapclassify.BoxPlot(LST_gdf['vals'])
LST_gdf['rank_boxplot']=LST_BoxPlot.yb
LST_BoxPlot
```




    BoxPlot
    
          Interval         Count
    ----------------------------
    [14119.00, 14763.50] |  1711
    (14763.50, 15128.00] | 18031
    (15128.00, 15264.00] | 19775
    (15264.00, 15371.00] | 19589
    (15371.00, 15735.50] | 19573
    (15735.50, 15795.00] |    31




```python
LST_gdf.boxplot(column=['vals'],grid=False,figsize=(1,7));
```


<img src="./imgs/3_6_b/output_52_0.png" height='auto' width='auto' title="caDesign">    



```python
LST_gdf.plot('vals',cmap='Set1',figsize=(10,10),scheme='BoxPlot',legend=True);
```


<img src="./imgs/3_6_b/output_53_0.png" height='auto' width='auto' title="caDesign">    


`JenksCaspall`分类方法。


```python
LST_JenksCaspall=mapclassify.JenksCaspall(LST_gdf['vals'],k=5)
LST_gdf['rank_JenksCaspall']=LST_JenksCaspall.yb
LST_JenksCaspall
```




    JenksCaspall
    
          Interval         Count
    ----------------------------
    [14119.00, 15008.00] | 10686
    (15008.00, 15174.00] | 14119
    (15174.00, 15298.00] | 21338
    (15298.00, 15417.00] | 19622
    (15417.00, 15795.00] | 12945




```python
LST_gdf.plot('vals',cmap='Set1',figsize=(10,10),k=5,scheme='jenkscaspall',legend=True);
```


<img src="./imgs/3_6_b/output_56_0.png" height='auto' width='auto' title="caDesign">    


`EqualInterval`分类方法。


```python
LST_EqualInterval=mapclassify.EqualInterval(LST_gdf['vals'],k=5) 
LST_gdf['rank_EqualInterval']=LST_EqualInterval.yb
LST_EqualInterval
```




    EqualInterval
    
          Interval         Count
    ----------------------------
    [14119.00, 14454.20] |   136
    (14454.20, 14789.40] |  1969
    (14789.40, 15124.60] | 17270
    (15124.60, 15459.80] | 50970
    (15459.80, 15795.00] |  8365




```python
LST_gdf.plot('vals',cmap='Set1',figsize=(10,10),k=5,scheme='EqualInterval',legend=True);
```


<img src="./imgs/3_6_b/output_59_0.png" height='auto' width='auto' title="caDesign">    


查看最终数据，确定正确后写入本地磁盘。


```python
LST_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vals</th>
      <th>x</th>
      <th>y</th>
      <th>geometry</th>
      <th>rank_boxplot</th>
      <th>rank_JenksCaspall</th>
      <th>rank_EqualInterval</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>81717</th>
      <td>15381</td>
      <td>-2316.563583</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-1853.251 5671874.276, -1853.251 567...</td>
      <td>4</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>81718</th>
      <td>15388</td>
      <td>-1389.938150</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-926.625 5671874.276, -926.625 56709...</td>
      <td>4</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>81719</th>
      <td>15358</td>
      <td>-463.312717</td>
      <td>5.671411e+06</td>
      <td>POLYGON ((-0.000 5671874.276, -0.000 5670947.6...</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




```python
LST_rank_fn=r'I:\data\london\LST_rank.gpkg'
LST_gdf.to_file(LST_rank_fn,driver='GPKG',layer='lst_rank')
```

* 根据 LST 栅格单元将 WorldCover 切分为一个个样方

用 LST 建立的切分样方单元切分栅格数据时，切分后的样方长宽栅格单元数可能不同，因此先随机采样切分 1000 份后，查看长宽大小的频数再确定最终样方大小。从结果来看，纬度1，即样方的高度基本为101个栅格单元；纬度2，即样方的宽度分布数的变化相对较多，但基本在160个以上。因为切分样方可能与被切分的栅格数据之间并不一定完全水平或垂直吻合，因此切分后的样方单元可能存在空值，所以选择高度大小为90，而宽度大小为150的配置，并通过配置偏移，移除周边可能为空值的栅格单元。上述计算中，定义`xy_size_elevation()`函数查看切分后的样方大小；定义`build_clipped_raster_dataset()`函数，切分栅格建立数据集。


```python
clipper_fn=r'I:\data\london\LST_rank.gpkg'   
raster_fn=r'I:\\data\\ESA_London\\ESA_WorldCover_10m_2020_v100_N51W003_Map.tif'

usda_geodataProcess.xy_size_elevation(clipper_fn,raster_fn);
```

    0  1    2  
    1  101  169    100
            171     95
            168     88
            165     85
            167     81
            166     79
            170     78
            164     76
            172     68
            163     48
            173     46
            174     40
            162     29
            175     25
            161     22
            176     15
            177      7
            178      2
            40       1
            160      1
            123      1
            47       1
            46       1
       100  173      1
    Name: count, dtype: int64
    

前文将 LST 栅格数据单元矢量化后写入为 GPKG 数据格式（如果为 SHP 格式数据时，配置的字段较长时，可能会被切断，例如`rank_JenksCaspall`字段被切短为`rank_Jenks`）。构建数据集的函数使用多线程计算，可以配置`ratio_cpu`参数确定 CPU 的使用率；`ratio_split`参数影响数据集的批量大小，批量大小为使用的 CPU 数和`ratio_split`参数之积。

在定义`build_clipped_raster_dataset()`函数时，考虑到有些 LST 字段可能被用到，例如纬度列`y`，其温度与纬度有一定关系。因此参数`y_columns`定义为一个列表，可以输入多个字段，以第一个字段为默认的$y$值，其它字段数据写入到`extra`键下。


```python
dataset_save_fn='I:\data\london\LC2LST_dataset_rank_JenksCaspall.pickle'
usda_geodataProcess.build_clipped_raster_dataset(clipper_fn,raster_fn,dataset_save_fn,['rank_JenksCaspall','y'],90,150,5,10,ratio_cpu=0.7,ratio_split=30) 
```

读取查看建立的数据集。


```python
with open(dataset_save_fn,'rb') as f:
    ds=pickle.load(f)
```


```python
print(ds.data.shape,ds.target.shape,ds.extra.shape)
sample=ds.data[0]
print(f'data shape:{sample.shape};\ndata:\n{sample};\ntarget={ds.target[0]}')
```

    (76683, 1, 90, 150) (76683,) (76683, 1)
    data shape:(1, 90, 150);
    data:
    [[[80 80 80 ... 50 50 50]
      [80 80 80 ... 50 50 50]
      [80 80 80 ... 50 50 50]
      ...
      [30 30 30 ... 30 30 30]
      [30 30 30 ... 30 30 30]
      [30 30 30 ... 30 30 30]]];
    target=0
    


```python
plt.imshow(sample[0]);
```


<img src="./imgs/3_6_b/output_70_0.png" height='auto' width='auto' title="caDesign">    


同样的方式，建立`BoxPlot`和`EqualInterval`分类方式的数据集。


```python
usda_geodataProcess.build_clipped_raster_dataset(clipper_fn,raster_fn,r'I:\data\london\LC2LST_dataset_rank_EqualInterval.pickle',['rank_EqualInterval','y'],90,150,5,10,ratio_cpu=0.7,ratio_split=30) 
usda_geodataProcess.build_clipped_raster_dataset(clipper_fn,raster_fn,r'I:\data\london\LC2LST_dataset_rank_boxplot.pickle',['rank_boxplot','y'],90,150,5,10,ratio_cpu=0.7,ratio_split=30)
```

* 建立数据集加载器，与查看进一步将样方数据切分为连续的图块矩阵（patch）

以`EqualInterval`方式为例。


```python
# dataset_sel_save_fn=r'I:\data\london\LC2LST_dataset_rank_JenksCaspall.pickle'
# dataset_sel_save_fn=r'I:\data\london\LC2LST_dataset_rank_boxplot.pickle'
dataset_sel_save_fn=r'I:\data\london\LC2LST_dataset_rank_EqualInterval.pickle'

with open(dataset_sel_save_fn,'rb') as f:
    ds=pickle.load(f)
ds_unique_target=np.unique(ds.target)
ds_unique_data=np.unique(ds.data)
print(f'ds_unique_target:{ds_unique_target};\nnum_classes={len(ds_unique_target)};\nds_unique_data:{ds_unique_data}\nmax_data={max(ds_unique_data)}')
```

    ds_unique_target:[0 1 2 3 4];
    num_classes=5;
    ds_unique_data:[ 0 10 20 30 40 50 60 80 90]
    max_data=90
    

将数据集切分为训练和测试（验证）数据集，并通过除以大于或等于分类最大值将值缩放到[0,1]区间。并建立数据集加载器。


```python
x_train, x_test, y_train, y_test = train_test_split(ds.data, ds.target.astype(int),test_size=0.2)
x_train, x_test, y_train, y_test=torch.Tensor(x_train), torch.Tensor(x_test), torch.Tensor(y_train).type(torch.LongTensor), torch.Tensor(y_test).type(torch.LongTensor) 
x_train=x_train/100.
x_test=x_test/100.

train_ds=TensorDataset(x_train,y_train)
train_dl=DataLoader(train_ds,batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)

test_ds=TensorDataset(x_test,y_test)
test_dl=DataLoader(test_ds,batch_size=128, shuffle=False, drop_last=False, num_workers=4)
```

查看将样方数据切分为连续的图块矩阵。切分的单个图块大小需要能够被样方长宽整除，例如样方大小为(90,150)，那么配置`patch_size=15`，可以划分为$(90/15)*(150/15)=60$个图块。


```python
img_patches = usda_models.img_to_patch(x_train, patch_size=15, flatten_channels=False)
print(img_patches.shape)

fig, ax = plt.subplots(10, 1, figsize=(20,5))
fig.suptitle("Images as input sequences of patches")
for i in range(10):
    img_grid = torchvision.utils.make_grid(img_patches[i], nrow=60, normalize=True, pad_value=0.9)
    img_grid = img_grid.permute(1, 2, 0)
    ax[i].imshow(img_grid)
    ax[i].axis('off')
plt.show()
plt.close()
```

    torch.Size([61346, 60, 1, 15, 15])
    


<img src="./imgs/3_6_b/output_78_1.png" height='auto' width='auto' title="caDesign">    


#### 2) 训练视觉模型

分别使用`JenksCaspall`、`boxplot`和`EqualInterval`三种分类数据集训练模型。在配置参数时，`boxplot`的类别`num_classes`有6个，其它两个为5个。可以使用 TensorBoard 日志，方便后续训练参数可视化观察。

每一数据集训练迭代100次，用验证（测试）数据集分别计算各自训练模型的精度，`boxplot`分类方式精度为0.348；`EqualInterval`分类方式精度为0.664；`JenksCaspall`分类方式精度为0.324。基于 WorldCover 数据只能部分的解释 LST 数值，其中其它可能影响因素还包括 WorldCover 的分类类型是否适合；WorldCover 的分类精度目前 2020 年为74.4%，2021 年为76.6%；LST 的数据精度影响；三种数据集分类方式是否适合；切分样方的图块大小是否适合；模型本身的网络结构是否适合，及未考虑加入的其它影响因素等。

在进一步的探索中，除了依据上述影响因素调整参数，增加影响 LST 的其它因素外，可以重新设定问题，例如仅关注高于（或低于）某一 LST 值的区域，这样可以简化分类类别为两类，重点分析高温区域或低温区域的地表覆盖结构组成的向量空间特征等。


```python
model_kwargs=dict(embed_dim=256, 
    hidden_dim=512, 
    num_channels=1, 
    num_heads=8, 
    num_layers=6, 
    num_classes=5, 
    patch_size=15, 
    num_patches=60, 
    dropout=0.2,)

# CHECKPOINT_PATH=r'I:\model_ckpts\ViT_LC_LST_JenksCaspall'#r'I:\model_ckpts\ViT_LC_LST'
# CHECKPOINT_PATH=r'I:\model_ckpts\ViT_LC_LST_boxplot'
CHECKPOINT_PATH=r'I:\model_ckpts\ViT_LC_LST_EqualInterval'

device=torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
logger=TensorBoardLogger(os.path.join(CHECKPOINT_PATH, "tensorboard"), name="lclst")
trainer=pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, "ViT"),
                     accelerator="gpu" if str(device).startswith("cuda") else "cpu",
                     #logger=logger,
                     devices=1,
                     max_epochs=180,
                     callbacks=[ModelCheckpoint(save_weights_only=True, mode="max", monitor="val_acc"),
                                LearningRateMonitor("epoch")])

trainer.logger._log_graph=True         # If True, we plot the computation graph in tensorboard
trainer.logger._default_hp_metric=None # Optional logging argument that we don't need
```

    GPU available: True (cuda), used: True
    TPU available: False, using: 0 TPU cores
    IPU available: False, using: 0 IPUs
    HPU available: False, using: 0 HPUs
    


```python
# Check whether pretrained model exists. If yes, load it and skip training
pretrained_filename = os.path.join(CHECKPOINT_PATH, "ViT.ckpt")
if os.path.isfile(pretrained_filename):
    print(f"Found pretrained model at {pretrained_filename}, loading...")
    model=usda_models.ViT.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters
else:
    pl.seed_everything(42) # To be reproducable
    model=usda_models.ViT(model_kwargs,lr=3e-4)
    trainer.fit(model, train_dl, test_dl)
    model=usda_models.ViT.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training 
```


    Global seed set to 42
    LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

      | Name      | Type               | Params
    -------------------------------------------------
    0 | model     | VisionTransformer  | 3.2 M 
    1 | valid_acc | MulticlassAccuracy | 0     
    -------------------------------------------------
    3.2 M     Trainable params
    0         Non-trainable params
    3.2 M     Total params
    12.953    Total estimated model params size (MB)
    Epoch 23:  38%|▍| 184/479 [1:11:44<1:55:00, 23.39s/it, v_num=0, loss_step=0.768, val_loss=0.856, val_acc=0.67


试验中测试和验证数据集使用了相同的数据。


```python
test_result=trainer.test(model, test_dl, verbose=False)
result={"test": test_result[0]["test_acc"]}
print("ViT results", result)
```

    LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
    

    Testing DataLoader 0: 100%|████████████████████████████████████████████████| 120/120 [00:05<00:00, 22.22it/s]
    ViT results {'test': 0.67177414894104}
    

## 3.6.2 街道视域景观指数的时空特征表述和预测

### 3.6.2.1 数据准备

#### 1) 全景静态图检索下载

分析对象为西安老城区东西大街。

1. 首先用 [Google Earth](https://www.google.com/earth/versions/)<sup>⑤</sup>沿道路绘制路径，保存为 KML 数据格式。定义`kml2gdf_folder()`函数读取 KML 对象为 GeoDataFrame 格式数据。（也可以直接使用即有的矢量（SHP 格式）道路数据文件，用`geopandas`库读取）；
2. 定义`roads_pts4bsv_tourLine()`函数，由道路线段提取给定距离的采样点，用于全景图采样定位； 
3. 定义`baidu_steetview_crawler()`数据检索工具，根据采样点从[百度地图开放平台](https://lbsyun.baidu.com/index.php?title=%E9%A6%96%E9%A1%B5)<sup>⑥</sup>全景静态图API下载全景图；
4. 定义`img_valid_copy_folder()`函数，验证下载图像的有效性，并复制有效的图像至新建的文件夹下。总共下载图像583张，有效图像568张。


```python
%load_ext autoreload 
%autoreload 2 
%reload_ext autoreload
import usda.geodata_process as usda_geodataProcess 
import usda.datasets as usda_datasets
from usda.migrated_project import pass_panoseg
import usda.utils as usda_utils
import usda.pano_projection_transformation as usda_pano
from usda.database import gpd2postSQL,postSQL2gpd
import usda.utils as usda_utils
import usda.models as usda_models

import matplotlib.pyplot as plt
import geopandas as gpd
import pandas as pd
import os
from matplotlib import image as mpimg
import pickle
import glob
import rioxarray as rxr
import seaborn as sb
import torch.nn as nn

import torch.optim as optim
import torch.utils.data as data
import numpy as np
import torch
import plotly.express as px
```



读取 KML 路径。



```python
huiminjie_fn='../data/dongxistreet.kml'

xian_epsg=32649
huiminjie=usda_geodataProcess.kml2gdf_folder(huiminjie_fn,epsg=xian_epsg)
huiminjie
```

    100%|██████████| 1/1 [00:00<00:00, 10.71it/s]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>geometry</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>dongxistreet</td>
      <td></td>
      <td>LINESTRING Z (308400.083 3793037.020 0.000, 30...</td>
      <td>dongxistreet.kml</td>
    </tr>
  </tbody>
</table>
</div>



提取采样点。


```python
sample_multipts=usda_datasets.roads_pts4bsv_tourLine(huiminjie,8)
ax=sample_multipts.plot(figsize=(20,10),markersize=1)
plt.xticks(rotation=90);
```

    100%|██████████| 1/1 [00:00<00:00, 62.82it/s]
    100%|██████████| 1/1 [00:00<00:00, 13.18it/s]
    


<img src="./imgs/3_6_b/output_90_1.png" height='auto' width='auto' title="caDesign">    


因为定义的`baidu_steetview_crawler()`方法中，区分了具有不同名称的道路路径，其默认字段为`Name`，因此增加该字段。


```python
sample_multipts['Name']='dongxistreet'
sample_multipts
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>group</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>dongxistreet</td>
      <td>huiminjie.kml</td>
      <td>MULTIPOINT Z (108.93892 34.26214 0.00000, 108....</td>
    </tr>
  </tbody>
</table>
</div>



检索全景图。

> 百度地图开放平台每天有固定配额，超出配额，需要另行支付费用。


```python
pano_fn=r'E:\data\pano_dongxistreet\images'
pano_info={'pt_fns':r'E:\data\pano_dongxistreet\pt_fns_street.pickle',
           "coords":r'E:\data\pano_dongxistreet\coords_street.pickle',
           "downloadError_idx":r'E:\data\pano_dongxistreet\downloadError_idx_street.pickle'}
ak='rSxNX840wLxwVVhs5RDInfPqegZ12G78'

coords,pts_num=usda_datasets.baidu_steetview_crawler(sample_multipts,pano_fn,ak,pano_info)
```

    
    pts_num=583
    

    100%|██████████| 1/1 [05:26<00:00, 326.31s/it]
    

验证图像的有效性。


```python
with open(pano_info["pt_fns"],'rb') as f:
    pt_fns=pickle.load(f)
    
pano_valid_fn=r'E:\data\pano_dongxistreet\images_valid'
usda_datasets.img_valid_copy_folder(pano_fn,pano_valid_fn)     
```

    100%|██████████| 583/583 [00:00<00:00, 2776.87it/s]
    100%|██████████| 568/568 [00:04<00:00, 135.04it/s]
    

#### 2)  全景图像素级语义分割（Pixel-wise semantic segmentation）

应用[PASS（ERF-PSPNet）深度学习模型](https://github.com/elnino9ykl/PASS)<sup>⑦</sup>实现全景图像素级语义分割。Yang, K等人<sup>[2]</sup>提供了 $1024 \times 512$大小的预训练模型参数，而百度全景图的大小也为$1024 \times 512$，因此可以避免重新训练模型。为了方便使用该模型，将其代码迁移至`USDA`库方便调用。迁移时为了避免增加库的大小，并未迁移预训练模型参数文件，需要从 PASS 作者的 [GitHub 代码仓库](https://github.com/elnino9ykl/PASS/tree/master/trained_models)<sup>⑧</sup>获取，作为输入参数传入。全景图分割后保存于两个子文件夹，一个为`seg_img`，存储分割图像；另一个为`seg_label'，存储分割标签数据。


```python
weights_fn=r'C:\Users\richie\omen_richiebao\omen_github\USDA_special_study\models\erfpspnet.pth'
pano_dir=r'G:\data\pano_dongxistreet\images_valid'
save_dir=r'G:\data\pano_dongxistreet\pano_seg'
pass_panoseg.pass_seg(weights_fn,pano_dir,save_dir)
```

    Model and weights LOADED successfully
    

    100%|██████████| 566/566 [01:38<00:00,  5.73it/s]
    

打印查看分割后结果。


```python
fn=r'dongxistreet_228'
fig,axes=plt.subplots(1,2,figsize=(20,10))
img=mpimg.imread(os.path.join(pano_dir,fn+'.jpg'))
axes[0].imshow(img)

seg=mpimg.imread(os.path.join(save_dir,f'seg_img\{fn}.jpg'))
axes[1].imshow(seg)
plt.show()
```


<img src="./imgs/3_6_b/output_100_0.png" height='auto' width='auto' title="caDesign">    



查看分割标签文件。


```python
with open(os.path.join(save_dir,f'seg_label\{fn}.pkl'),'rb') as f:
    label=pickle.load(f)
label
```




    tensor([[22, 22, 22,  ..., 22, 22, 22],
            [22, 22, 22,  ..., 22, 22, 22],
            [22, 22, 22,  ..., 22, 22, 22],
            ...,
            [27, 27, 27,  ..., 27, 27, 27],
            [27, 27, 27,  ..., 27, 27, 27],
            [27, 27, 27,  ..., 27, 27, 27]], dtype=torch.uint8)



#### 3) 百度 POI 数据检索下载

百度 POI 数据下载参看*POI数据与描述性统计和正态分布*部分。这里直接使用参看部分的处理结果数据，并将其裁切到分析路径缓冲距离 1000 m 范围内。


```python
pois_fn=r'G:\data\POI_dongxistreet\poisInAll_gdf.geojson'
pois=gpd.read_file(pois_fn)
pois.to_crs(huiminjie.crs,inplace=True)

region=huiminjie.buffer(1000,join_style=3,cap_style=3)
clipped_pois=gpd.clip(pois,region)
clipped_pois
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>level_0</th>
      <th>level_1</th>
      <th>name</th>
      <th>location_lat</th>
      <th>location_lng</th>
      <th>detail_info_tag</th>
      <th>detail_info_overall_rating</th>
      <th>detail_info_price</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1237</th>
      <td>poi_0_delicacy</td>
      <td>2474</td>
      <td>韩式自助烤肉店</td>
      <td>34.252172</td>
      <td>108.929424</td>
      <td>美食;外国餐厅</td>
      <td>4.4</td>
      <td>77</td>
      <td>POINT (309338.325 3792056.394)</td>
    </tr>
    <tr>
      <th>14319</th>
      <td>poi_14_realEstate</td>
      <td>2046</td>
      <td>众生房产</td>
      <td>34.252177</td>
      <td>108.929302</td>
      <td>生活服务;房产中介机构</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309327.161 3792057.198)</td>
    </tr>
    <tr>
      <th>1200</th>
      <td>poi_0_delicacy</td>
      <td>2400</td>
      <td>粤珍轩(含光店)</td>
      <td>34.252202</td>
      <td>108.927973</td>
      <td>美食;中餐厅</td>
      <td>3.9</td>
      <td>115</td>
      <td>POINT (309204.828 3792062.485)</td>
    </tr>
    <tr>
      <th>4144</th>
      <td>poi_10_medicalTreatment</td>
      <td>1688</td>
      <td>西安碑林含光门中医诊所</td>
      <td>34.252214</td>
      <td>108.928526</td>
      <td>医疗;诊所</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309255.754 3792062.769)</td>
    </tr>
    <tr>
      <th>35110</th>
      <td>poi_5_spot</td>
      <td>1090</td>
      <td>西北联大纪念碑</td>
      <td>34.251402</td>
      <td>108.920978</td>
      <td>旅游景点;文物古迹</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>POINT (308558.776 3791986.915)</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20867</th>
      <td>poi_16_government</td>
      <td>2166</td>
      <td>中共莲湖区教育局委员会</td>
      <td>34.268539</td>
      <td>108.935593</td>
      <td>政府机构;各级政府</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309943.366 3793860.143)</td>
    </tr>
    <tr>
      <th>20877</th>
      <td>poi_16_government</td>
      <td>2186</td>
      <td>陕西省观赏石协会西安观赏石协会联络处</td>
      <td>34.268617</td>
      <td>108.935436</td>
      <td>政府机构;行政单位</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309929.062 3793869.041)</td>
    </tr>
    <tr>
      <th>20866</th>
      <td>poi_16_government</td>
      <td>2164</td>
      <td>中国共产党西安市莲湖区建设和住房保障局委员会</td>
      <td>34.268627</td>
      <td>108.935667</td>
      <td>政府机构;其他</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309950.306 3793869.743)</td>
    </tr>
    <tr>
      <th>20845</th>
      <td>poi_16_government</td>
      <td>2122</td>
      <td>中共莲湖区城市管理和综合执法局委员会</td>
      <td>34.268647</td>
      <td>108.936819</td>
      <td>政府机构;其他</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (310056.438 3793869.855)</td>
    </tr>
    <tr>
      <th>20881</th>
      <td>poi_16_government</td>
      <td>2194</td>
      <td>西安市莲湖区教育区</td>
      <td>34.268770</td>
      <td>108.935615</td>
      <td>政府机构;行政单位</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>POINT (309945.841 3793885.682)</td>
    </tr>
  </tbody>
</table>
<p>1389 rows × 9 columns</p>
</div>



查看 POI 数据裁切后结果。


```python
f, ax=plt.subplots(1,1,figsize=(20,20))
clipped_pois.plot(ax=ax,column='level_0')
huiminjie.plot(ax=ax,edgecolor='k',linewidth=5,linestyle='-')
plt.tight_layout()
plt.show()
```


<img src="./imgs/3_6_b/output_106_0.png" height='auto' width='auto' title="caDesign">   


保存裁切后的 POI 数据。


```python
clipped_pois_fn=r'G:\data\POI_dongxistreet\clipped_poi_gdf.gpkg'
clipped_pois.to_file(clipped_pois_fn,driver='GPKG', layer='poi')
```

### 3.6.2.2 全景与语义分割图的投影变换

在城市街道空间的组成结构分析过程中，需要根据不同的分析内容对数据进行预先处理满足分析的要求和改善计算的准确性。极坐标格式全景图(小行星视角360度全景)用于天空相关指数的计算，避免等量矩形投影图未闭合的天空形状影响；等量矩形投影图和极坐标格式全景图因为投影变形，对象像素所占比例不能最大限度的反应实际视觉下对象比例关系。而立方体型全景格式由前，后，左，右，上，下6张透视图组成，用于语义分割对象所占像素百分比的统计相对合理；球面全景，可以反应对象在实际空间中的位置关系，用于语义分割对象空间位置变化的分析。

#### 1) 等量矩形投影图到立方体型全景格式

应用Zhou, C.<sup>[3]</sup>等人 [Oculus 360 度视频流测量研究成果](https://github.com/bingsyslab/360projection)<sup>⑨</sup>，实现全景图到立方体格式全景图的投影。迁移代码至`USDA`库，定义`equi2cube()`方法，并应用多线程计算。定义方法时，输出结果包含3类数据，在生成的子文件夹`img_seg_redefined_color`下为重新定义的 PASS 分割结果分类颜色配置，其值如下`label_color_name`属性；在子文件夹`cube_img_seg`下为立方体格式全景图图像；在子文件夹`cube_label_seg`下为立方体格式全景图对应像素标签。


```python
__C=usda_utils.AttrDict()
args=__C
__C.pano_path=r'G:\data\pano_dongxistreet\images_valid'
__C.label_seg_path=r'G:\data\pano_dongxistreet\pano_seg\seg_label'   
__C.face_size=1000
__C.equi2cub_dir=r'G:\data\pano_dongxistreet\pano_projection_transforms'

__C.pano_redefined_path=r'G:\data\pano_dongxistreet\pano_projection_transforms\img_seg_redefined_color'
__C.output_shape=(1024,1024)
__C.little_planet='little_planet_1'
__C.polar_seg_img_dir=r'G:\data\pano_dongxistreet\polar_seg_img'

__C.coords_street_fn=r'G:\data\pano_dongxistreet\coords_street.pickle'

__C.db=usda_utils.AttrDict() 
__C.db.UN='postgres'
__C.db.PW='123456'
__C.db.DB='visual_metrics'
__C.db.GC='geometry' 
__C.db.db_info=dict(geom_col=args.db.GC,myusername=args.db.UN,mypassword=args.db.PW,mydatabase=args.db.DB)

__C.tiff_sky_save_root=r'G:\data\pano_dongxistreet\tiff_sky'

__C.colors_dominant2cluster_path=r'G:\data\pano_dongxistreet\colors_dominant2cluster.pkl'

__C.visual_BOW_kmeans_fn=r'G:\data\pano_dongxistreet\visual_BOW_kmeans.pkl'
__C.feature_map_fn=r'G:\data\pano_dongxistreet\feature_map.pkl'
```


```python
label_seg_path=args.label_seg_path
label_seg_fns=glob.glob(os.path.join(label_seg_path,'*.pkl'))
equi2cube_dir=args.equi2cub_dir
face_size=args.face_size

usda_pano.equi2cube(label_seg_fns,equi2cube_dir,face_size,cpu_num=8)
```

     100%|██████████| 144/566 [00:10<00:00, 1385.52it/s]

查看重新定义 PASS 全景图分割结果颜色值。


```python
usda_pano.label_color_name
```




    {0: [(117, 115, 102), 'pole'],
     1: [(212, 209, 156), 'slight'],
     2: [(224, 9, 9), 'bboard'],
     3: [(227, 195, 66), 'tlight'],
     4: [(137, 147, 169), 'car'],
     5: [(53, 67, 98), 'truck'],
     6: [(185, 181, 51), 'bicycle'],
     7: [(238, 108, 91), 'motor'],
     8: [(247, 5, 5), 'bus'],
     9: [(127, 154, 82), 'tsignf'],
     10: [(193, 209, 167), 'tsignb'],
     11: [(82, 83, 76), 'road'],
     12: [(141, 142, 133), 'sidewalk'],
     13: [(208, 212, 188), 'curbcut'],
     14: [(98, 133, 145), 'crosspln'],
     15: [(194, 183, 61), 'bikelane'],
     16: [(141, 139, 115), 'curb'],
     17: [(157, 186, 133), 'fence'],
     18: [(114, 92, 127), 'wall'],
     19: [(78, 61, 76), 'building'],
     20: [(100, 56, 67), 'person'],
     21: [(240, 116, 148), 'rider'],
     22: [(32, 181, 191), 'sky'],
     23: [(55, 204, 26), 'vege'],
     24: [(84, 97, 82), 'terrain'],
     25: [(231, 24, 126), 'markings'],
     26: [(141, 173, 166), 'crosszeb'],
     27: [(0, 0, 0), 'Nan']}



查看输出结果。


```python
fn=r'dongxistreet_228'
fig,axes=plt.subplots(1,2,figsize=(20,10))
seg=mpimg.imread(os.path.join(equi2cube_dir,'img_seg_redefined_color/'+fn+'.jpg'))
axes[0].imshow(seg)
cube=mpimg.imread(os.path.join(equi2cube_dir,'cube_img_seg/'+fn+'.jpg'))
axes[1].imshow(cube)
plt.show()
```


<img src="./imgs/3_6_b/output_115_0.png" height='auto' width='auto' title="caDesign">    



#### 2） 等量矩形投影图到极坐标格式全景图

应用[Making a Little Planet Panorma using Python and Scikit Image](https://richwareham.com/little-planet-projection/)<sup>⑩</sup>阐述的方法，定义`equi2polar()`函数，将全景图分割图像转化为极坐标格式。


```python
pano_path=args.pano_redefined_path
output_shape=args.output_shape
little_planet=args.little_planet
polar_save_path=args.polar_seg_img_dir   

usda_pano.equi2polar(pano_path,output_shape,polar_save_path,little_planet='little_planet_1')
```

    100%|██████████| 566/566 [01:41<00:00,  5.60it/s] 
    

查看转化后的结果。


```python
fn=r'dongxistreet_228'
fig,ax=plt.subplots(figsize=(5,5))
polar=mpimg.imread(os.path.join(polar_save_path,fn+'.jpg'))
ax.imshow(polar)
plt.show()
```


<img src="./imgs/3_6_b/output_119_0.png" height='auto' width='auto' title="caDesign">    


#### 3）等量矩形投影图到球面全景

使用 [mayavi](https://docs.enthought.com/mayavi/mayavi/) <sup>⑪</sup>三维科学数据可视化绘图工具，定义`sphere_panorama_label()`方法实现球面全景投影。`mlab.show()`方法可以交互显示三维图像，也可以通过`mlab.savefig`方法保存图像。


```python
fn=r'dongxistreet_228'
pano_img_fn=os.path.join(pano_dir,fn+'.jpg') 
usda_pano.sphere_panorama_label(pano_img_fn)
```

<img src="./imgs/3_6_b/3_6_b_03_s.gif" height='auto' width=500 title="caDesign">

将上述完成投影变换计算的立方体型全景格式、极坐标格式全景图、球面全景与原始分割全景和对应的原始全景图像排布如下观察。

<img src="./imgs/3_6_b/3_6_b_04.png" height='auto' width='auto' title="caDesign">

### 3.6.2.3 视域景观指数计算

分析城市街道空间特征的指数主要包括基于立方体型360度全景图语义分割对象像素占比，即绿视率、天空视域因子和地面视域占比，及视觉（熵）均衡度和域对象位置变化；基于极坐标格式全景图语义分割天空对象的景观指数，包括周长面积比、形状指数和分维数；基于等量矩形投影全景图颜色的主题色提取和色彩丰富度指数；基于尺度不变特征转换特征关键点信息的关键点邻域尺度(i,j]区间频数、标准差和视域特征匹配消失距离；基于行业分类服务内容兴趣点的POI点数、POI均衡度和POI特征映射，总共16个指数。其中反应视域城市街道物质空间组成结构，基于全景图计算机视觉分析的指数13个；反应居民日常活动，基于具有社会属性，即服务空间的兴趣点指数3个。

| 序号  | 指数名称  |  值个数 | 内容  |  公式 |  描述 |   
|---|---|---|---|---|---|
|  1 | 绿视率（Seg object_Green view index, Seg_GVI）  | 1  | 基于立方体型360度全景图语义分割对象像素占比  | $Seg\_GVI= \frac{ P_{seg\_green} }{P}  \times 100$  |  绿视率（$Seg\_GVI$）等于立方体型360度全景图语义分割对象中植被像素数$P_{seg\_green}$ 占全部像素数P的百分比。 |   
|  2 | 天空视域因子（Seg object Sky view factor, Seg_SVF）  | 1  |   | $Seg\_SVF= \frac{ P_{seg\_sky} }{P}  \times 100$  | 天空视域因子（$Seg\_SVF$ ）等于立方体型360度全景图语义分割对象中天空像素数$P_{seg\_sky}$ 占全部像素数 P的百分比。  |   
|  3 | 地面视域占比（Seg object Ground view factor, Seg_GVF）  | 1  |   | $Seg\_GVF= \frac{ P_{seg\_ground} }{P}  \times 100$  | 地面视域占比（$Seg\_GVF$ ）等于立方体型360度全景图语义分割对象中地面像素数$P_{seg\_ground}$ 占全部像素数P的百分比。  |   
|  4 | 视觉（熵）均衡度（Seg object equilibrium degree, Seg_ED）  |  1 |   |  $Seg\_ED= \frac{- \sum_{i=1}^n  P_{i}logP_{i}  }{logN}$  | 视觉（熵）均衡度（$Seg\_ED$）为立方体型360度全景图语义分割对象信息熵与最大熵值$logN$之比。 $P_{i}$ 为第$i$个语义分割对象像素数与全部像素数的比值。  |  
| 5  | 视域对象位置变化（Variation degree of objects , VDO）  | 多个值  |   |  $VDO_{ij}= \Delta  ( A_{0} ) _{ij} +  \Delta  ( A_{1} ) _{ij} +  \ldots  + \Delta  ( A_{k-1} ) _{ij};  \Delta  (A) _{ij}=\begin{cases}1 & \Delta  (A) _{ij}> 0\\0 & \Delta  (A) _{ij}=0\end{cases} $ |  视域对象位置变化$VDO$为分析路径下各个地理位置点的球面全景语义分割对象在球面各像素点位置上的变化，即任意球面位置$(i,j)$在路径上相邻两位置语义分割对象发生了改变则加1，即$\Delta  (A) _{ij}=1$否则加0，未发生改变，得球面位置$(i,j)$的变化次数$VDO_{ij}$。$VDO$矩阵即为视域对象位置变化。 |  
|  6 | 天际线周长面积比（均值）（Skyline perimeter area ratio, Sky_PARA(mn)） |  1 | 基于极坐标格式全景图语义分割天空对象的景观指数  |  $Sky\_PARA_{(mn)} = \frac{ \sum_{i=1}^n  \frac{ p_{i} }{ a_{i} }  }{n}$  |  天际线周长面积比（均值）（$Sky\_PARA_{(mn)}$）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$与面积$a_{i}$ 比之和除以天空的斑块数$n$。由PyLandStats库（Python）计算。 |   
|  7 | 天际线形状指数（均值）（Skyline shape index, Sky_ SHAPE(mn)）  | 1  |   | $ Sky\_SHAPE_{(mn)} = \frac{ \sum_{i=1}^n  \frac{.25 p_{i} }{ \sqrt{ a_{i} } } }{n} $  |  天际线形状指数（均值）（$ Sky\_SHAPE_{(mn)}$）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$与面积$a_{i}$ 平方根比值乘以调整系数的和除以天空的斑块数 $n$。 由PyLandStats库（Python）计算。|   
|  8 | 天际线分维数（均值）（Skyline fractal dimension, Sky_ FRAC(mn) ）  |  1 |   | $Sky\_FRAC_{(mn)} = \frac{ \sum_{i=1}^n  \frac{2ln(.25 p_{i} )}{ln( a_{i} )}  }{n} $  | 天际线分维数（均值）（$Sky\_FRAC_{(mn)}$ ）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$乘以调整系数后取其对数的2倍与面积$a_{i}$ 的对数比值的和除以天空的斑块数 $n$。 由PyLandStats库（Python）计算。 |   
|  9 | 主题色（Theme color, TC）  | 多个值  | 基于等量矩形投影全景图城市街道色彩  | $argmin_{S} \sum_{i=1}^k  \sum_{x \in  S_{i} }\|x-  \mu _{i}   \|^{2}  $;$TC=\{ TC_{i} : TC_{i} =  \frac{1}{ \| S_{i} \| }  \sum_{ x_{j}  \in   S_{i} }  x_{j} \}$ | 主题色（$TC$）为等量矩形投影全景图颜色值聚类各簇中心值 $TC_{i}$的集合，即第$i$个类簇所有颜色点各属性值（R、G、B）的和除以该簇个数$\|S_{i}\|$。聚类条件为使得所有簇内各颜色点$x$到该簇中心值（经验均值）$μ_{i}$的平方误差和最小。 由scikit-learn库（Python）的K-Means方法聚类。 |   
|  10 | 色彩丰富度指数（Color richness index, CRI）   |  1 |   | $CRI= \frac{- \sum_{i=1}^k  P_{i}logP_{i}  }{log\| S\| } $;$P_{i} = \frac{\| S_{i} \|  }{ \sum_{i=1}^k \| S_{i} \|  } , S_{i} \in S$  | 色彩丰富度指数（CRI）为等量矩形投影全景图主题色聚类的信息熵与最大熵值log⌈S⌉的比值， ⌈S⌉ 即主题色聚类数，全景图各颜色点所属主题色由主题色TC计算时获取。P_i为第i个主题色聚类簇颜色点数（像素数）⌈S_i ⌉与全部像素数的比值。  |   
|  11 |关键点邻域尺度(i,j]区间频数（Key point size(i-j] frequency,KPSF_(i,j] )   | 多个值  | 尺度不变特征转换（Scale Invariant Feature Transform, SIFT）  |  $ KPSF_{(i,j]} =\{ x_{k} :i \leq  x_{k} <j,  x_{k}  \in KPS  \}$ | 关键点邻域尺度$(i,j]$区间频数（$KPSF_{(i,j]}$) 为关键点邻域尺度$x_{k}$, 即提取的等量矩形投影全景图特征关键点的大小 $KPS$, 满足条件$i≤ x_{k} < j$的集合。  由opencv-python库（Python）StarDetector_create()方法提取特征关键点。|   
| 12 | 关键点邻域尺度标准差（Key point size std, KPS_STD）  | 1  |   | $KPS\_STD= \sqrt{ \frac{1}{N} \sum_{i=1}^N   ( x_{i}- \mu  )^{2}  } ,  x_{i}  \epsilon KPS$  | 关键点邻域尺度标准差（$KPS\_STD$）为各个关键点邻域尺度$x_{i}$ 与均值 $μ$的差值平方除以关键点数的平方根。 由opencv-python库（Python）StarDetector_create()方法提取特征关键点。 |    
| 13  | 视域特征匹配消失距离 （Vanishing distance of feature matching, VDFM ）   |  1 |   | $VDFM=f( x_{1} ), where  \triangle (x)== \triangle ( \triangle (x)) \& \triangle (x)!=0$  | 视域特征匹配消失距离  $VDFM$为分析路径某一位置等量矩形投影全景图与之后所有位置全景图图像匹配特征点数变化趋于平缓的位置与该位置的路径距离。$\triangle (x)$为连续相邻图像匹配特征点数的差值，$\triangle ( \triangle (x))$为差值的差值；$f(x_{1} )$为满足条件的第一个值$x_{1}$作为参数输入函数$f$，返回其间的路径距离。  由opencv-python库（Python）BFMatcher()方法计算图像匹配。  |   
| 14  | 兴趣点数（Number of POI, POI_NUM）  |  1 |  POI | $POI\_NUM=n$  | 兴趣点数$POI\_NUM$为分析路径某一位置给定缓冲区下兴趣点的数量。|   
| 15  | POI均衡度（Equilibrium degree of POI, POI_ED）  |  1 |   |  $POI\_ED= \frac{- \sum_{i=1}^k  P_{i}logP_{i}  }{log\|S\|} $; $P_{i}= \frac{\| S_{i} \|}{ \sum_{i=1}^k \| S_{i} \| }  , S_{i} \in S$| $POI$均衡度$POI\_ED$为分析路径某一位置给定缓冲区下兴趣点一级行业分类的信息熵与最大熵值$log\|S\|$的比值，$\|S\|$为兴趣点一级行业分类数。$P_{i}$为第$i$个一级行业分类数$\| S_{i} \|$与全部一级行业分类数的比值。  |   
| 16  | POI特征映射（码本映射）（Codewords of POI, POI_CW）  | 多个值  |   |  POI\_CW=[w_{0},w_{1},⋯,w_{k} ] |  $POI$特征映射（码本映射）$POI\_CW$为分析路径某一位置给定缓冲区下兴趣点各一级行业分类的数量或其与总数的比值的矩阵或向量。$k$为一级行业分类的数量，即为矩阵的长度。 |   


#### 1）街道空间对象视域占比指数测量

语义分割立方体型全景图，计算植被（绿视率）、天空（天空视域因子）、地面视域所占百分比，以及视觉熵均衡度。将计算结果划分为4个数量级区间，(0,15], (15,25], (25,50]和(50,100]，可以描述为较少，正常，较多，多。街道空间对象视域占比指数与城市街区类型，空间体验，市民活动行为，建筑外热环境（微气候）等内容相关。

* 街道空间对象视域占比


```python
with open(args.coords_street_fn,'rb') as f: 
    coords=pickle.load(f) 
```


```python
label_seg_path=os.path.join(args.equi2cub_dir,'cube_label_seg') 
img_Seg_path=os.path.join(args.equi2cub_dir,'cube_img_seg')   
cube_object_percent_gdf=usda_pano.metrics_seg_pano_proportion(label_seg_path,img_Seg_path,coords,)    
```

    100%|██████████| 566/566 [03:33<00:00,  2.65it/s]
    


```python
gpd2postSQL(cube_object_percent_gdf,table_name='cube_object_percent',**args.db.db_info)   
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is cube_object_percent.
    


```python
cube_object_percent_gdf=postSQL2gpd(table_name='cube_object_percent',**args.db.db_info)  
cube_object_percent_gdf.tail(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is cube_object_percent.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>pole</th>
      <th>slight</th>
      <th>bboard</th>
      <th>tlight</th>
      <th>car</th>
      <th>truck</th>
      <th>...</th>
      <th>person</th>
      <th>rider</th>
      <th>sky</th>
      <th>vege</th>
      <th>terrain</th>
      <th>markings</th>
      <th>crosszeb</th>
      <th>Nan</th>
      <th>ground_diff</th>
      <th>sky_vege</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>0.006400</td>
      <td>0.0</td>
      <td>2.758550</td>
      <td>0.0</td>
      <td>3.548533</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.011150</td>
      <td>0.0</td>
      <td>29.560383</td>
      <td>0.521933</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>31.350317</td>
      <td>41.225100</td>
      <td>30.082317</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>0.020317</td>
      <td>0.0</td>
      <td>1.121667</td>
      <td>0.0</td>
      <td>12.247250</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.008017</td>
      <td>0.0</td>
      <td>29.791083</td>
      <td>1.563883</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>14.151933</td>
      <td>50.491133</td>
      <td>31.354967</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.982000</td>
      <td>0.0</td>
      <td>23.858583</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.047583</td>
      <td>0.0</td>
      <td>30.658100</td>
      <td>2.070233</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9.059367</td>
      <td>46.557150</td>
      <td>32.728333</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 34 columns</p>
</div>




```python
cube_object_percent_gdf.plot(column='vege',figsize=(20,1),markersize=10,legend=True, cmap='hot');
```


<img src="./imgs/3_6_b/output_129_0.png" height='auto' width='auto' title="caDesign">    



* 视觉（熵）均衡度


```python
cube_object_VE_gdf=usda_pano.metrics_visual_entropy(cube_object_percent_gdf)
gpd2postSQL(cube_object_VE_gdf,table_name='cube_object_percent',**args.db.db_info)  
cube_object_VE_gdf.tail(3)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is cube_object_percent.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>pole</th>
      <th>slight</th>
      <th>bboard</th>
      <th>tlight</th>
      <th>car</th>
      <th>truck</th>
      <th>...</th>
      <th>vege</th>
      <th>terrain</th>
      <th>markings</th>
      <th>crosszeb</th>
      <th>Nan</th>
      <th>ground_diff</th>
      <th>sky_vege</th>
      <th>ground</th>
      <th>ve</th>
      <th>equilibrium_degree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>0.006400</td>
      <td>0.0</td>
      <td>2.758550</td>
      <td>0.0</td>
      <td>3.548533</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.521933</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>31.350317</td>
      <td>41.225100</td>
      <td>30.082317</td>
      <td>53.860950</td>
      <td>1.674268</td>
      <td>50.245055</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>0.020317</td>
      <td>0.0</td>
      <td>1.121667</td>
      <td>0.0</td>
      <td>12.247250</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.563883</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>14.151933</td>
      <td>50.491133</td>
      <td>31.354967</td>
      <td>54.351650</td>
      <td>1.948515</td>
      <td>58.475244</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.982000</td>
      <td>0.0</td>
      <td>23.858583</td>
      <td>0.0</td>
      <td>...</td>
      <td>2.070233</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9.059367</td>
      <td>46.557150</td>
      <td>32.728333</td>
      <td>51.518967</td>
      <td>1.787379</td>
      <td>53.639539</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 37 columns</p>
</div>




```python
cube_object_percent_gdf.plot(column='ve',figsize=(20,1),markersize=10,legend=True, cmap='hot');
```


<img src="./imgs/3_6_b/output_132_0.png" height='auto' width='auto' title="caDesign">    


* 街道空间对象视域占比区间统计 

从计算结果的表中可以初步判断分析区域不同视域占比频数比例的分布，绿视率`vege_percentage`低于15%的接近一半数量，道路以车行为主，高于25%适宜于步行体验，易于放松身心的占到约30%；天空视域因子`sky_percentage`高于50%的基本没有，以25%为数量级划分，高低各占约一半；将绿视率和天空视域因子综合考虑，即自然因素视域占比`sky_vege_percentage`，高于25%的达到96%的数量；地面视域占比`ground_percentage`有42.049%的数量高于50%，通常为道路交叉口以及快速路、主干路等路面宽阔的空间。街道空间对象的混合程度`equilibrium_degree_percentage`以50%为数量级划分，上下各占约一半，即约有一半数量的街道空间对象均质性相对较强，对象视域数量分布均衡；而一半数量均质性较弱，以某一类对象占主导。


```python
params={'bins': [0,15,25,50,100],
        'columns': ['vege','sky','sky_vege','ground','equilibrium_degree',],
        'percentage2excel_path': '../graph/objects_percentage.xlsx',
        'digits': 3}

percentage,column_names=usda_pano.percent_frequency(cube_object_percent_gdf,params['columns'],params['bins'],params['digits'])
percentage
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vege</th>
      <th>sky</th>
      <th>sky_vege</th>
      <th>ground</th>
      <th>equilibrium_degree</th>
      <th>vege_percentage</th>
      <th>sky_percentage</th>
      <th>sky_vege_percentage</th>
      <th>ground_percentage</th>
      <th>equilibrium_degree_percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(-0.001, 15.0]</th>
      <td>265</td>
      <td>173</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>46.820</td>
      <td>30.565</td>
      <td>0.353</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>(15.0, 25.0]</th>
      <td>59</td>
      <td>132</td>
      <td>13</td>
      <td>0</td>
      <td>0</td>
      <td>10.424</td>
      <td>23.322</td>
      <td>2.297</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>(25.0, 50.0]</th>
      <td>242</td>
      <td>261</td>
      <td>393</td>
      <td>328</td>
      <td>303</td>
      <td>42.756</td>
      <td>46.113</td>
      <td>69.435</td>
      <td>57.951</td>
      <td>53.534</td>
    </tr>
    <tr>
      <th>(50.0, 100.0]</th>
      <td>0</td>
      <td>0</td>
      <td>158</td>
      <td>238</td>
      <td>263</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>27.915</td>
      <td>42.049</td>
      <td>46.466</td>
    </tr>
  </tbody>
</table>
</div>



#### 2）天际线变化指数

语义分割后的等量矩形投影全景图转换为极坐标格式的小行星全景图，提取天空对象计算斑块数量(NP)、周长面积比、形状指数、分维数等4个景观指数。

* 计算天际线变化指数


```python
polar_seg_root=args.polar_seg_img_dir
hsv_lower=[0,0,200]
hsv_upper=[180,255,255] 
tiff_sky_save_root=args.tiff_sky_save_root

metrics_skyline_shape_gdf=usda_pano.metrics_skyline_shape(polar_seg_root,coords,hsv_lower,hsv_upper,tiff_sky_save_root)
```

    100%|██████████| 566/566 [02:33<00:00,  3.69it/s]
    


```python
gpd2postSQL(metrics_skyline_shape_gdf,table_name='metrics_skyline_shape',**args.db.db_info)              
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is metrics_skyline_shape.
    


```python
metrics_skyline_shape_gdf=postSQL2gpd(table_name='metrics_skyline_shape',**args.db.db_info)  
metrics_skyline_shape_gdf.tail(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is metrics_skyline_shape.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>total_area</th>
      <th>area_mn</th>
      <th>perimeter_mn</th>
      <th>perimeter_area_ratio_mn</th>
      <th>number_of_patches</th>
      <th>landscape_shape_index</th>
      <th>shape_index_mn</th>
      <th>fractal_dimension_mn</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>37749.0</td>
      <td>150.996000</td>
      <td>2205.600000</td>
      <td>331.851991</td>
      <td>250.0</td>
      <td>7.087404</td>
      <td>1.123028</td>
      <td>1.018418</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>140020.0</td>
      <td>718.051282</td>
      <td>4803.076923</td>
      <td>296.252504</td>
      <td>195.0</td>
      <td>6.252336</td>
      <td>1.206710</td>
      <td>1.025840</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>41104.0</td>
      <td>185.990950</td>
      <td>4474.208145</td>
      <td>296.170397</td>
      <td>221.0</td>
      <td>12.177340</td>
      <td>1.235508</td>
      <td>1.028000</td>
    </tr>
  </tbody>
</table>
</div>



打印查看天空形状。


```python
fn=r'dongxistreet_228'
sky_example=rxr.open_rasterio(os.path.join(args.tiff_sky_save_root,fn+'.tif'),masked=True).squeeze()

f, ax=plt.subplots(1,1,figsize=(4,4))
sky_example.plot.imshow(ax=ax,add_colorbar=False)
plt.show()
```


<img src="./imgs/3_6_b/output_140_0.png" height='auto' width='auto' title="caDesign">    


* 天际线景观指数间的相关系数

计算4个指数的相关系数，相关性值高于0.5的两对指数分别为周长面积比和分维数（0.65），及形状指数和分维数（0.84）。使用自然最佳断裂点分级方法（Natural break, Jenks）划分指数，尽量使得划分的聚类簇示例偏离划分界限值观察天际线的形状差异。


```python
correlation_columns=['number_of_patches','perimeter_area_ratio_mn','shape_index_mn', 'fractal_dimension_mn',]
corr=usda_pano.correlation_df(metrics_skyline_shape_gdf,correlation_columns,digits=3)
```


<img src="./imgs/3_6_b/output_142_0.png" height='auto' width='auto' title="caDesign">    


#### 3）街道空间的色彩

色彩属性表征城市街道空间的类型和视觉感受。计算区域尺度全景图主题色，通过主题色分布邻近像素聚类，计算获取每一全景图对应街道空间位置的主题色分布信息熵及均衡度。

* 计算图像主题色（多进程）  


```python
img_path=args.pano_path
resize_scale=0.5
number_of_colors=16

img_dominant_color_gdf=usda_pano.find_dominant_colors_pool_main(img_path,[coords,resize_scale,number_of_colors]) 
```

    100%|██████████| 566/566 [11:57<00:00,  1.27s/it]
    


```python
gpd2postSQL(img_dominant_color_gdf,table_name='img_dominant_color',**args.db.db_info)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is img_dominant_color.
    


```python
img_dominant_color_gdf=postSQL2gpd(table_name='img_dominant_color',**args.db.db_info)  
img_dominant_color_gdf.tail(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is img_dominant_color.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>#d5d7d8</td>
      <td>#8ea9d6</td>
      <td>#aac4e8</td>
      <td>#030102</td>
      <td>#a82224</td>
      <td>#332f2e</td>
      <td>#747070</td>
      <td>#e6eaef</td>
      <td>#b7bbc2</td>
      <td>#1f1816</td>
      <td>#8f8988</td>
      <td>#a3a1a2</td>
      <td>#c2d9f4</td>
      <td>#4a4642</td>
      <td>#f9fbfd</td>
      <td>#5b5959</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>#aa2426</td>
      <td>#757170</td>
      <td>#1d1a19</td>
      <td>#b8cde8</td>
      <td>#a7abb0</td>
      <td>#050303</td>
      <td>#888b8f</td>
      <td>#85a1c7</td>
      <td>#dbe1ea</td>
      <td>#a0b8d6</td>
      <td>#302d2d</td>
      <td>#474545</td>
      <td>#f4f8fc</td>
      <td>#615f5e</td>
      <td>#cfd1d2</td>
      <td>#214ba5</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>#c2c4c6</td>
      <td>#3a3738</td>
      <td>#545252</td>
      <td>#070505</td>
      <td>#f4f8fc</td>
      <td>#a62526</td>
      <td>#dcdddf</td>
      <td>#6c6968</td>
      <td>#231f1f</td>
      <td>#84a0c6</td>
      <td>#9db5d3</td>
      <td>#d2e1f6</td>
      <td>#b5cbe6</td>
      <td>#9ca0a5</td>
      <td>#244ba1</td>
      <td>#838183</td>
    </tr>
  </tbody>
</table>
</div>



* 主题色聚类（多进程）


```python
colors_dominant2cluster_path=args.colors_dominant2cluster_path
resize_scale_cluster=0.1
_=usda_pano.dominant2cluster_colors_pool_main(img_path,colors_dominant2cluster_path,[coords,resize_scale_cluster,number_of_colors])
```

    100%|██████████| 566/566 [01:13<00:00,  7.70it/s]
    


```python
with open(colors_dominant2cluster_path,'rb') as f:
    color_dic_list=pickle.load(f)
```


```python
print(color_dic_list[0])
```

    {'fn_stem': 'dongxistreet_0', 'fn_key': 'dongxistreet', 'fn_idx': 0, 'geometry': <POINT (108.919 34.261)>, 'counter': {1: 23, 0: 310, 2: 337, 3: 91, 4: 83, 5: 112, 6: 357, 7: 79, 8: 297, 9: 308, 10: 33, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 3, 17: 1, 18: 3, 19: 1, 20: 2, 21: 1, 22: 1, 23: 1, 24: 1, 25: 2, 26: 1, 27: 1, 28: 2, 29: 22, 30: 1, 31: 2, 32: 7, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 2, 43: 1, 44: 1, 45: 2, 46: 1, 47: 1, 48: 2, 49: 1, 50: 2, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 4, 58: 1, 59: 6, 60: 13, 61: 3, 62: 1, 63: 2, 64: 1, 65: 2, 66: 2, 67: 1, 68: 1, 69: 7, 70: 1, 71: 10, 72: 5, 73: 9, 74: 1, 75: 1, 76: 1, 77: 1, 78: 2, 79: 1, 80: 1, 81: 1, 82: 3, 83: 4, 84: 1, 85: 1, 86: 2, 87: 8, 88: 1, 89: 1, 90: 8, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 3, 98: 6, 99: 2, 100: 1, 101: 1, 102: 5, 103: 1, 104: 4, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 5, 112: 2, 113: 1, 114: 2, 115: 1, 116: 3, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 2, 124: 5, 125: 6, 126: 1, 127: 22, 128: 2, 129: 2, 130: 1, 131: 1, 132: 2, 133: 25, 134: 1, 135: 4, 136: 1, 137: 1, 138: 1, 139: 3, 140: 2, 141: 1, 142: 1, 143: 2, 144: 4, 145: 1, 146: 1, 147: 3, 148: 1, 149: 1, 150: 1, 151: 5, 152: 4, 153: 23, 154: 1, 155: 1, 156: 1, 157: 4, 158: 4, 159: 20, 160: 2, 161: 1, 162: 2, 163: 3, 164: 1, 165: 2, 166: 5, 167: 1, 168: 2, 169: 2, 170: 1, 171: 1, 172: 1, 173: 1, 174: 3, 175: 1, 176: 1, 177: 2, 178: 1, 179: 1, 180: 1, 181: 1, 182: 3, 183: 1, 184: 1, 185: 1, 186: 6, 187: 7, 188: 1, 189: 1, 190: 1, 191: 1, 192: 1, 193: 3, 194: 1, 195: 1, 196: 6, 197: 1, 198: 1, 199: 1, 200: 6, 201: 2, 202: 1, 203: 5, 204: 1, 205: 2, 206: 1, 207: 1, 208: 1, 209: 1, 210: 1, 211: 2, 212: 46, 213: 2, 214: 1, 215: 3, 216: 1, 217: 1, 218: 1, 219: 3, 220: 2, 221: 2, 222: 5, 223: 4, 224: 1, 225: 1, 226: 1, 227: 1, 228: 1, 229: 1, 230: 1, 231: 1, 232: 1, 233: 1, 234: 1, 235: 1, 236: 1, 237: 1, 238: 1, 239: 1, 240: 1, 241: 4, 242: 1, 243: 1, 244: 1, 245: 1, 246: 1, 247: 1, 248: 1, 249: 2, 250: 105, 251: 1, 252: 1, 253: 1, 254: 2, 255: 1, 256: 1, 257: 1, 258: 2, 259: 2, 260: 1, 261: 2, 262: 1, 263: 1, 264: 15, 265: 1, 266: 1, 267: 4, 268: 5, 269: 2, 270: 1, 271: 1, 272: 1, 273: 1, 274: 4, 275: 1, 276: 94, 277: 1, 278: 1, 279: 1, 280: 363, 281: 3, 282: 1, 283: 3, 284: 49, 285: 2, 286: 1, 287: 1, 288: 6, 289: 3, 290: 1, 291: 3, 292: 1, 293: 27, 294: 1, 295: 26, 296: 2, 297: 3, 298: 3, 299: 8, 300: 1, 301: 4, 302: 1, 303: 2, 304: 3, 305: 18, 306: 1, 307: 2, 308: 2, 309: 2, 310: 3, 311: 1, 312: 3, 313: 3, 314: 6, 315: 2, 316: 1, 317: 3, 318: 1, 319: 1, 320: 2, 321: 22, 322: 2, 323: 10, 324: 2, 325: 2, 326: 3, 327: 1, 328: 2, 329: 1, 330: 1, 331: 1, 332: 10, 333: 3, 334: 1, 335: 2, 336: 2, 337: 1, 338: 1, 339: 1, 340: 3, 341: 2, 342: 1, 343: 1, 344: 1, 345: 1, 346: 1, 347: 1, 348: 1, 349: 1, 350: 1, 351: 1, 352: 1, 353: 1, 354: 1, 355: 3, 356: 1, 357: 2, 358: 1, 359: 1, 360: 2, 361: 7, 362: 3, 363: 1, 364: 1}}
    

* 色彩丰富度指数计算


```python
colors_dominant_entropy_gdf=usda_pano.colors_entropy(colors_dominant2cluster_path)
```

    3570
    

    100%|██████████| 566/566 [00:03<00:00, 183.03it/s]
    


```python
gpd2postSQL(colors_dominant_entropy_gdf,table_name='colors_dominant_entropy',**args.db.db_info)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is colors_dominant_entropy.
    


```python
colors_dominant_entropy_gdf=postSQL2gpd(table_name='colors_dominant_entropy',**args.db.db_info)  
colors_dominant_entropy_gdf.tail(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is colors_dominant_entropy.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>counter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>69.367080</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>69.022090</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>68.598123</td>
    </tr>
  </tbody>
</table>
</div>



查看色彩丰富度指数的空间分布。


```python
colors_dominant_entropy_gdf.plot(column='counter',figsize=(20,1),legend=True,cmap='hot',markersize=10);
```


<img src="./imgs/3_6_b/output_156_0.png" height='auto' width='auto' title="caDesign">    


打印原始图像、主题色的分布、主题色比例和主题色的聚类分布。


```python
fn=r'dongxistreet_228'
usda_pano.dominant2cluster_colors_imshow(os.path.join(args.pano_path,fn+'.jpg'),coords,colors_dominant_entropy_gdf,resize_scale=0.1,number_of_colors=16) 
```


<img src="./imgs/3_6_b/output_158_0.png" height='auto' width='auto' title="caDesign">    

#### 4）关键点邻域大小

尺度不变特征变换（SIFT）在不同的尺度上寻找关键点。关键点邻域大小反映了对象具有的尺度特征。图中两幅全景影像提取了图像的关键点，对关键点的邻域大小划分为 (0,10], (10,20], (20,30] 和 (30,40] 等4个区间，可以描述为小尺度，中尺度，较大尺度和大尺度。当图像内的对象较小时，例如窗户的角点、招牌的边缘等，通常是实际当中较为细碎的对象；当对象如天空，成片的墙面时，所提取的边缘特征的邻域尺度则较大。因此尺度不变特征变换关键点邻域尺度大小一定程度上反应了街道视域空间繁复的程度。分别计算所有全景图像给定4个区间的频数，如果图像关键点某一区间的邻域尺度频数接近时，则这些图像在该区间具有相似尺度的对象。

> 该部分代码及解释可以参看*图像分类器、识别器与机器学习模型网络实验应用平台部署*部分。

* 提取图像特征，返回所有图像关键点聚类视觉词袋 


```python
num_cluster=32
img_fp_list=glob.glob(os.path.join(args.pano_path,'*.jpg'))
kmeans=usda_pano.feature_builder_BOW(num_cluster).get_visual_BOW(img_fp_list) # pip install opencv-contrib-python (pip uninstall opencv-python)
```

    100%|██████████| 566/566 [00:15<00:00, 35.74it/s]
    

    start KMean...
    end KMean...
    


```python
kmeans
```




<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KMeans(n_clusters=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">KMeans</label><div class="sk-toggleable__content"><pre>KMeans(n_clusters=32)</pre></div></div></div></div></div>




```python
visual_BOW_kmeans_fn=args.visual_BOW_kmeans_fn
with open(visual_BOW_kmeans_fn,'wb') as f: 
    pickle.dump(kmeans,f) # 存储kmeans聚类模型  
```

* 图像的特征映射（码本映射）


```python
with open(visual_BOW_kmeans_fn,'rb') as f:
    kmeans=pickle.load(f) 
    
feature_map=usda_pano.feature_builder_BOW(num_cluster).get_feature_map(img_fp_list,kmeans) 
```

    100%|██████████| 566/566 [00:19<00:00, 29.23it/s]
    


```python
feature_map_fn=args.feature_map_fn
with open(feature_map_fn,'wb') as f: 
    pickle.dump(feature_map,f)
```

* 码本映射转换为GeoDataFrame，写入数据库


```python
with open(feature_map_fn,'rb') as f:
    feature_map=pickle.load(f)   
featureMap_gdf=usda_pano.kps_desciptors_BOW_feature(feature_map,coords,num_cluster)     
```

    100%|██████████| 566/566 [00:00<00:00, 41992.75it/s]
    


```python
gpd2postSQL(featureMap_gdf,table_name='featuremap',**args.db.db_info)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is featuremap.
    


```python
featureMap_gdf=postSQL2gpd(table_name='featuremap',**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is featuremap.
    


```python
featureMap_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>...</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>13.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>16.0</td>
      <td>...</td>
      <td>10.0</td>
      <td>13.0</td>
      <td>19.0</td>
      <td>3.0</td>
      <td>10.0</td>
      <td>7.0</td>
      <td>14.0</td>
      <td>9.0</td>
      <td>26.0</td>
      <td>23.0</td>
    </tr>
    <tr>
      <th>564</th>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>26.0</td>
      <td>14.0</td>
      <td>12.0</td>
      <td>21.0</td>
      <td>9.0</td>
      <td>9.0</td>
      <td>...</td>
      <td>9.0</td>
      <td>11.0</td>
      <td>12.0</td>
      <td>3.0</td>
      <td>12.0</td>
      <td>15.0</td>
      <td>9.0</td>
      <td>14.0</td>
      <td>14.0</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>565</th>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>34.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>28.0</td>
      <td>27.0</td>
      <td>12.0</td>
      <td>...</td>
      <td>11.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>9.0</td>
      <td>13.0</td>
      <td>12.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 36 columns</p>
</div>



* 给定分割区间，统计关键点邻域尺度 


```python
bins=[0,10,20,30,40]
kp_size_stats_gdf=usda_pano.kp_stats(feature_map,coords,bins)
```

    100%|██████████| 566/566 [00:04<00:00, 139.08it/s]
    


```python
gpd2postSQL(kp_size_stats_gdf,table_name='kp_size_stats',**args.db.db_info)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is kp_size_stats.
    


```python
kp_size_stats_gdf=postSQL2gpd(table_name='kp_size_stats',**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is kp_size_stats.
    


```python
kp_size_stats_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
      <th>num</th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>-0.001_10.0</th>
      <th>10.0_20.0</th>
      <th>30.0_40.0</th>
      <th>20.0_30.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>445.0</td>
      <td>11.051685</td>
      <td>8.464527</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>16.0</td>
      <td>32.0</td>
      <td>445</td>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
      <td>261</td>
      <td>104</td>
      <td>37</td>
      <td>43</td>
    </tr>
    <tr>
      <th>564</th>
      <td>395.0</td>
      <td>10.881013</td>
      <td>8.517138</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>16.0</td>
      <td>32.0</td>
      <td>395</td>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
      <td>249</td>
      <td>77</td>
      <td>35</td>
      <td>34</td>
    </tr>
    <tr>
      <th>565</th>
      <td>464.0</td>
      <td>10.741379</td>
      <td>8.445604</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>12.0</td>
      <td>32.0</td>
      <td>464</td>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
      <td>292</td>
      <td>98</td>
      <td>43</td>
      <td>31</td>
    </tr>
  </tbody>
</table>
</div>



特征点邻域大小比较示例


```python
kp_stats_example_fn=['dongxistreet_228','dongxistreet_269']
img_path=args.pano_path
usda_pano.kp_show(feature_map,kp_stats_example_fn,img_path)   
```


<img src="./imgs/3_6_b/output_177_0.png" height='auto' width='auto' title="caDesign">    



### 3.6.2.4 不同邻里尺度最优簇数选择和指数贡献度

`AgglomerativeClustering`层次聚类算法中`connectivity`参数可以为每个样本指定连接矩阵（Connectivity matrix）。该连接矩阵可以通过`kneighbors_graph`方法，给定每个样本的邻元数计算。越少的邻元数，在聚类中所考虑的邻里关系相对越少，即邻里尺度趋于小范围；反之则越多，邻里尺度趋于大范围。不同邻里尺度下对给定多个街道空间景观指数聚类，计算指数特征的贡献度不仅可以发现主导街区特征的景观指数和对街区特征形成影响较小的景观指数，还可以发现指数作用不同邻里尺度的变化。

`AgglomerativeClustering`方法需要指定聚类的数量，给定`KElbowVisualizer`方法计算的拐点作为最有簇数


```python
panorama_object_percent_gdf=postSQL2gpd(table_name='cube_object_percent',**args.db.db_info)
sky_class_level_metrics_gdf=postSQL2gpd(table_name='metrics_skyline_shape',**args.db.db_info)
colors_dominant_entropy_gdf=postSQL2gpd(table_name='colors_dominant_entropy',**args.db.db_info)
kp_size_stats_gdf=postSQL2gpd(table_name='kp_size_stats',**args.db.db_info)

metrics_panorama_object_percent=['vege','sky','ground','equilibrium_degree']
metrics_sky_class_level_metrics=['number_of_patches','perimeter_area_ratio_mn','shape_index_mn','fractal_dimension_mn']
metrics_colors_dominant_entropy=['counter']
metrics_kp_size_stats=['-0.001_10.0', '10.0_20.0','30.0_40.0', '20.0_30.0']  
metrics_auxiliary=['fn_stem', 'fn_key', 'fn_idx', 'geometry']

metrics_merge=pd.concat([panorama_object_percent_gdf[metrics_panorama_object_percent],
                        sky_class_level_metrics_gdf[metrics_sky_class_level_metrics],
                        colors_dominant_entropy_gdf[metrics_colors_dominant_entropy],
                        kp_size_stats_gdf[metrics_kp_size_stats],
                        panorama_object_percent_gdf[metrics_auxiliary]],axis=1)  
fields_mapping= {
    'vege':'Green view index', 
    'sky':'Sky view factor', 
    'ground':'Ground view index', 
    'equilibrium_degree':'Equilibrium degree',
    'number_of_patches':'number of patches', 
    'perimeter_area_ratio_mn':'Perimeter area ratio(mn)', 
    'shape_index_mn':'Shape index(mn)',
    'fractal_dimension_mn':'Fractal dimension(mn)', 
    'counter':'Color richness index', 
    '-0.001_10.0':'Key point size(0-10]', 
    '10.0_20.0':'Key point size(10-20]',
    '30.0_40.0':'Key point size(30-40]', 
    '20.0_30.0':'Key point size(20-30]'} 
metrics_merge=metrics_merge.rename(columns=fields_mapping)
metrics_merge_gdf=gpd.GeoDataFrame(metrics_merge,crs=panorama_object_percent_gdf.crs,geometry='geometry')

gpd2postSQL(metrics_merge_gdf,table_name='metrics_merge',**args.db.db_info) 
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is cube_object_percent.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is metrics_skyline_shape.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is colors_dominant_entropy.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is kp_size_stats.
    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is metrics_merge.
    


```python
metrics_merge_gdf=postSQL2gpd(table_name='metrics_merge',**args.db.db_info)
metrics_merge_gdf.tail(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is metrics_merge.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Green view index</th>
      <th>Sky view factor</th>
      <th>Ground view index</th>
      <th>Equilibrium degree</th>
      <th>number of patches</th>
      <th>Perimeter area ratio(mn)</th>
      <th>Shape index(mn)</th>
      <th>Fractal dimension(mn)</th>
      <th>Color richness index</th>
      <th>Key point size(0-10]</th>
      <th>Key point size(10-20]</th>
      <th>Key point size(30-40]</th>
      <th>Key point size(20-30]</th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>0.521933</td>
      <td>29.560383</td>
      <td>53.860950</td>
      <td>50.245055</td>
      <td>250.0</td>
      <td>331.851991</td>
      <td>1.123028</td>
      <td>1.018418</td>
      <td>69.367080</td>
      <td>261</td>
      <td>104</td>
      <td>37</td>
      <td>43</td>
      <td>dongxistreet_97</td>
      <td>dongxistreet</td>
      <td>97</td>
      <td>POINT (108.92703 34.26116)</td>
    </tr>
    <tr>
      <th>564</th>
      <td>1.563883</td>
      <td>29.791083</td>
      <td>54.351650</td>
      <td>58.475244</td>
      <td>195.0</td>
      <td>296.252504</td>
      <td>1.206710</td>
      <td>1.025840</td>
      <td>69.022090</td>
      <td>249</td>
      <td>77</td>
      <td>35</td>
      <td>34</td>
      <td>dongxistreet_98</td>
      <td>dongxistreet</td>
      <td>98</td>
      <td>POINT (108.92712 34.26116)</td>
    </tr>
    <tr>
      <th>565</th>
      <td>2.070233</td>
      <td>30.658100</td>
      <td>51.518967</td>
      <td>53.639539</td>
      <td>221.0</td>
      <td>296.170397</td>
      <td>1.235508</td>
      <td>1.028000</td>
      <td>68.598123</td>
      <td>292</td>
      <td>98</td>
      <td>43</td>
      <td>31</td>
      <td>dongxistreet_99</td>
      <td>dongxistreet</td>
      <td>99</td>
      <td>POINT (108.92720 34.26116)</td>
    </tr>
  </tbody>
</table>
</div>



* 不同邻里尺度（邻元数）最优簇数计算-多指数 

通过给定多个簇数（聚类数）分别聚类，计算每个点到其所属聚类中心的平方距离之和(distortion score)，曲线拐点即为最优的簇数选择。从下述计算结果来看，各个不同邻里尺度的最优簇数不尽相同。


```python
fields=['Green view index','Sky view factor', 'Ground view index','Equilibrium degree', 'Perimeter area ratio(mn)','Shape index(mn)', 'Fractal dimension(mn)', 'Color richness index','Key point size(0-10]', 'Key point size(10-20]','Key point size(30-40]', 'Key point size(20-30]',]
kneighbors_graph_n_neighbors_list=[5,10,15,20,25,30,35,40,45,50,60,70,80,90,100,110,120,130,140,150]
distortion_score_save_path='../graph'
k=(2,12)

elbow_score_dict=usda_pano.distortion_score_elbow_kneighbors(metrics_merge_gdf,fields,distortion_score_save_path,kneighbors_graph_n_neighbors_list,k)  
```

    100%|██████████| 20/20 [00:44<00:00,  2.22s/it]
    

    [118.69348062107632, 64.84605180802042, 54.69607692661462, 50.580944380733044, 44.62354172738738, 40.754705891336904, 37.80621351461414, 36.2090554105516, 34.73579086012199, 33.37959313559141] 4 54.69607692661462
    





```python
usda_pano.elbow_score_plot(elbow_score_dict,k,figsize=(6, 8),ylim=(0,160),legend_loc='upper right')
```


<img src="./imgs/3_6_b/output_183_0.png" height='auto' width='auto' title="caDesign">    

* 不同邻里尺度景观指数贡献度

给定不同邻里尺度的连接矩阵，和对应的最优簇数，通过特征选择（SelectKBest）方法，计算给定连续邻元数下景观指数贡献度及其变化。计算结果显示，不同邻里尺度下Seg_GVI基本占绝对优势，其次为Seg_SVF、CRI和KPSF(0-10]。


```python
featureScores_dict=usda_pano.idxes_clustering_contribution_kneighbors(metrics_merge_gdf,fields,elbow_score_dict) 
```

    100%|██████████| 20/20 [00:06<00:00,  3.18it/s]
    


```python
x_offsets={ 'Fractal dimension(mn)':60,'Key point size(30-40]':60,'Equilibrium degree':60}
y_offsets={'Perimeter area ratio(mn)':50,'Key point size(20-30]':25,'Color richness index':10}
usda_pano.idxes_clustering_contribution_kneighbors_plot(featureScores_dict,figsize=(5, 10),x_offsets=x_offsets,y_offsets=y_offsets)  
```


<img src="./imgs/3_6_b/output_186_0.png" height='auto' width='auto' title="caDesign">    


### 3.6.2.5 街道行业分类服务空间组成结构

每一位置点建立 500m 的缓冲区域，提取落于缓冲区内的POI点数据。计算每一位置点对应的POI点数量，信息熵和均衡度。


```python
clipped_pois_fn=r'G:\data\POI_dongxistreet\clipped_poi_gdf.gpkg'
poi_gdf=gpd.read_file(clipped_pois_fn)
print(poi_gdf.crs)
```

    PROJCS["WGS 84 / UTM zone 49N",GEOGCS["WGS 84",DATUM["World Geodetic System 1984",SPHEROID["WGS 84",6378137,298.257223563]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AUTHORITY["EPSG","4326"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",111],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",500000],PARAMETER["false_northing",0],UNIT["metre",1],AXIS["Easting",EAST],AXIS["Northing",NORTH],AUTHORITY["EPSG","32649"]]
    


```python
coordi_df=metrics_merge_gdf.to_crs(poi_gdf.crs)
```


```python
pos_poi_idxes_gdf,pos_poi_feature_vector_gdf=usda_pano.street_poi_structure(poi=poi_gdf,position=coordi_df,distance=500)
```

    100%|██████████| 566/566 [01:31<00:00,  6.17it/s]
    


```python
pos_poi_idxes_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>frank_e</th>
      <th>num</th>
      <th>num_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>POINT (309138.206 3793057.251)</td>
      <td>52.488255</td>
      <td>121</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>564</th>
      <td>POINT (309146.205 3793057.353)</td>
      <td>52.861526</td>
      <td>121</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>565</th>
      <td>POINT (309154.205 3793057.456)</td>
      <td>52.838794</td>
      <td>119</td>
      <td>-2.0</td>
    </tr>
  </tbody>
</table>
</div>



打印 POI 数量列`num`和信息熵列`frank_e`，可以看到以钟楼区域及其西侧（回民街）数量最多，街道空间提供的服务越多。而均衡度最大的区域在POI数量最少的区域，是因为主要的行业分类，例如购物、生活服务、美食和酒店等在该区域分布较少，减少了不同行业数量的差异。


```python
pos_poi_idxes_gdf.plot(column='num',cmap='hot',figsize=(20,3),markersize=5,legend=True);
```


<img src="./imgs/3_6_b/output_193_0.png" height='auto' width='auto' title="caDesign">    


```python
pos_poi_idxes_gdf.plot(column='frank_e',cmap='hot',figsize=(20,3),markersize=5,legend=True);
```


<img src="./imgs/3_6_b/output_194_0.png" height='auto' width='auto' title="caDesign">    

`pos_poi_feature_vector_gdf`为每一位置点给定范围内， POI 一级分类频数。


```python
pos_poi_feature_vector_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>...</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>563</th>
      <td>POINT (309138.206 3793057.251)</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>13.0</td>
      <td>15.0</td>
      <td>11.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>10.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>564</th>
      <td>POINT (309146.205 3793057.353)</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>13.0</td>
      <td>15.0</td>
      <td>10.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>...</td>
      <td>2.0</td>
      <td>10.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>565</th>
      <td>POINT (309154.205 3793057.456)</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>13.0</td>
      <td>14.0</td>
      <td>10.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>...</td>
      <td>2.0</td>
      <td>11.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 26 columns</p>
</div>




```python
gpd2postSQL(pos_poi_idxes_gdf,table_name='pos_poi_idxes',**args.db.db_info) 
gpd2postSQL(pos_poi_feature_vector_gdf,table_name='pos_poi_feature_vector',**args.db.db_info) 
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is pos_poi_idxes.
    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is pos_poi_feature_vector.
    

合并全景图视域景观指数和 POI 相关指数，并写入数据库。


```python
cols=['frank_e','num','num_diff']
metrics_merge_gdf[cols]=pos_poi_idxes_gdf[cols]
```


```python
gpd2postSQL(metrics_merge_gdf,table_name='metrics_inall',**args.db.db_info)
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is metrics_inall.
    

### 3.6.2.6 建立特征指数的 LSTM 时空预测模型

使用 LSTM 网络结构构建预测模型。首先读取前文处理的视域空间指数和 POI 指数数据，移除可能存在的空值，用`fn_idx`字段按照东西大街空间顺序排序。


```python
metrics_inall=postSQL2gpd(table_name='metrics_inall',**args.db.db_info)
metrics_inall.sort_values(by=['fn_idx'],inplace=True)
metrics_inall.reset_index(drop=True,inplace=True)
metrics_inall.dropna(inplace=True)
metrics_inall.head(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is metrics_inall.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Green view index</th>
      <th>Sky view factor</th>
      <th>Ground view index</th>
      <th>Equilibrium degree</th>
      <th>number of patches</th>
      <th>Perimeter area ratio(mn)</th>
      <th>Shape index(mn)</th>
      <th>Fractal dimension(mn)</th>
      <th>Color richness index</th>
      <th>Key point size(0-10]</th>
      <th>Key point size(10-20]</th>
      <th>Key point size(30-40]</th>
      <th>Key point size(20-30]</th>
      <th>fn_stem</th>
      <th>fn_key</th>
      <th>fn_idx</th>
      <th>geometry</th>
      <th>frank_e</th>
      <th>num</th>
      <th>num_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4.988783</td>
      <td>39.721033</td>
      <td>50.634883</td>
      <td>48.372925</td>
      <td>282.0</td>
      <td>261.505874</td>
      <td>1.228234</td>
      <td>1.033018</td>
      <td>65.470208</td>
      <td>159</td>
      <td>44</td>
      <td>22</td>
      <td>22</td>
      <td>dongxistreet_1</td>
      <td>dongxistreet</td>
      <td>1</td>
      <td>POINT (108.91910 34.26081)</td>
      <td>57.426584</td>
      <td>55</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.789183</td>
      <td>39.835183</td>
      <td>50.661900</td>
      <td>45.381630</td>
      <td>295.0</td>
      <td>266.110274</td>
      <td>1.199734</td>
      <td>1.031069</td>
      <td>67.015989</td>
      <td>144</td>
      <td>44</td>
      <td>17</td>
      <td>32</td>
      <td>dongxistreet_2</td>
      <td>dongxistreet</td>
      <td>2</td>
      <td>POINT (108.91918 34.26078)</td>
      <td>57.426584</td>
      <td>55</td>
      <td>-164.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.378683</td>
      <td>39.334867</td>
      <td>49.886200</td>
      <td>46.898469</td>
      <td>286.0</td>
      <td>260.221003</td>
      <td>1.191649</td>
      <td>1.029841</td>
      <td>66.440458</td>
      <td>157</td>
      <td>45</td>
      <td>14</td>
      <td>19</td>
      <td>dongxistreet_3</td>
      <td>dongxistreet</td>
      <td>3</td>
      <td>POINT (108.91927 34.26076)</td>
      <td>57.426584</td>
      <td>55</td>
      <td>-128.0</td>
    </tr>
  </tbody>
</table>
</div>



使用`Plotly`库打印交互式图表，查看具体细节信息。


```python
metrics_inall_copy=metrics_inall.copy(deep=True)
metrics_inall_copy[['lat','lon']]=metrics_inall_copy.apply(lambda row:[row.geometry.y,row.geometry.x],axis=1,result_type='expand')
```


```python
fig = px.scatter_mapbox(metrics_inall_copy, lat="lat", lon="lon", hover_name="fn_idx", hover_data=['Green view index','Color richness index','frank_e'],zoom=14, height=300)
fig.update_layout(mapbox_style="open-street-map")
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()
```

<img src="./imgs/3_6_b/3_6_b_05.png" height='auto' width='auto' title="caDesign">


定义`normalize_by_meanNstd()`函数标准化数据，公式为$\frac{v- \mu }{ \sigma } $，式中$v$为数据值，$\mu$为数据（一列数据，即某一指数序列）的均值；$\sigma$为数据的标准差。打印标准化后的数据，查看各列（指数）曲线变化。


```python
cols=['Green view index', 'Sky view factor', 'Ground view index','Equilibrium degree', 'number of patches', 'Perimeter area ratio(mn)','Shape index(mn)', 'Fractal dimension(mn)', 'Color richness index',
      'Key point size(0-10]', 'Key point size(10-20]','Key point size(30-40]', 'Key point size(20-30]','frank_e', 'num']

norm_df,mean_std_dict=usda_utils.normalize_by_meanNstd(metrics_inall[cols])
print(mean_std_dict)
norm_df.plot.line(figsize=(20,20),subplots=True);
```

    {'Green view index': [19.923202684365783, 16.43173153981058], 'Sky view factor': [22.42920268436578, 9.705913947185682], 'Ground view index': [49.61750383480826, 3.458661094856522], 'Equilibrium degree': [49.2884185074578, 4.362935945874506], 'number of patches': [250.99469026548672, 67.83167767775927], 'Perimeter area ratio(mn)': [270.536192974786, 29.428301484843914], 'Shape index(mn)': [1.1646643107968098, 0.04053803041743256], 'Fractal dimension(mn)': [1.0259775695134745, 0.00417126374694389], 'Color richness index': [72.11344856579554, 5.1726015268900865], 'Key point size(0-10]': [296.6725663716814, 111.91842920496616], 'Key point size(10-20]': [67.7575221238938, 23.25421415827134], 'Key point size(30-40]': [21.08495575221239, 7.3114505216344154], 'Key point size(20-30]': [27.833628318584072, 9.241476911181776], 'frank_e': [53.119824785230435, 6.098244214407541], 'num': [118.43362831858407, 65.38189450866699]}
    


<img src="./imgs/3_6_b/output_207_1.png" height='auto' width='auto' title="caDesign">    


查看各指数间的相关系数，为指数的进一步删选提供依据。


```python
fig, ax=plt.subplots(figsize=(12, 10))
sb.heatmap(norm_df.corr(),cmap='YlGnBu',annot=True,ax=ax)
plt.show()
```


<img src="./imgs/3_6_b/output_209_0.png" height='auto' width='auto' title="caDesign">    


提取测试部分指数，并逐一训练各个指数的 LSTM 网络模型，且将训练的各模型保存至本地磁盘。在训练时，根据前文指数变化曲线，和训练均方误差曲线变化，及打印的预测曲线来调整配置窗口`window_size`的大小。


```python
cols_selection=['Green view index','Equilibrium degree','Perimeter area ratio(mn)', 'Color richness index','Key point size(0-10]','frank_e' ]
test_size=100
batch_size=64

window_size_dict={'Green view index':10,'Equilibrium degree':1,'Perimeter area ratio(mn)':5, 'Color richness index':10,'Key point size(0-10]':1,'frank_e':5}
save_path=r'G:\model_ckpts\spatial_metrics_lstm\spatial_metrics_lst.pt'
model_state_dict={}
for col in cols_selection:  
    print('-'*10,col)
    window_size=window_size_dict[col]
    train_data_dict,test_data_dict,train_loader_dict,test_loader_dict=usda_utils.create_sequence2series_datasetNdataloader_from_df(norm_df,cols_selection,window_size=window_size) 
    model=usda_models.Simple_LSTM(input_size=window_size,output_size=1,hidden_size=128)
    train_rmse_dict, test_rmse_dict=usda_models.spatial_metrics_train(model,train_loader_dict[col],train_data_dict[col],test_data_dict[col],n_epochs=100,verbose=False)      
    usda_models.train_test_rmse_plot(train_rmse_dict,test_rmse_dict)
    model_state_dict[col]=model.state_dict()
    
torch.save(model_state_dict,save_path)
```

    ---------- Green view index
    Complete training.
    


<img src="./imgs/3_6_b/output_211_1.png" height='auto' width='auto' title="caDesign">    

    


    ---------- Equilibrium degree
    Complete training.
    


<img src="./imgs/3_6_b/output_211_3.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Perimeter area ratio(mn)
    Complete training.
    


<img src="./imgs/3_6_b/output_211_5.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Color richness index
    Complete training.
    


<img src="./imgs/3_6_b/output_211_7.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Key point size(0-10]
    Complete training.
    


<img src="./imgs/3_6_b/output_211_9.png" height='auto' width='auto' title="caDesign">    
    


    ---------- frank_e
    Complete training.
    


<img src="./imgs/3_6_b/output_211_11.png" height='auto' width='auto' title="caDesign">    
    


打印指数真实曲线和预测曲线，观察训练的模型预测能力。


```python
spatial_metrics_lst=torch.load(save_path)
for col in cols_selection:
    window_size=window_size_dict[col]
    train_data_dict,test_data_dict,train_loader_dict,test_loader_dict=usda_utils.create_sequence2series_datasetNdataloader_from_df(norm_df,cols_selection,window_size=window_size) 
    trained_model=usda_models.Simple_LSTM(input_size=window_size,output_size=1,hidden_size=128)
    trained_model.load_state_dict(spatial_metrics_lst[col])
    print(trained_model)
    usda_models.timeseries_pred_plot(trained_model,norm_df[col],train_data_dict[col],test_data_dict[col],window_size,title=f'{col}_prediction')    
```

    Simple_LSTM(
      (lstm): LSTM(10, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_1.png" height='auto' width='auto' title="caDesign">    
    


    Simple_LSTM(
      (lstm): LSTM(1, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_3.png" height='auto' width='auto' title="caDesign">    
    


    Simple_LSTM(
      (lstm): LSTM(5, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_5.png" height='auto' width='auto' title="caDesign">    
    


    Simple_LSTM(
      (lstm): LSTM(10, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_7.png" height='auto' width='auto' title="caDesign">    
    


    Simple_LSTM(
      (lstm): LSTM(1, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_9.png" height='auto' width='auto' title="caDesign">    
    


    Simple_LSTM(
      (lstm): LSTM(5, 128, batch_first=True)
      (linear): Linear(in_features=128, out_features=1, bias=True)
    )
    


<img src="./imgs/3_6_b/output_213_11.png" height='auto' width='auto' title="caDesign">    
    


模型训练时，均方误差的计算是用连续切分的指数值片段（窗口）预测紧邻的下一个空间的指数值，且每一指数片段均采样自指数的真实值。如果构建一个类似文本生成的试验，则把每一个新预测的下一空间的指数值追加到已有指数序列下，用于再下一空间指数值的预测，周而复始，不断生成连续空间的指数值。从下述计算打印结果来看，通常临近真实值小部分空间区域指数顺势变化，但随着空间的延长，模型已经不再有变化预测能力，曲线变成直线。这与本次试验有限的样本量、简单架构的 LSTM 网络结构有关。


```python
spatial_metrics_lst=torch.load(save_path)
generation_dict={}
for col in cols_selection:
    print('-'*10,col)
    window_size=window_size_dict[col]
    trained_model=usda_models.Simple_LSTM(input_size=window_size,output_size=1,hidden_size=128)
    trained_model.load_state_dict(spatial_metrics_lst[col])
    pred_lst,X=usda_models.timeseries_pred_generation(trained_model,metrics_inall[col][-20:],window_size,gen_length=60,norm=mean_std_dict[col])    
    generation_dict[col]=[pred_lst,X]
    
    usda_models.timeseries_pred_generation_plot(X,pred_lst)    
```

    ---------- Green view index
    


<img src="./imgs/3_6_b/output_215_1.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Equilibrium degree
    


<img src="./imgs/3_6_b/output_215_3.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Perimeter area ratio(mn)
    


<img src="./imgs/3_6_b/output_215_5.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Color richness index
    


<img src="./imgs/3_6_b/output_215_7.png" height='auto' width='auto' title="caDesign">    
    


    ---------- Key point size(0-10]
    


<img src="./imgs/3_6_b/output_215_9.png" height='auto' width='auto' title="caDesign">    
    


    ---------- frank_e
    


<img src="./imgs/3_6_b/output_215_11.png" height='auto' width='auto' title="caDesign">    
    


---

注释（Notes）：

①  全球土地覆盖产品（WorldCover） 2020年，（<https://worldcover2020.esa.int/>）。

②  全球土地覆盖产品（WorldCover） 2021年，（<https://worldcover2021.esa.int/>）。

③  WorldCover数据产品使用手册（Product User Manual），（<https://github.com/microsoft/PlanetaryComputerExamples/blob/main/datasets/esa-worldcover/esa-worldcover-example.ipynb>）。

④  Planetary Computer Hub（PcHub），（<https://github.com/microsoft/PlanetaryComputerExamples/blob/main/datasets/esa-worldcover/esa-worldcover-example.ipynb>）。

⑤  Google Earth，（<https://www.google.com/earth/versions/>）。

⑥  百度地图开放平台，（<https://lbsyun.baidu.com/index.php?title=%E9%A6%96%E9%A1%B5>）。

⑦  PASS（ERF-PSPNet）深度学习模型，（<https://github.com/elnino9ykl/PASS>）。

⑧  PASS GitHub 代码仓库，（<https://github.com/elnino9ykl/PASS/tree/master/trained_models>）。

⑨  Oculus 360 度视频流测量研究成果，（<https://github.com/bingsyslab/360projection>）。

⑩  Making a Little Planet Panorma using Python and Scikit Image，（<https://richwareham.com/little-planet-projection/>）。

⑪  mayavi 三维科学数据可视化绘图工具，（<https://docs.enthought.com/mayavi/mayavi/>）。

参考文献（References）:

[1] Accessing ESA WorldCover classification data with the Planetary Computer STAC API,<https://github.com/microsoft/PlanetaryComputerExamples/blob/main/datasets/esa-worldcover/esa-worldcover-example.ipynb>

[2] Yang, K., Hu, X., Bergasa, L. M., Romera, E., & Wang, K. (2020). PASS: Panoramic Annular Semantic Segmentation. IEEE Transactions on Intelligent Transportation Systems, 21(10), 4171–4185. doi:10.1109/tits.2019.2938965 

[3] Zhou, C., Li, Z., & Liu, Y. (2017). A Measurement Study of Oculus 360 Degree Video Streaming. Proceedings of the 8th ACM on Multimedia Systems Conference - MMSys’17. doi:10.1145/3083187.3083190
